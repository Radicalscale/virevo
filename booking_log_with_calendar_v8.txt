âœ… Loaded agent: JK First Caller-optimizer3-antigrav
   Model: grok-4-fast-non-reasoning
âœ… Loaded agent: JK First Caller-optimizer3-antigrav
   Model: grok-4-fast-non-reasoning
   Flow nodes: 66
âš ï¸ Could not import RAG service: Read-only file system (os error 30)
ğŸ“‹ Built cached system prompt: 5684 chars (global) + 1402 chars (technical)
ğŸ’‰ Injecting custom variables: {'customer_name': 'Kendrick', 'email': 'kendrickbowman9@gmail.com'}
âœ… Session initialized

============================================================
ğŸ“œ RUNNING SCRIPTED CONVERSATION
============================================================


============================================================
ğŸ¤ TURN 5: User says: "User: Hello?"
============================================================
â±ï¸ [20:07:58.064] ğŸ“¥ process_user_input() ENTRY - text: 'User: Hello?...'
â±ï¸ [20:07:58.064] â© About to call _process_call_flow_streaming()
â±ï¸ [20:07:58.064] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:07:58.064] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 1, Is first: True
â±ï¸ [20:07:58.064] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:07 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 9 chars) - will return text instantly
Using flow node: Greeting (type: conversation, mode: script)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [20:07:58.064] ğŸ“„ About to process content (mode=script, length=9)
ğŸ“¤ Streaming script as 1 sentence(s)
    ğŸ”Š TTS: Kendrick?
ğŸ“¤ Streamed script sentence 1/1: Kendrick?...
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 2 in conversation history
LLM response (0.00s): Kendrick?
Total latency: 0.00s

   ğŸ“ NODE: Greeting
   ğŸ¤– RESPONSE: Kendrick?

============================================================
ğŸ¤ TURN 6: User says: "User: Yes, this is Kendrick."
============================================================
â±ï¸ [20:07:58.565] ğŸ“¥ process_user_input() ENTRY - text: 'User: Yes, this is Kendrick....'
â±ï¸ [20:07:58.566] â© About to call _process_call_flow_streaming()
â±ï¸ [20:07:58.566] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:07:58.566] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 3, Is first: False
ğŸ” Using explicitly set current_node_id: 2
â±ï¸ [20:07:58.566] ğŸ”€ About to call _follow_transition() for: User: Yes, this is Kendrick....
Evaluating transitions from Greeting for message: User: Yes, this is Kendrick.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:07:58.617] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 3 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:59.099] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 482ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Confirms name (Yes|Speaking|This is he/she|etc)...', 'Wrong number (No John here|Wrong number|etc) - don...', 'Does not conform (Any other response / Resistance)...']
Selected transition index: 0
Transition: Greeting -> Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
â±ï¸ [TIMING] TRANSITION_EVAL: 533ms
â±ï¸ [20:07:59.099] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:07 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 89 chars) - will return text instantly
Using flow node: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation) (type: conversation, mode: script)
â±ï¸ [20:07:59.099] ğŸ“„ About to process content (mode=script, length=89)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: This is Jake...
ğŸ“¤ Streamed script sentence 1/2: This is Jake......
    ğŸ”Š TTS: I was just, um, wondering if you could possibly help me out for a moment?
ğŸ“¤ Streamed script sentence 2/2: I was just, um, wondering if you could possibly he...
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763159750250 in conversation history
LLM response (0.53s): This is Jake... I was just, um, wondering if you could possibly help me out for a moment?
Total latency: 0.53s

   ğŸ“ NODE: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
   ğŸ¤– RESPONSE: This is Jake... I was just, um, wondering if you could possibly help me out for a moment?

============================================================
ğŸ¤ TURN 7: User says: "User: Sure, what is this about?"
============================================================
â±ï¸ [20:07:59.601] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sure, what is this about?...'
â±ï¸ [20:07:59.601] â© About to call _process_call_flow_streaming()
â±ï¸ [20:07:59.601] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:07:59.601] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 5, Is first: False
ğŸ” Using explicitly set current_node_id: 1763159750250
â±ï¸ [20:07:59.601] ğŸ”€ About to call _follow_transition() for: User: Sure, what is this about...
Evaluating transitions from Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation) for message: User: Sure, what is this about?
ğŸ¤ AUTO-TRANSITION AFTER RESPONSE enabled - user spoke, transitioning to: 1763161849799
âœ… Auto-transitioned (after response) to: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
ğŸ“ User's response captured: 'User: Sure, what is this about?...'
â±ï¸ [TIMING] TRANSITION_EVAL: 0ms
â±ï¸ [20:07:59.601] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:07 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 260 chars) - will return text instantly
Using flow node: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic (type: conversation, mode: script)
â±ï¸ [20:07:59.602] ğŸ“„ About to process content (mode=script, length=260)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: Well, uh, I don't know if you could yet, but, I'm calling because you filled out...
ğŸ“¤ Streamed script sentence 1/2: Well, uh, I don't know if you could yet, but, I'm ...
    ğŸ”Š TTS: I know this call is out of the blue, but do you have just 25 seconds for me to e...
ğŸ“¤ Streamed script sentence 2/2: I know this call is out of the blue, but do you ha...
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763161849799 in conversation history
LLM response (0.00s): Well, uh, I don't know if you could yet, but, I'm calling because you filled out an ad about stacking income without stacking hours. I know this call is out of the blue, but do you have just 25 seconds for me to explain why I'm reaching out today specifically?
Total latency: 0.00s

   ğŸ“ NODE: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
   ğŸ¤– RESPONSE: Well, uh, I don't know if you could yet, but, I'm calling because you filled out an ad about stacking income without stacking hours. I know this call is out of the blue, but do you have just 25 second...

============================================================
ğŸ¤ TURN 8: User says: "User: That sounds interesting."
============================================================
â±ï¸ [20:08:00.103] ğŸ“¥ process_user_input() ENTRY - text: 'User: That sounds interesting....'
â±ï¸ [20:08:00.103] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:00.103] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:00.103] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 7, Is first: False
ğŸ” Using explicitly set current_node_id: 1763161849799
â±ï¸ [20:08:00.103] ğŸ”€ About to call _follow_transition() for: User: That sounds interesting....
Evaluating transitions from Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic for message: User: That sounds interesting.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:00.147] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 4 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:00.541] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 393ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Agrees|consents (yes|sure|okay|hear more|call cons...', 'Any objection or non compliance that isn\'t a "I do...', 'NO (flat out)|No recall (done quickly) AND no othe...', "I'm Busy, or requests to call back responses from ..."]
Selected transition index: 0
Transition: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic -> N_IntroduceModel_And_AskQuestions_V3_Adaptive
â±ï¸ [TIMING] TRANSITION_EVAL: 437ms
â±ï¸ [20:08:00.541] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 164 chars) - will return text instantly
Using flow node: N_IntroduceModel_And_AskQuestions_V3_Adaptive (type: conversation, mode: script)
â±ï¸ [20:08:00.541] ğŸ“„ About to process content (mode=script, length=164)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: Okay, in a nutshell, we set up passive income websites, and we let them produce ...
ğŸ“¤ Streamed script sentence 1/2: Okay, in a nutshell, we set up passive income webs...
    ğŸ”Š TTS: What questions come to mind as soon as you hear something like that?
ğŸ“¤ Streamed script sentence 2/2: What questions come to mind as soon as you hear so...
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763163400676 in conversation history
LLM response (0.44s): Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What questions come to mind as soon as you hear something like that?
Total latency: 0.44s

   ğŸ“ NODE: N_IntroduceModel_And_AskQuestions_V3_Adaptive
   ğŸ¤– RESPONSE: Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What questions come to mind as soon as you hear something like that?

============================================================
ğŸ¤ TURN 9: User says: "User: I work in software sales."
============================================================
â±ï¸ [20:08:01.042] ğŸ“¥ process_user_input() ENTRY - text: 'User: I work in software sales....'
â±ï¸ [20:08:01.042] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:01.042] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:01.042] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 9, Is first: False
ğŸ” Using explicitly set current_node_id: 1763163400676
â±ï¸ [20:08:01.042] ğŸ”€ About to call _follow_transition() for: User: I work in software sales...
Evaluating transitions from N_IntroduceModel_And_AskQuestions_V3_Adaptive for message: User: I work in software sales.
ğŸ¤ AUTO-TRANSITION AFTER RESPONSE enabled - user spoke, transitioning to: 1763206946898
âœ… Auto-transitioned (after response) to: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
ğŸ“ User's response captured: 'User: I work in software sales....'
â±ï¸ [TIMING] TRANSITION_EVAL: 0ms
â±ï¸ [20:08:01.042] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive (type: conversation, mode: conversation)
ğŸ“š Q&A/KB node detected by label - skipping pre-response mandatory check, will check on transition
â±ï¸ [20:08:01.042] ğŸ“„ About to process content (mode=conversation, length=483)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N_KB_Q&A_With_StrategicNarrative_V3_Adaptive': use_parallel_llm=False
â±ï¸ [20:08:01.091] ğŸ’¬ LLM REQUEST START: 9 conversation turns, 8508 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (1422 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 5, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (9 messages)
ğŸ“   assistant: Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What...
ğŸ“   user: User: I work in software sales....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:01.579] ğŸ’¬ LLM FIRST TOKEN: 488ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Software sales is a solid fieldâ€”lots of folks in that space are looking to d...
ğŸ“¤ Streamed sentence: [N] Software sales is a solid fieldâ€”lots of folks ...
    ğŸ”Š TTS: What drew you to the ad about stacking income without adding hours?
ğŸ“¤ Streamed final fragment: What drew you to the ad about stacking income with...
â±ï¸ [TIMING] LLM_TOTAL: 797ms for 184 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763206946898 in conversation history
LLM response (0.85s): [N] Software sales is a solid fieldâ€”lots of folks in that space are looking to diversify income without burning out. What drew you to the ad about stacking income without adding hours?
Total latency: 0.85s

   ğŸ“ NODE: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
   ğŸ¤– RESPONSE: [N] Software sales is a solid fieldâ€”lots of folks in that space are looking to diversify income without burning out. What drew you to the ad about stacking income without adding hours?

============================================================
ğŸ¤ TURN 13: User says: "User: I make about $120,000 a year base."
============================================================
â±ï¸ [20:08:02.390] ğŸ“¥ process_user_input() ENTRY - text: 'User: I make about $120,000 a year base....'
â±ï¸ [20:08:02.390] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:02.390] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:02.390] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 11, Is first: False
ğŸ” Using explicitly set current_node_id: 1763206946898
â±ï¸ [20:08:02.390] ğŸ”€ About to call _follow_transition() for: User: I make about $120,000 a ...
Evaluating transitions from N_KB_Q&A_With_StrategicNarrative_V3_Adaptive for message: User: I make about $120,000 a year base.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:02.427] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:02.834] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 407ms
ğŸ¤– AI transition decision: '1'
ğŸ“Š Available transitions: ['...would you honestly be upset if you had an extra...', 'User has answered income questions, provided finan...']
Selected transition index: 1
Transition: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive -> Logic Split - Income
â±ï¸ [TIMING] TRANSITION_EVAL: 444ms
â±ï¸ [20:08:02.834] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
ğŸ” Auto-detected PROMPT mode (instruction markers found)
Using flow node: Logic Split - Income (type: logic_split, mode: prompt)
ğŸ”€ Logic Split node reached - evaluating conditions
ğŸ”€ Evaluating 1 conditions
  Condition 1: amount_reference greater_than 8000
    Variable value: 
    Could not extract numbers: var=None, compare=8000.0
    Result: False
â„¹ï¸ No conditions matched - using default path: 1763197118793
âœ… Condition matched - moving to node: N_AskCapital_5k_V1_Adaptive
ğŸ“‹ Processing node streaming - Type: conversation, Mode: prompt, Content length: 921 chars
ğŸ¤– Using PROMPT mode - will generate AI response
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:02.871] ğŸ’¬ LLM REQUEST START: 11 conversation turns, 8946 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (1860 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 6, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (11 messages)
ğŸ“   assistant: [N] Software sales is a solid fieldâ€”lots of folks in that space are looking to diversify income with...
ğŸ“   user: User: I make about $120,000 a year base....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:03.384] ğŸ’¬ LLM FIRST TOKEN: 513ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] $120,000 base is impressiveâ€”puts you in a strong spot to scale up without ri...
ğŸ“¤ Streamed sentence: [N] $120,000 base is impressiveâ€”puts you in a stro...
    ğŸ”Š TTS: For this model,
ğŸ“¤ Streamed sentence: For this model,...
    ğŸ”Š TTS: we typically look for about five thousand dollars in liquid capital to get start...
ğŸ“¤ Streamed sentence: we typically look for about five thousand dollars ...
    ğŸ”Š TTS: Do you have that amount accessible right now?
ğŸ“¤ Streamed final fragment: Do you have that amount accessible right now?...
â±ï¸ [TIMING] LLM_TOTAL: 2009ms for 246 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763197118793 in conversation history
LLM response (2.49s): [N] $120,000 base is impressiveâ€”puts you in a strong spot to scale up without risking your main gig. For this model, we typically look for about five thousand dollars in liquid capital to get started. Do you have that amount accessible right now?
Total latency: 2.49s

   ğŸ“ NODE: N_AskCapital_5k_V1_Adaptive
   ğŸ¤– RESPONSE: [N] $120,000 base is impressiveâ€”puts you in a strong spot to scale up without risking your main gig. For this model, we typically look for about five thousand dollars in liquid capital to get started....

============================================================
ğŸ¤ TURN 15: User says: "User: I have about $20,000 in savings right now."
============================================================
â±ï¸ [20:08:05.381] ğŸ“¥ process_user_input() ENTRY - text: 'User: I have about $20,000 in savings right now....'
â±ï¸ [20:08:05.381] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:05.381] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:05.381] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 13, Is first: False
ğŸ” Using explicitly set current_node_id: 1763197118793
â±ï¸ [20:08:05.381] ğŸ”€ About to call _follow_transition() for: User: I have about $20,000 in ...
Evaluating transitions from N_AskCapital_5k_V1_Adaptive for message: User: I have about $20,000 in savings right now.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:05.419] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:05.987] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 567ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ["If the user's response indicates they have the cap...", "They indicate they don't have at least $5k (ie, No..."]
Selected transition index: 0
Transition: N_AskCapital_5k_V1_Adaptive -> N401_AskWhyNow_Initial_V10_AssertiveFrame
â±ï¸ [TIMING] TRANSITION_EVAL: 605ms
â±ï¸ [20:08:05.987] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [20:08:05.987] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/13 messages)
â±ï¸ [20:08:06.023] ğŸ’¬ LLM REQUEST START: 13 conversation turns, 12692 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5606 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 7, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] $120,000 base is impressiveâ€”puts you in a strong spot to scale up without risking your main gig....
ğŸ“   user: User: I have about $20,000 in savings right now....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:06.597] ğŸ’¬ LLM FIRST TOKEN: 574ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Twenty thousand in savings gives you plenty of flexibility to get a few site...
ğŸ“¤ Streamed sentence: [N] Twenty thousand in savings gives you plenty of...
    ğŸ”Š TTS: Just to understand a bit better,
ğŸ“¤ Streamed sentence: Just to understand a bit better,...
    ğŸ”Š TTS: is there a specific reason you're looking to make a change or explore something ...
ğŸ“¤ Streamed sentence: is there a specific reason you're looking to make ...
    ğŸ”Š TTS: as opposed to say,
ğŸ“¤ Streamed sentence: as opposed to say,...
    ğŸ”Š TTS: six months from now?
ğŸ“¤ Streamed final fragment: six months from now?...
â±ï¸ [TIMING] LLM_TOTAL: 875ms for 271 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (1.52s): [N] Twenty thousand in savings gives you plenty of flexibility to get a few sites up and running. Just to understand a bit better, is there a specific reason you're looking to make a change or explore something like this right now, as opposed to say, six months from now?
Total latency: 1.52s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] Twenty thousand in savings gives you plenty of flexibility to get a few sites up and running. Just to understand a bit better, is there a specific reason you're looking to make a change or explore...

============================================================
ğŸ¤ TURN 17: User says: "User: No, it's just me making the decisions."
============================================================
â±ï¸ [20:08:07.400] ğŸ“¥ process_user_input() ENTRY - text: 'User: No, it's just me making the decisions....'
â±ï¸ [20:08:07.400] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:07.400] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:07.400] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 15, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [20:08:07.400] ğŸ”€ About to call _follow_transition() for: User: No, it's just me making ...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: No, it's just me making the decisions.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:07.444] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:07.861] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 417ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: To ask the "Why now?" question and then use assertive, frame-controlling tactics to handle any defer...
â±ï¸ [TIMING] TRANSITION_EVAL: 460ms
â±ï¸ [20:08:07.861] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [20:08:07.861] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/15 messages)
â±ï¸ [20:08:07.904] ğŸ’¬ LLM REQUEST START: 15 conversation turns, 12692 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5606 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 8, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Twenty thousand in savings gives you plenty of flexibility to get a few sites up and running. Ju...
ğŸ“   user: User: No, it's just me making the decisions....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:08.420] ğŸ’¬ LLM FIRST TOKEN: 516ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Got it,
ğŸ“¤ Streamed sentence: [N] Got it,...
    ğŸ”Š TTS: so you're the one calling the shots here.
ğŸ“¤ Streamed sentence: so you're the one calling the shots here....
    ğŸ”Š TTS: Exploring is smart,
ğŸ“¤ Streamed sentence: Exploring is smart,...
    ğŸ”Š TTS: but let me ask you this: when you picture things six months from now,
ğŸ“¤ Streamed sentence: but let me ask you this: when you picture things s...
    ğŸ”Š TTS: do you see yourself in the exact same spot financially,
ğŸ“¤ Streamed sentence: do you see yourself in the exact same spot financi...
    ğŸ”Š TTS: or have you taken action on something to change that?
ğŸ“¤ Streamed final fragment: or have you taken action on something to change th...
â±ï¸ [TIMING] LLM_TOTAL: 994ms for 253 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (1.50s): [N] Got it, so you're the one calling the shots here. Exploring is smart, but let me ask you this: when you picture things six months from now, do you see yourself in the exact same spot financially, or have you taken action on something to change that?
Total latency: 1.50s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] Got it, so you're the one calling the shots here. Exploring is smart, but let me ask you this: when you picture things six months from now, do you see yourself in the exact same spot financially, ...

============================================================
ğŸ¤ TURN 19: User says: "User: I can probably deduce about 10 hours a week."
============================================================
â±ï¸ [20:08:09.400] ğŸ“¥ process_user_input() ENTRY - text: 'User: I can probably deduce about 10 hours a week....'
â±ï¸ [20:08:09.400] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:09.400] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:09.400] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 17, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [20:08:09.400] ğŸ”€ About to call _follow_transition() for: User: I can probably deduce ab...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: I can probably deduce about 10 hours a week.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:09.444] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:09.883] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 438ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: 0
Transition: N401_AskWhyNow_Initial_V10_AssertiveFrame -> N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
â±ï¸ [TIMING] TRANSITION_EVAL: 483ms
â±ï¸ [20:08:09.883] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned (type: conversation, mode: prompt)
â±ï¸ [20:08:09.884] ğŸ“„ About to process content (mode=prompt, length=1863)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/17 messages)
â±ï¸ [20:08:09.929] ğŸ’¬ LLM REQUEST START: 17 conversation turns, 9888 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (2802 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 9, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Got it, so you're the one calling the shots here. Exploring is smart, but let me ask you this: w...
ğŸ“   user: User: I can probably deduce about 10 hours a week....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:10.560] ğŸ’¬ LLM FIRST TOKEN: 631ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Ten hours a week is a realistic commitment for someone in your positionâ€”enou...
ğŸ“¤ Streamed sentence: [N] Ten hours a week is a realistic commitment for...
    ğŸ”Š TTS: You know,
ğŸ“¤ Streamed sentence: You know,...
    ğŸ”Š TTS: that's actually refreshing to hear.
ğŸ“¤ Streamed sentence: that's actually refreshing to hear....
    ğŸ”Š TTS: You know why?
ğŸ“¤ Streamed final fragment: You know why?...
â±ï¸ [TIMING] LLM_TOTAL: 957ms for 196 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198047712 in conversation history
LLM response (1.49s): [N] Ten hours a week is a realistic commitment for someone in your positionâ€”enough to build momentum without overwhelming your schedule. You know, that's actually refreshing to hear. You know why?
Total latency: 1.49s

   ğŸ“ NODE: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
   ğŸ¤– RESPONSE: [N] Ten hours a week is a realistic commitment for someone in your positionâ€”enough to build momentum without overwhelming your schedule. You know, that's actually refreshing to hear. You know why?

============================================================
ğŸ¤ TURN 21: User says: "User: My credit is good, around 750."
============================================================
â±ï¸ [20:08:11.388] ğŸ“¥ process_user_input() ENTRY - text: 'User: My credit is good, around 750....'
â±ï¸ [20:08:11.388] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:11.388] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:11.388] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 19, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198047712
â±ï¸ [20:08:11.388] ğŸ”€ About to call _follow_transition() for: User: My credit is good, aroun...
Evaluating transitions from N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned for message: User: My credit is good, around 750.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:11.434] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:11.716] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 281ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['The User responds with anything - take their respo...', 'The user says they have to go. - Call them back - ...']
Selected transition index: 0
Transition: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned -> N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
â±ï¸ [TIMING] TRANSITION_EVAL: 327ms
â±ï¸ [20:08:11.716] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned (type: conversation, mode: prompt)
â±ï¸ [20:08:11.716] ğŸ“„ About to process content (mode=prompt, length=4458)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/19 messages)
â±ï¸ [20:08:11.761] ğŸ’¬ LLM REQUEST START: 19 conversation turns, 12484 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5398 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 10, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Ten hours a week is a realistic commitment for someone in your positionâ€”enough to build momentum...
ğŸ“   user: User: My credit is good, around 750....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:12.152] ğŸ’¬ LLM FIRST TOKEN: 390ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] A 750 credit score is excellentâ€”that opens doors for any financing if needed...
ğŸ“¤ Streamed sentence: [N] A 750 credit score is excellentâ€”that opens doo...
    ğŸ”Š TTS: You know,
ğŸ“¤ Streamed sentence: You know,...
    ğŸ”Š TTS: that's actually refreshing to hear.
ğŸ“¤ Streamed sentence: that's actually refreshing to hear....
    ğŸ”Š TTS: You know why?
ğŸ“¤ Streamed final fragment: You know why?...
â±ï¸ [TIMING] LLM_TOTAL: 654ms for 155 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198201369 in conversation history
LLM response (1.03s): [N] A 750 credit score is excellentâ€”that opens doors for any financing if needed down the line. You know, that's actually refreshing to hear. You know why?
Total latency: 1.03s

   ğŸ“ NODE: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
   ğŸ¤– RESPONSE: [N] A 750 credit score is excellentâ€”that opens doors for any financing if needed down the line. You know, that's actually refreshing to hear. You know why?

============================================================
ğŸ¤ TURN 25: User says: "User: That makes sense. I see why you called."
============================================================
â±ï¸ [20:08:12.917] ğŸ“¥ process_user_input() ENTRY - text: 'User: That makes sense. I see why you called....'
â±ï¸ [20:08:12.918] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:12.918] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:12.918] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 21, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198201369
â±ï¸ [20:08:12.918] ğŸ”€ About to call _follow_transition() for: User: That makes sense. I see ...
Evaluating transitions from N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned for message: User: That makes sense. I see why you called.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:12.962] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:13.224] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 261ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['The User responds saying yes to some relevant valu...', 'The user says they have to go....']
Selected transition index: 0
Transition: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned -> N500A_ProposeDeeperDive_V5_Adaptive
â±ï¸ [TIMING] TRANSITION_EVAL: 306ms
â±ï¸ [20:08:13.224] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500A_ProposeDeeperDive_V5_Adaptive (type: conversation, mode: prompt)
â±ï¸ [20:08:13.224] ğŸ“„ About to process content (mode=prompt, length=4127)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500A_ProposeDeeperDive_V5_Adaptive': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/21 messages)
â±ï¸ [20:08:13.269] ğŸ’¬ LLM REQUEST START: 21 conversation turns, 12153 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5067 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 11, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] A 750 credit score is excellentâ€”that opens doors for any financing if needed down the line. You ...
ğŸ“   user: User: That makes sense. I see why you called....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:13.838] ğŸ’¬ LLM FIRST TOKEN: 568ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Glad it's clicking for you.
ğŸ“¤ Streamed sentence: [N] Glad it's clicking for you....
    ğŸ”Š TTS: To make sure we tailor this right for your situation,
ğŸ“¤ Streamed sentence: To make sure we tailor this right for your situati...
    ğŸ”Š TTS: would you be open to hopping on a quick strategy call with our senior consultant...
ğŸ“¤ Streamed sentence: would you be open to hopping on a quick strategy c...
    ğŸ”Š TTS: It'll outline exactly how to get those lead gen sites built and monetized withou...
ğŸ“¤ Streamed final fragment: It'll outline exactly how to get those lead gen si...
â±ï¸ [TIMING] LLM_TOTAL: 1144ms for 273 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198305881 in conversation history
LLM response (1.50s): [N] Glad it's clicking for you. To make sure we tailor this right for your situation, would you be open to hopping on a quick strategy call with our senior consultant Kendrick? It'll outline exactly how to get those lead gen sites built and monetized without the guesswork.
Total latency: 1.50s

   ğŸ“ NODE: N500A_ProposeDeeperDive_V5_Adaptive
   ğŸ¤– RESPONSE: [N] Glad it's clicking for you. To make sure we tailor this right for your situation, would you be open to hopping on a quick strategy call with our senior consultant Kendrick? It'll outline exactly h...

============================================================
ğŸ¤ TURN 28: User says: "User: I am in Eastern time."
============================================================
â±ï¸ [20:08:14.915] ğŸ“¥ process_user_input() ENTRY - text: 'User: I am in Eastern time....'
â±ï¸ [20:08:14.915] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:14.915] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:14.915] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 23, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198305881
â±ï¸ [20:08:14.915] ğŸ”€ About to call _follow_transition() for: User: I am in Eastern time....
Evaluating transitions from N500A_ProposeDeeperDive_V5_Adaptive for message: User: I am in Eastern time.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:14.959] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:15.412] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 452ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ['Prospect agrees that setting up another call "soun...']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: Simply ask them if they want to set up and appointment - do not offer an appointment or try to sched...
â±ï¸ [TIMING] TRANSITION_EVAL: 497ms
â±ï¸ [20:08:15.413] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500A_ProposeDeeperDive_V5_Adaptive (type: conversation, mode: prompt)
â±ï¸ [20:08:15.413] ğŸ“„ About to process content (mode=prompt, length=4127)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500A_ProposeDeeperDive_V5_Adaptive': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/23 messages)
â±ï¸ [20:08:15.457] ğŸ’¬ LLM REQUEST START: 23 conversation turns, 12153 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5067 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 12, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Glad it's clicking for you. To make sure we tailor this right for your situation, would you be o...
ğŸ“   user: User: I am in Eastern time....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:15.947] ğŸ’¬ LLM FIRST TOKEN: 490ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Eastern time works perfectly since that's where we're based too.
ğŸ“¤ Streamed sentence: [N] Eastern time works perfectly since that's wher...
    ğŸ”Š TTS: So,
ğŸ“¤ Streamed sentence: So,...
    ğŸ”Š TTS: to get you that custom strategy session with Kendrick,
ğŸ“¤ Streamed sentence: to get you that custom strategy session with Kendr...
    ğŸ”Š TTS: are you open to scheduling it for a time that fits your week?
ğŸ“¤ Streamed final fragment: are you open to scheduling it for a time that fits...
â±ï¸ [TIMING] LLM_TOTAL: 823ms for 189 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198305881 in conversation history
LLM response (1.37s): [N] Eastern time works perfectly since that's where we're based too. So, to get you that custom strategy session with Kendrick, are you open to scheduling it for a time that fits your week?
Total latency: 1.37s

   ğŸ“ NODE: N500A_ProposeDeeperDive_V5_Adaptive
   ğŸ¤– RESPONSE: [N] Eastern time works perfectly since that's where we're based too. So, to get you that custom strategy session with Kendrick, are you open to scheduling it for a time that fits your week?

============================================================
ğŸ¤ TURN 32: User says: "User: Sure, Tuesday at 2pm works for me."
============================================================
â±ï¸ [20:08:16.782] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sure, Tuesday at 2pm works for me....'
â±ï¸ [20:08:16.782] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:16.782] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:16.782] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 25, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198305881
â±ï¸ [20:08:16.782] ğŸ”€ About to call _follow_transition() for: User: Sure, Tuesday at 2pm wor...
Evaluating transitions from N500A_ProposeDeeperDive_V5_Adaptive for message: User: Sure, Tuesday at 2pm works for me.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:16.829] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:17.211] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 382ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Prospect agrees that setting up another call "soun...']
Selected transition index: 0
Transition: N500A_ProposeDeeperDive_V5_Adaptive -> N500B_AskTimezone_V2_FullyTuned
â±ï¸ [TIMING] TRANSITION_EVAL: 429ms
â±ï¸ [20:08:17.212] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500B_AskTimezone_V2_FullyTuned (type: conversation, mode: prompt)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [20:08:17.212] ğŸ“„ About to process content (mode=prompt, length=1398)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500B_AskTimezone_V2_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/25 messages)
â±ï¸ [20:08:17.331] ğŸ’¬ LLM REQUEST START: 25 conversation turns, 9424 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (2338 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 13, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Eastern time works perfectly since that's where we're based too. So, to get you that custom stra...
ğŸ“   user: User: Sure, Tuesday at 2pm works for me....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:17.707] ğŸ’¬ LLM FIRST TOKEN: 376ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Perfect,
ğŸ“¤ Streamed sentence: [N] Perfect,...
    ğŸ”Š TTS: Tuesday at 2pm Eastern.
ğŸ“¤ Streamed sentence: Tuesday at 2pm Eastern....
    ğŸ”Š TTS: Let me check the calendar for that time real quick.
ğŸ“¤ Streamed sentence: Let me check the calendar for that time real quick...
    ğŸ”Š TTS: One second.
ğŸ“¤ Streamed final fragment: One second....
â±ï¸ [TIMING] LLM_TOTAL: 481ms for 100 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198398056 in conversation history
LLM response (1.03s): [N] Perfect, Tuesday at 2pm Eastern. Let me check the calendar for that time real quick. One second.
Total latency: 1.03s

   ğŸ“ NODE: N500B_AskTimezone_V2_FullyTuned
   ğŸ¤– RESPONSE: [N] Perfect, Tuesday at 2pm Eastern. Let me check the calendar for that time real quick. One second.

============================================================
ğŸ¤ TURN 35: User says: "User: Sounds great, lock it in!"
============================================================
â±ï¸ [20:08:18.313] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sounds great, lock it in!...'
â±ï¸ [20:08:18.313] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:18.313] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:18.313] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 27, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198398056
ğŸ” PRE-TRANSITION: Extracting mandatory vars on CURRENT node N500B_AskTimezone_V2_FullyTuned before transition
ğŸ” Real-time extraction: Processing 3 variables
ğŸ¤– Using configured LLM provider: grok (grok-4-fast-non-reasoning) for extraction
Failed to decrypt key, assuming unencrypted: 
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
  âœ“ timeZone: Eastern time (extracted in real-time)
  âœ“ scheduleTime: Tuesday at 2pm (extracted in real-time)
  âœ“ amPm: pm (extracted in real-time)
âœ… Real-time extraction complete: 3 variables
âœ… PRE-TRANSITION: All mandatory vars satisfied on N500B_AskTimezone_V2_FullyTuned - proceeding with transition
â±ï¸ [20:08:18.745] ğŸ”€ About to call _follow_transition() for: User: Sounds great, lock it in...
Evaluating transitions from N500B_AskTimezone_V2_FullyTuned for message: User: Sounds great, lock it in!
ğŸ” Transition 0 requires variable checks: ['scheduleTime', 'timeZone', 'amPm']
  âœ… All required variables present for transition 0
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:18.828] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:19.279] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 450ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['The user has provided their timezone OR the user c...']
Selected transition index: 0
Transition: N500B_AskTimezone_V2_FullyTuned -> Calendar-check
â±ï¸ [TIMING] TRANSITION_EVAL: 533ms
â±ï¸ [20:08:19.279] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
ğŸ”§ Replaced {{timeZone}} with Eastern time in content
ğŸ”§ Replaced {{scheduleTime}} with Tuesday at 2pm in content
ğŸ”§ Replaced {{amPm}} with pm in content
ğŸ” Auto-detected SCRIPT mode (no instruction markers, length: 0 chars)
Using flow node: Calendar-check (type: function, mode: script)
ğŸ”§ Function/Webhook node reached - executing webhook
â³ Waiting for webhook to complete before transitioning...
ğŸŒ Calling webhook: POST https://n8n.outlier-agency.com/webhook/45d79a22-2266-4596-ae1f-1354e2a98675
ğŸ“‹ Detected JSON schema format - building request from extracted variables
âš ï¸ Variable 'customer_email' not found in extracted variables
ğŸ“¤ Request body: {
  "scheduleTime": "Tuesday at 2pm",
  "timeZone": "Eastern time",
  "customer_email": null,
  "callerName": "",
  "to_number": "+17708336397",
  "customer_name": "Kendrick"
}...
HTTP Request: POST https://n8n.outlier-agency.com/webhook/45d79a22-2266-4596-ae1f-1354e2a98675 "HTTP/1.1 200 OK"
âœ… Webhook response: 200
ğŸ“¥ Response text: {
  "results": [
    {
      "toolCallId": "2600:1700:3280:1d10:34df:82ae:f4ed:1ea2",
      "result": "Apologize to them, and tell them their time isn't available. The available time slots are Sunday ...
ğŸ“¥ Response data: {
  "results": [
    {
      "toolCallId": "2600:1700:3280:1d10:34df:82ae:f4ed:1ea2",
      "result": "Apologize to them, and tell them their time isn't available. The available time slots are Sunday at eleven fifteen AM, Sunday at twelve o'clock PM, or Sunday at one fifteen PM. Then ask them what w...
ğŸ’¾ Stored webhook response in variable: webhook_response2
ğŸ”„ Extracting fields from webhook response to update session variables...
Response data keys: ['results']
  âœ“ Updated session variable: results = [{'toolCallId': '2600:1700:3280:1d10:34df:82ae:f4ed:1ea2', 'result': "Apologize to them, and tell them their time isn't available. The available time slots are Sunday at eleven fifteen AM, Sunday at twelve o'clock PM, or Sunday at one fifteen PM. Then ask them what works for them. The full list of time slots in case they ask for something else:    "}]
âœ… Updated 1 session variables from webhook response
ğŸ”€ Evaluating transition for function node with webhook response...
Failed to decrypt key, assuming unencrypted: 
ğŸ”§ Function node detected - including webhook response in transition evaluation
ğŸ“¦ Webhook response data for transition: {"results": [{"toolCallId": "2600:1700:3280:1d10:34df:82ae:f4ed:1ea2", "result": "Apologize to them, and tell them their time isn't available. The available time slots are Sunday at eleven fifteen AM,...
â±ï¸ [20:08:31.883] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:32.284] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 400ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['After webhook completes - The time was not availab...', 'The time is available and was booked....']
Selected transition index: 0
Transition: Calendar-check -> N_Scheduling_RescheduleAndHandle_V5_FullyTuned
ğŸ“ Function node recursion: Updated current_node to N_Scheduling_RescheduleAndHandle_V5_FullyTuned
ğŸ“‹ Processing node streaming - Type: conversation, Mode: prompt, Content length: 1029 chars
ğŸ¤– Using PROMPT mode - will generate AI response
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:08:32.327] ğŸ’¬ LLM REQUEST START: 27 conversation turns, 9886 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (2800 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: I type - adjust your response accordingly
CONVERSATION STATUS: Turn 14, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (27 messages)
ğŸ“   assistant: [N] Perfect, Tuesday at 2pm Eastern. Let me check the calendar for that time real quick. One second....
ğŸ“   user: User: Sounds great, lock it in!...
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:32.740] ğŸ’¬ LLM FIRST TOKEN: 412ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Hold on,
ğŸ“¤ Streamed sentence: [N] Hold on,...
    ğŸ”Š TTS: I just checked the calendar,
ğŸ“¤ Streamed sentence: I just checked the calendar,...
    ğŸ”Š TTS: and Tuesday at 2pm isn't available anymoreâ€”sorry about that mix-up.
ğŸ“¤ Streamed sentence: and Tuesday at 2pm isn't available anymoreâ€”sorry a...
    ğŸ”Š TTS: The open slots we have right now are Sunday at eleven fifteen AM,
ğŸ“¤ Streamed sentence: The open slots we have right now are Sunday at ele...
    ğŸ”Š TTS: Sunday at twelve o'clock PM,
ğŸ“¤ Streamed sentence: Sunday at twelve o'clock PM,...
    ğŸ”Š TTS: or Sunday at one fifteen PM Eastern.
ğŸ“¤ Streamed sentence: or Sunday at one fifteen PM Eastern....
    ğŸ”Š TTS: Which one of those works best for you?
ğŸ“¤ Streamed final fragment: Which one of those works best for you?...
â±ï¸ [TIMING] LLM_TOTAL: 829ms for 280 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763200225645 in conversation history
LLM response (14.84s): [N] Hold on, I just checked the calendar, and Tuesday at 2pm isn't available anymoreâ€”sorry about that mix-up. The open slots we have right now are Sunday at eleven fifteen AM, Sunday at twelve o'clock PM, or Sunday at one fifteen PM Eastern. Which one of those works best for you?
Total latency: 14.84s

   ğŸ“ NODE: N_Scheduling_RescheduleAndHandle_V5_FullyTuned
   ğŸ¤– RESPONSE: [N] Hold on, I just checked the calendar, and Tuesday at 2pm isn't available anymoreâ€”sorry about that mix-up. The open slots we have right now are Sunday at eleven fifteen AM, Sunday at twelve o'clock...

============================================================
ğŸ¤ TURN 36: User says: "Great, bye."
============================================================
â±ï¸ [20:08:33.658] ğŸ“¥ process_user_input() ENTRY - text: 'Great, bye....'
â±ï¸ [20:08:33.658] â© About to call _process_call_flow_streaming()
â±ï¸ [20:08:33.658] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:08:33.658] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 29, Is first: False
ğŸ” Using explicitly set current_node_id: 1763200225645
ğŸ” PRE-TRANSITION: Extracting mandatory vars on CURRENT node N_Scheduling_RescheduleAndHandle_V5_FullyTuned before transition
ğŸ” Real-time extraction: Processing 2 variables
  ğŸ”„ scheduleTime: Cleared for update (was: Tuesday at 2pm)
  ğŸ”„ amPm: Cleared for update (was: pm)
ğŸ¤– Using configured LLM provider: grok (grok-4-fast-non-reasoning) for extraction
Failed to decrypt key, assuming unencrypted: 
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
âœ… Real-time extraction complete: 2 variables
âš ï¸ Mandatory variable missing: scheduleTime
âš ï¸ Mandatory variable missing: amPm
ğŸš« 2 mandatory variables missing, generating reprompt
ğŸ“ Using prompt message: Get a day and time from them.
Failed to decrypt key, assuming unencrypted: 
HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
âœ… Generated reprompt: What day and time work best for you to discuss this further?...
âš ï¸ PRE-TRANSITION: Mandatory vars still missing - BLOCKING transition, staying on N_Scheduling_RescheduleAndHandle_V5_FullyTuned
â±ï¸ [20:08:36.625] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:08 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
ğŸ”§ Replaced {{timeZone}} with Eastern time in content
ğŸ”§ Replaced {{webhook_response2}} with {'results': [{'toolCallId': '2600:1700:3280:1d10:34df:82ae:f4ed:1ea2', 'result': "Apologize to them, and tell them their time isn't available. The available time slots are Sunday at eleven fifteen AM, Sunday at twelve o'clock PM, or Sunday at one fifteen PM. Then ask them what works for them. The full list of time slots in case they ask for something else:    "}]} in content
ğŸ”§ Replaced {{results}} with [{'toolCallId': '2600:1700:3280:1d10:34df:82ae:f4ed:1ea2', 'result': "Apologize to them, and tell them their time isn't available. The available time slots are Sunday at eleven fifteen AM, Sunday at twelve o'clock PM, or Sunday at one fifteen PM. Then ask them what works for them. The full list of time slots in case they ask for something else:    "}] in content
Using flow node: N_Scheduling_RescheduleAndHandle_V5_FullyTuned (type: conversation, mode: prompt)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [20:08:36.625] ğŸ“„ About to process content (mode=prompt, length=1713)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N_Scheduling_RescheduleAndHandle_V5_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/29 messages)
â±ï¸ [20:08:36.666] ğŸ’¬ LLM REQUEST START: 29 conversation turns, 10522 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (3436 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: I type - adjust your response accordingly
CONVERSATION STATUS: Turn 15, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:08 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Hold on, I just checked the calendar, and Tuesday at 2pm isn't available anymoreâ€”sorry about tha...
ğŸ“   user: Great, bye....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:08:37.460] ğŸ’¬ LLM FIRST TOKEN: 793ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] I get it if you're wrapping up,
ğŸ“¤ Streamed sentence: [N] I get it if you're wrapping up,...
    ğŸ”Š TTS: but before we end,
ğŸ“¤ Streamed sentence: but before we end,...
    ğŸ”Š TTS: just to make sure we're goodâ€”does one of those Sunday slots work,
ğŸ“¤ Streamed sentence: just to make sure we're goodâ€”does one of those Sun...
    ğŸ”Š TTS: or should I look into next week for you?
ğŸ“¤ Streamed final fragment: or should I look into next week for you?...
â±ï¸ [TIMING] LLM_TOTAL: 1320ms for 161 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200758 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763200225645 in conversation history
LLM response (4.33s): [N] I get it if you're wrapping up, but before we end, just to make sure we're goodâ€”does one of those Sunday slots work, or should I look into next week for you?
Total latency: 4.33s

   ğŸ“ NODE: N_Scheduling_RescheduleAndHandle_V5_FullyTuned
   ğŸ¤– RESPONSE: [N] I get it if you're wrapping up, but before we end, just to make sure we're goodâ€”does one of those Sunday slots work, or should I look into next week for you?

============================================================
ğŸ“Š SCRIPT COMPLETE - NODE HISTORY:
============================================================
  Turn 5: Greeting
  Turn 6: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
  Turn 7: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
  Turn 8: N_IntroduceModel_And_AskQuestions_V3_Adaptive
  Turn 9: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
  Turn 13: N_AskCapital_5k_V1_Adaptive
  Turn 15: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 17: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 19: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
  Turn 21: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
  Turn 25: N500A_ProposeDeeperDive_V5_Adaptive
  Turn 28: N500A_ProposeDeeperDive_V5_Adaptive
  Turn 32: N500B_AskTimezone_V2_FullyTuned
  Turn 35: N_Scheduling_RescheduleAndHandle_V5_FullyTuned
  Turn 36: N_Scheduling_RescheduleAndHandle_V5_FullyTuned

âœ… Loaded agent: JK First Caller-optimizer3-antigrav
   Model: grok-4-fast-non-reasoning
âœ… Loaded agent: JK First Caller-optimizer3-antigrav
   Model: grok-4-fast-non-reasoning
   Flow nodes: 66
âš ï¸ Could not import RAG service: Read-only file system (os error 30)
ğŸ“‹ Built cached system prompt: 5684 chars (global) + 1402 chars (technical)
ğŸ’‰ Injecting custom variables: {'customer_name': 'Kendrick', 'email': 'kendrickbowman9@gmail.com'}
âœ… Session initialized

============================================================
ğŸ“œ RUNNING SCRIPTED CONVERSATION
============================================================


============================================================
ğŸ¤ TURN 5: User says: "User: Hello?"
============================================================
â±ï¸ [19:25:34.095] ğŸ“¥ process_user_input() ENTRY - text: 'User: Hello?...'
â±ï¸ [19:25:34.095] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:34.095] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:34.095] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 1, Is first: True
â±ï¸ [19:25:34.095] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 9 chars) - will return text instantly
Using flow node: Greeting (type: conversation, mode: script)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [19:25:34.095] ğŸ“„ About to process content (mode=script, length=9)
ğŸ“¤ Streaming script as 1 sentence(s)
    ğŸ”Š TTS: Kendrick?
ğŸ“¤ Streamed script sentence 1/1: Kendrick?...
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 2 in conversation history
LLM response (0.00s): Kendrick?
Total latency: 0.00s

   ğŸ“ NODE: Greeting
   ğŸ¤– RESPONSE: Kendrick?

============================================================
ğŸ¤ TURN 6: User says: "User: Yes, this is Kendrick."
============================================================
â±ï¸ [19:25:34.595] ğŸ“¥ process_user_input() ENTRY - text: 'User: Yes, this is Kendrick....'
â±ï¸ [19:25:34.595] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:34.595] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:34.595] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 3, Is first: False
ğŸ” Using explicitly set current_node_id: 2
â±ï¸ [19:25:34.595] ğŸ”€ About to call _follow_transition() for: User: Yes, this is Kendrick....
Evaluating transitions from Greeting for message: User: Yes, this is Kendrick.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:34.639] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 3 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:35.125] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 486ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Confirms name (Yes|Speaking|This is he/she|etc)...', 'Wrong number (No John here|Wrong number|etc) - don...', 'Does not conform (Any other response / Resistance)...']
Selected transition index: 0
Transition: Greeting -> Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
â±ï¸ [TIMING] TRANSITION_EVAL: 529ms
â±ï¸ [19:25:35.125] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 89 chars) - will return text instantly
Using flow node: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation) (type: conversation, mode: script)
â±ï¸ [19:25:35.125] ğŸ“„ About to process content (mode=script, length=89)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: This is Jake...
ğŸ“¤ Streamed script sentence 1/2: This is Jake......
    ğŸ”Š TTS: I was just, um, wondering if you could possibly help me out for a moment?
ğŸ“¤ Streamed script sentence 2/2: I was just, um, wondering if you could possibly he...
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763159750250 in conversation history
LLM response (0.53s): This is Jake... I was just, um, wondering if you could possibly help me out for a moment?
Total latency: 0.53s

   ğŸ“ NODE: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
   ğŸ¤– RESPONSE: This is Jake... I was just, um, wondering if you could possibly help me out for a moment?

============================================================
ğŸ¤ TURN 7: User says: "User: Sure, what is this about?"
============================================================
â±ï¸ [19:25:35.627] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sure, what is this about?...'
â±ï¸ [19:25:35.628] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:35.628] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:35.628] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 5, Is first: False
ğŸ” Using explicitly set current_node_id: 1763159750250
â±ï¸ [19:25:35.628] ğŸ”€ About to call _follow_transition() for: User: Sure, what is this about...
Evaluating transitions from Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation) for message: User: Sure, what is this about?
ğŸ¤ AUTO-TRANSITION AFTER RESPONSE enabled - user spoke, transitioning to: 1763161849799
âœ… Auto-transitioned (after response) to: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
ğŸ“ User's response captured: 'User: Sure, what is this about?...'
â±ï¸ [TIMING] TRANSITION_EVAL: 0ms
â±ï¸ [19:25:35.628] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 260 chars) - will return text instantly
Using flow node: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic (type: conversation, mode: script)
â±ï¸ [19:25:35.628] ğŸ“„ About to process content (mode=script, length=260)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: Well, uh, I don't know if you could yet, but, I'm calling because you filled out...
ğŸ“¤ Streamed script sentence 1/2: Well, uh, I don't know if you could yet, but, I'm ...
    ğŸ”Š TTS: I know this call is out of the blue, but do you have just 25 seconds for me to e...
ğŸ“¤ Streamed script sentence 2/2: I know this call is out of the blue, but do you ha...
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763161849799 in conversation history
LLM response (0.00s): Well, uh, I don't know if you could yet, but, I'm calling because you filled out an ad about stacking income without stacking hours. I know this call is out of the blue, but do you have just 25 seconds for me to explain why I'm reaching out today specifically?
Total latency: 0.00s

   ğŸ“ NODE: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
   ğŸ¤– RESPONSE: Well, uh, I don't know if you could yet, but, I'm calling because you filled out an ad about stacking income without stacking hours. I know this call is out of the blue, but do you have just 25 second...

============================================================
ğŸ¤ TURN 8: User says: "User: That sounds interesting."
============================================================
â±ï¸ [19:25:36.130] ğŸ“¥ process_user_input() ENTRY - text: 'User: That sounds interesting....'
â±ï¸ [19:25:36.130] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:36.130] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:36.130] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 7, Is first: False
ğŸ” Using explicitly set current_node_id: 1763161849799
â±ï¸ [19:25:36.130] ğŸ”€ About to call _follow_transition() for: User: That sounds interesting....
Evaluating transitions from Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic for message: User: That sounds interesting.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:36.184] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 4 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:36.522] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 338ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Agrees|consents (yes|sure|okay|hear more|call cons...', 'Any objection or non compliance that isn\'t a "I do...', 'NO (flat out)|No recall (done quickly) AND no othe...', "I'm Busy, or requests to call back responses from ..."]
Selected transition index: 0
Transition: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic -> N_IntroduceModel_And_AskQuestions_V3_Adaptive
â±ï¸ [TIMING] TRANSITION_EVAL: 391ms
â±ï¸ [19:25:36.522] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 164 chars) - will return text instantly
Using flow node: N_IntroduceModel_And_AskQuestions_V3_Adaptive (type: conversation, mode: script)
â±ï¸ [19:25:36.523] ğŸ“„ About to process content (mode=script, length=164)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: Okay, in a nutshell, we set up passive income websites, and we let them produce ...
ğŸ“¤ Streamed script sentence 1/2: Okay, in a nutshell, we set up passive income webs...
    ğŸ”Š TTS: What questions come to mind as soon as you hear something like that?
ğŸ“¤ Streamed script sentence 2/2: What questions come to mind as soon as you hear so...
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763163400676 in conversation history
LLM response (0.39s): Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What questions come to mind as soon as you hear something like that?
Total latency: 0.39s

   ğŸ“ NODE: N_IntroduceModel_And_AskQuestions_V3_Adaptive
   ğŸ¤– RESPONSE: Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What questions come to mind as soon as you hear something like that?

============================================================
ğŸ¤ TURN 9: User says: "User: I work in software sales."
============================================================
â±ï¸ [19:25:37.024] ğŸ“¥ process_user_input() ENTRY - text: 'User: I work in software sales....'
â±ï¸ [19:25:37.025] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:37.025] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:37.025] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 9, Is first: False
ğŸ” Using explicitly set current_node_id: 1763163400676
â±ï¸ [19:25:37.025] ğŸ”€ About to call _follow_transition() for: User: I work in software sales...
Evaluating transitions from N_IntroduceModel_And_AskQuestions_V3_Adaptive for message: User: I work in software sales.
ğŸ¤ AUTO-TRANSITION AFTER RESPONSE enabled - user spoke, transitioning to: 1763206946898
âœ… Auto-transitioned (after response) to: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
ğŸ“ User's response captured: 'User: I work in software sales....'
â±ï¸ [TIMING] TRANSITION_EVAL: 0ms
â±ï¸ [19:25:37.025] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive (type: conversation, mode: conversation)
ğŸ“š Q&A/KB node detected by label - skipping pre-response mandatory check, will check on transition
â±ï¸ [19:25:37.025] ğŸ“„ About to process content (mode=conversation, length=483)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N_KB_Q&A_With_StrategicNarrative_V3_Adaptive': use_parallel_llm=False
â±ï¸ [19:25:37.070] ğŸ’¬ LLM REQUEST START: 9 conversation turns, 8508 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (1422 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 5, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (9 messages)
ğŸ“   assistant: Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What...
ğŸ“   user: User: I work in software sales....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:37.566] ğŸ’¬ LLM FIRST TOKEN: 496ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Software sales is a solid fieldâ€”keeps you busy with quotas and all.
ğŸ“¤ Streamed sentence: [N] Software sales is a solid fieldâ€”keeps you busy...
    ğŸ”Š TTS: How does that tie into your interest in stacking income without adding more hour...
ğŸ“¤ Streamed final fragment: How does that tie into your interest in stacking i...
â±ï¸ [TIMING] LLM_TOTAL: 924ms for 154 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763206946898 in conversation history
LLM response (0.97s): [N] Software sales is a solid fieldâ€”keeps you busy with quotas and all. How does that tie into your interest in stacking income without adding more hours?
Total latency: 0.97s

   ğŸ“ NODE: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
   ğŸ¤– RESPONSE: [N] Software sales is a solid fieldâ€”keeps you busy with quotas and all. How does that tie into your interest in stacking income without adding more hours?

============================================================
ğŸ¤ TURN 13: User says: "User: I make about $120,000 a year base."
============================================================
â±ï¸ [19:25:38.496] ğŸ“¥ process_user_input() ENTRY - text: 'User: I make about $120,000 a year base....'
â±ï¸ [19:25:38.496] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:38.496] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:38.496] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 11, Is first: False
ğŸ” Using explicitly set current_node_id: 1763206946898
â±ï¸ [19:25:38.496] ğŸ”€ About to call _follow_transition() for: User: I make about $120,000 a ...
Evaluating transitions from N_KB_Q&A_With_StrategicNarrative_V3_Adaptive for message: User: I make about $120,000 a year base.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:38.535] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:38.988] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 452ms
ğŸ¤– AI transition decision: '1'
ğŸ“Š Available transitions: ['...would you honestly be upset if you had an extra...', 'User has answered income questions, provided finan...']
Selected transition index: 1
Transition: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive -> Logic Split - Income
â±ï¸ [TIMING] TRANSITION_EVAL: 492ms
â±ï¸ [19:25:38.988] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
ğŸ” Auto-detected PROMPT mode (instruction markers found)
Using flow node: Logic Split - Income (type: logic_split, mode: prompt)
ğŸ”€ Logic Split node reached - evaluating conditions
ğŸ”€ Evaluating 1 conditions
  Condition 1: amount_reference greater_than 8000
    Variable value: 
    Could not extract numbers: var=None, compare=8000.0
    Result: False
â„¹ï¸ No conditions matched - using default path: 1763197118793
âœ… Condition matched - moving to node: N_AskCapital_5k_V1_Adaptive
ğŸ“‹ Processing node streaming - Type: conversation, Mode: prompt, Content length: 921 chars
ğŸ¤– Using PROMPT mode - will generate AI response
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:39.033] ğŸ’¬ LLM REQUEST START: 11 conversation turns, 8946 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (1860 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 6, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (11 messages)
ğŸ“   assistant: [N] Software sales is a solid fieldâ€”keeps you busy with quotas and all. How does that tie into your ...
ğŸ“   user: User: I make about $120,000 a year base....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:39.571] ğŸ’¬ LLM FIRST TOKEN: 537ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] $120,000 base is impressiveâ€”puts you in a strong spot for scaling up.
ğŸ“¤ Streamed sentence: [N] $120,000 base is impressiveâ€”puts you in a stro...
    ğŸ”Š TTS: For this model,
ğŸ“¤ Streamed sentence: For this model,...
    ğŸ”Š TTS: we typically look for about five thousand dollars in liquid capital to get start...
ğŸ“¤ Streamed sentence: we typically look for about five thousand dollars ...
    ğŸ”Š TTS: Do you have that amount accessible right now?
ğŸ“¤ Streamed final fragment: Do you have that amount accessible right now?...
â±ï¸ [TIMING] LLM_TOTAL: 826ms for 219 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763197118793 in conversation history
LLM response (1.36s): [N] $120,000 base is impressiveâ€”puts you in a strong spot for scaling up. For this model, we typically look for about five thousand dollars in liquid capital to get started. Do you have that amount accessible right now?
Total latency: 1.36s

   ğŸ“ NODE: N_AskCapital_5k_V1_Adaptive
   ğŸ¤– RESPONSE: [N] $120,000 base is impressiveâ€”puts you in a strong spot for scaling up. For this model, we typically look for about five thousand dollars in liquid capital to get started. Do you have that amount ac...

============================================================
ğŸ¤ TURN 15: User says: "User: I have about $20,000 in savings right now."
============================================================
â±ï¸ [19:25:40.361] ğŸ“¥ process_user_input() ENTRY - text: 'User: I have about $20,000 in savings right now....'
â±ï¸ [19:25:40.361] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:40.361] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:40.361] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 13, Is first: False
ğŸ” Using explicitly set current_node_id: 1763197118793
â±ï¸ [19:25:40.361] ğŸ”€ About to call _follow_transition() for: User: I have about $20,000 in ...
Evaluating transitions from N_AskCapital_5k_V1_Adaptive for message: User: I have about $20,000 in savings right now.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:40.413] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:40.783] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 369ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ["If the user's response indicates they have the cap...", "They indicate they don't have at least $5k (ie, No..."]
Selected transition index: 0
Transition: N_AskCapital_5k_V1_Adaptive -> N401_AskWhyNow_Initial_V10_AssertiveFrame
â±ï¸ [TIMING] TRANSITION_EVAL: 421ms
â±ï¸ [19:25:40.783] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [19:25:40.784] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/13 messages)
â±ï¸ [19:25:40.835] ğŸ’¬ LLM REQUEST START: 13 conversation turns, 12692 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5606 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 7, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] $120,000 base is impressiveâ€”puts you in a strong spot for scaling up. For this model, we typical...
ğŸ“   user: User: I have about $20,000 in savings right now....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:42.136] ğŸ’¬ LLM FIRST TOKEN: 1301ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Twenty thousand in savings gives you solid flexibility there.
ğŸ“¤ Streamed sentence: [N] Twenty thousand in savings gives you solid fle...
    ğŸ”Š TTS: Just to understand a bit better,
ğŸ“¤ Streamed sentence: Just to understand a bit better,...
    ğŸ”Š TTS: is there a specific reason you're looking to make a change or explore something ...
ğŸ“¤ Streamed sentence: is there a specific reason you're looking to make ...
    ğŸ”Š TTS: as opposed to say,
ğŸ“¤ Streamed sentence: as opposed to say,...
    ğŸ”Š TTS: six months from now?
ğŸ“¤ Streamed final fragment: six months from now?...
â±ï¸ [TIMING] LLM_TOTAL: 1542ms for 239 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (2.02s): [N] Twenty thousand in savings gives you solid flexibility there. Just to understand a bit better, is there a specific reason you're looking to make a change or explore something like this right now, as opposed to say, six months from now?
Total latency: 2.02s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] Twenty thousand in savings gives you solid flexibility there. Just to understand a bit better, is there a specific reason you're looking to make a change or explore something like this right now, ...

============================================================
ğŸ¤ TURN 17: User says: "User: No, it's just me making the decisions."
============================================================
â±ï¸ [19:25:42.879] ğŸ“¥ process_user_input() ENTRY - text: 'User: No, it's just me making the decisions....'
â±ï¸ [19:25:42.879] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:42.879] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:42.879] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 15, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [19:25:42.879] ğŸ”€ About to call _follow_transition() for: User: No, it's just me making ...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: No, it's just me making the decisions.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:42.917] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:43.281] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 364ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: To ask the "Why now?" question and then use assertive, frame-controlling tactics to handle any defer...
â±ï¸ [TIMING] TRANSITION_EVAL: 402ms
â±ï¸ [19:25:43.282] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [19:25:43.282] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/15 messages)
â±ï¸ [19:25:43.321] ğŸ’¬ LLM REQUEST START: 15 conversation turns, 12692 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5606 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 8, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Twenty thousand in savings gives you solid flexibility there. Just to understand a bit better, i...
ğŸ“   user: User: No, it's just me making the decisions....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:43.737] ğŸ’¬ LLM FIRST TOKEN: 415ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Got it,
ğŸ“¤ Streamed sentence: [N] Got it,...
    ğŸ”Š TTS: so you're calling the shots on this one.
ğŸ“¤ Streamed sentence: so you're calling the shots on this one....
    ğŸ”Š TTS: Exploring options like this is smart,
ğŸ“¤ Streamed sentence: Exploring options like this is smart,...
    ğŸ”Š TTS: but let me ask you this: when you picture things six months from now,
ğŸ“¤ Streamed sentence: but let me ask you this: when you picture things s...
    ğŸ”Š TTS: do you see yourself in the exact same spot financially,
ğŸ“¤ Streamed sentence: do you see yourself in the exact same spot financi...
    ğŸ”Š TTS: or have you taken action on something to change that?
ğŸ“¤ Streamed final fragment: or have you taken action on something to change th...
â±ï¸ [TIMING] LLM_TOTAL: 808ms for 270 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (1.25s): [N] Got it, so you're calling the shots on this one. Exploring options like this is smart, but let me ask you this: when you picture things six months from now, do you see yourself in the exact same spot financially, or have you taken action on something to change that?
Total latency: 1.25s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] Got it, so you're calling the shots on this one. Exploring options like this is smart, but let me ask you this: when you picture things six months from now, do you see yourself in the exact same s...

============================================================
ğŸ¤ TURN 19: User says: "User: I can probably deduce about 10 hours a week."
============================================================
â±ï¸ [19:25:44.631] ğŸ“¥ process_user_input() ENTRY - text: 'User: I can probably deduce about 10 hours a week....'
â±ï¸ [19:25:44.632] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:44.632] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:44.632] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 17, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [19:25:44.632] ğŸ”€ About to call _follow_transition() for: User: I can probably deduce ab...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: I can probably deduce about 10 hours a week.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:44.689] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:45.130] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 440ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: 0
Transition: N401_AskWhyNow_Initial_V10_AssertiveFrame -> N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
â±ï¸ [TIMING] TRANSITION_EVAL: 498ms
â±ï¸ [19:25:45.130] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned (type: conversation, mode: prompt)
â±ï¸ [19:25:45.131] ğŸ“„ About to process content (mode=prompt, length=1863)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/17 messages)
â±ï¸ [19:25:45.181] ğŸ’¬ LLM REQUEST START: 17 conversation turns, 9888 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (2802 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 9, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Got it, so you're calling the shots on this one. Exploring options like this is smart, but let m...
ğŸ“   user: User: I can probably deduce about 10 hours a week....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:45.641] ğŸ’¬ LLM FIRST TOKEN: 459ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Ten hours a week is a realistic commitment for someone in your position.
ğŸ“¤ Streamed sentence: [N] Ten hours a week is a realistic commitment for...
    ğŸ”Š TTS: You know why that's actually a great starting point for building something susta...
ğŸ“¤ Streamed final fragment: You know why that's actually a great starting poin...
â±ï¸ [TIMING] LLM_TOTAL: 613ms for 164 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198047712 in conversation history
LLM response (1.16s): [N] Ten hours a week is a realistic commitment for someone in your position. You know why that's actually a great starting point for building something sustainable?
Total latency: 1.16s

   ğŸ“ NODE: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
   ğŸ¤– RESPONSE: [N] Ten hours a week is a realistic commitment for someone in your position. You know why that's actually a great starting point for building something sustainable?

============================================================
ğŸ¤ TURN 21: User says: "User: My credit is good, around 750."
============================================================
â±ï¸ [19:25:46.296] ğŸ“¥ process_user_input() ENTRY - text: 'User: My credit is good, around 750....'
â±ï¸ [19:25:46.296] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:46.296] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:46.296] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 19, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198047712
â±ï¸ [19:25:46.297] ğŸ”€ About to call _follow_transition() for: User: My credit is good, aroun...
Evaluating transitions from N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned for message: User: My credit is good, around 750.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:46.349] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:46.686] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 336ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['The User responds with anything - take their respo...', 'The user says they have to go. - Call them back - ...']
Selected transition index: 0
Transition: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned -> N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
â±ï¸ [TIMING] TRANSITION_EVAL: 389ms
â±ï¸ [19:25:46.687] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned (type: conversation, mode: prompt)
â±ï¸ [19:25:46.687] ğŸ“„ About to process content (mode=prompt, length=4458)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/19 messages)
â±ï¸ [19:25:46.748] ğŸ’¬ LLM REQUEST START: 19 conversation turns, 12484 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5398 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 10, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Ten hours a week is a realistic commitment for someone in your position. You know why that's act...
ğŸ“   user: User: My credit is good, around 750....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:47.417] ğŸ’¬ LLM FIRST TOKEN: 668ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] A 750 credit score is strongâ€”opens up options if needed down the line.
ğŸ“¤ Streamed sentence: [N] A 750 credit score is strongâ€”opens up options ...
    ğŸ”Š TTS: Building on that time commitment we discussed,
ğŸ“¤ Streamed sentence: Building on that time commitment we discussed,...
    ğŸ”Š TTS: does the idea of generating leads for local businesses through simple websites a...
ğŸ“¤ Streamed final fragment: does the idea of generating leads for local busine...
â±ï¸ [TIMING] LLM_TOTAL: 1040ms for 252 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198201369 in conversation history
LLM response (1.49s): [N] A 750 credit score is strongâ€”opens up options if needed down the line. Building on that time commitment we discussed, does the idea of generating leads for local businesses through simple websites appeal to you as a way to leverage those ten hours?
Total latency: 1.49s

   ğŸ“ NODE: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
   ğŸ¤– RESPONSE: [N] A 750 credit score is strongâ€”opens up options if needed down the line. Building on that time commitment we discussed, does the idea of generating leads for local businesses through simple websites...

============================================================
ğŸ¤ TURN 25: User says: "User: That makes sense. I see why you called."
============================================================
â±ï¸ [19:25:48.291] ğŸ“¥ process_user_input() ENTRY - text: 'User: That makes sense. I see why you called....'
â±ï¸ [19:25:48.291] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:48.291] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:48.291] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 21, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198201369
â±ï¸ [19:25:48.291] ğŸ”€ About to call _follow_transition() for: User: That makes sense. I see ...
Evaluating transitions from N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned for message: User: That makes sense. I see why you called.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:48.342] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:48.820] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 478ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['The User responds saying yes to some relevant valu...', 'The user says they have to go....']
Selected transition index: 0
Transition: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned -> N500A_ProposeDeeperDive_V5_Adaptive
â±ï¸ [TIMING] TRANSITION_EVAL: 529ms
â±ï¸ [19:25:48.820] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500A_ProposeDeeperDive_V5_Adaptive (type: conversation, mode: prompt)
â±ï¸ [19:25:48.821] ğŸ“„ About to process content (mode=prompt, length=4127)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500A_ProposeDeeperDive_V5_Adaptive': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/21 messages)
â±ï¸ [19:25:48.870] ğŸ’¬ LLM REQUEST START: 21 conversation turns, 12153 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5067 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 11, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] A 750 credit score is strongâ€”opens up options if needed down the line. Building on that time com...
ğŸ“   user: User: That makes sense. I see why you called....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:49.726] ğŸ’¬ LLM FIRST TOKEN: 855ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Glad it's clicking for you.
ğŸ“¤ Streamed sentence: [N] Glad it's clicking for you....
    ğŸ”Š TTS: The next step is setting up a quick strategy call with our senior consultant,
ğŸ“¤ Streamed sentence: The next step is setting up a quick strategy call ...
    ğŸ”Š TTS: Kendrick,
ğŸ“¤ Streamed sentence: Kendrick,...
    ğŸ”Š TTS: to map out a custom plan for your lead gen sites.
ğŸ“¤ Streamed sentence: to map out a custom plan for your lead gen sites....
    ğŸ”Š TTS: Does that work for you?
ğŸ“¤ Streamed final fragment: Does that work for you?...
â±ï¸ [TIMING] LLM_TOTAL: 1230ms for 193 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198305881 in conversation history
LLM response (1.81s): [N] Glad it's clicking for you. The next step is setting up a quick strategy call with our senior consultant, Kendrick, to map out a custom plan for your lead gen sites. Does that work for you?
Total latency: 1.81s

   ğŸ“ NODE: N500A_ProposeDeeperDive_V5_Adaptive
   ğŸ¤– RESPONSE: [N] Glad it's clicking for you. The next step is setting up a quick strategy call with our senior consultant, Kendrick, to map out a custom plan for your lead gen sites. Does that work for you?

============================================================
ğŸ¤ TURN 28: User says: "User: I am in Eastern time."
============================================================
â±ï¸ [19:25:50.602] ğŸ“¥ process_user_input() ENTRY - text: 'User: I am in Eastern time....'
â±ï¸ [19:25:50.602] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:50.602] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:50.602] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 23, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198305881
â±ï¸ [19:25:50.602] ğŸ”€ About to call _follow_transition() for: User: I am in Eastern time....
Evaluating transitions from N500A_ProposeDeeperDive_V5_Adaptive for message: User: I am in Eastern time.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:50.655] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:51.088] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 432ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ['Prospect agrees that setting up another call "soun...']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: Simply ask them if they want to set up and appointment - do not offer an appointment or try to sched...
â±ï¸ [TIMING] TRANSITION_EVAL: 485ms
â±ï¸ [19:25:51.088] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500A_ProposeDeeperDive_V5_Adaptive (type: conversation, mode: prompt)
â±ï¸ [19:25:51.088] ğŸ“„ About to process content (mode=prompt, length=4127)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500A_ProposeDeeperDive_V5_Adaptive': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/23 messages)
â±ï¸ [19:25:51.138] ğŸ’¬ LLM REQUEST START: 23 conversation turns, 12153 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5067 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 12, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Glad it's clicking for you. The next step is setting up a quick strategy call with our senior co...
ğŸ“   user: User: I am in Eastern time....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:51.722] ğŸ’¬ LLM FIRST TOKEN: 583ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Eastern time works perfectly since that's where we're based too.
ğŸ“¤ Streamed sentence: [N] Eastern time works perfectly since that's wher...
    ğŸ”Š TTS: To get you that strategy session with Kendrick,
ğŸ“¤ Streamed sentence: To get you that strategy session with Kendrick,...
    ğŸ”Š TTS: are you open to us finding a slot that fits your schedule next week?
ğŸ“¤ Streamed final fragment: are you open to us finding a slot that fits your s...
â±ï¸ [TIMING] LLM_TOTAL: 848ms for 185 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198305881 in conversation history
LLM response (1.39s): [N] Eastern time works perfectly since that's where we're based too. To get you that strategy session with Kendrick, are you open to us finding a slot that fits your schedule next week?
Total latency: 1.39s

   ğŸ“ NODE: N500A_ProposeDeeperDive_V5_Adaptive
   ğŸ¤– RESPONSE: [N] Eastern time works perfectly since that's where we're based too. To get you that strategy session with Kendrick, are you open to us finding a slot that fits your schedule next week?

============================================================
ğŸ¤ TURN 32: User says: "User: Sure, Tuesday at 2pm works for me."
============================================================
â±ï¸ [19:25:52.488] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sure, Tuesday at 2pm works for me....'
â±ï¸ [19:25:52.489] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:52.489] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:52.489] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 25, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198305881
â±ï¸ [19:25:52.489] ğŸ”€ About to call _follow_transition() for: User: Sure, Tuesday at 2pm wor...
Evaluating transitions from N500A_ProposeDeeperDive_V5_Adaptive for message: User: Sure, Tuesday at 2pm works for me.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:52.539] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:53.368] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 829ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Prospect agrees that setting up another call "soun...']
Selected transition index: 0
Transition: N500A_ProposeDeeperDive_V5_Adaptive -> N500B_AskTimezone_V2_FullyTuned
â±ï¸ [TIMING] TRANSITION_EVAL: 879ms
â±ï¸ [19:25:53.368] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500B_AskTimezone_V2_FullyTuned (type: conversation, mode: prompt)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [19:25:53.369] ğŸ“„ About to process content (mode=prompt, length=2269)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500B_AskTimezone_V2_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/25 messages)
â±ï¸ [19:25:53.419] ğŸ’¬ LLM REQUEST START: 25 conversation turns, 10295 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (3209 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 13, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Eastern time works perfectly since that's where we're based too. To get you that strategy sessio...
ğŸ“   user: User: Sure, Tuesday at 2pm works for me....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:54.179] ğŸ’¬ LLM FIRST TOKEN: 759ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Tuesday at 2 PM Eastern is locked inâ€”I'll get that confirmed with Kendrick r...
ğŸ“¤ Streamed sentence: [N] Tuesday at 2 PM Eastern is locked inâ€”I'll get ...
    ğŸ”Š TTS: Just to double-check,
ğŸ“¤ Streamed sentence: Just to double-check,...
    ğŸ”Š TTS: is there anything specific you'd like to cover on the call,
ğŸ“¤ Streamed sentence: is there anything specific you'd like to cover on ...
    ğŸ”Š TTS: like site setup or scaling potential?
ğŸ“¤ Streamed final fragment: like site setup or scaling potential?...
â±ï¸ [TIMING] LLM_TOTAL: 1067ms for 280 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198398056 in conversation history
LLM response (2.00s): [N] Tuesday at 2 PM Eastern is locked inâ€”I'll get that confirmed with Kendrick right away and send over the calendar invite to kendrickbowman9 at gmail dot com. Just to double-check, is there anything specific you'd like to cover on the call, like site setup or scaling potential?
Total latency: 2.00s

   ğŸ“ NODE: N500B_AskTimezone_V2_FullyTuned
   ğŸ¤– RESPONSE: [N] Tuesday at 2 PM Eastern is locked inâ€”I'll get that confirmed with Kendrick right away and send over the calendar invite to kendrickbowman9 at gmail dot com. Just to double-check, is there anything...

============================================================
ğŸ¤ TURN 35: User says: "User: Sounds great, lock it in!"
============================================================
â±ï¸ [19:25:54.988] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sounds great, lock it in!...'
â±ï¸ [19:25:54.988] â© About to call _process_call_flow_streaming()
â±ï¸ [19:25:54.988] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [19:25:54.988] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 27, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198398056
ğŸ” PRE-TRANSITION: Extracting mandatory vars on CURRENT node N500B_AskTimezone_V2_FullyTuned before transition
ğŸ” Real-time extraction: Processing 1 variables
ğŸ¤– Using configured LLM provider: grok (grok-4-fast-non-reasoning) for extraction
Failed to decrypt key, assuming unencrypted: 
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
  âœ“ timeZone: Eastern time (extracted in real-time)
âœ… Real-time extraction complete: 1 variables
âœ… PRE-TRANSITION: All mandatory vars satisfied on N500B_AskTimezone_V2_FullyTuned - proceeding with transition
â±ï¸ [19:25:55.504] ğŸ”€ About to call _follow_transition() for: User: Sounds great, lock it in...
Evaluating transitions from N500B_AskTimezone_V2_FullyTuned for message: User: Sounds great, lock it in!
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [19:25:55.552] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:55.960] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 407ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ['The user has told you their timezone...']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: Remove ssml tags - and keep toolkits max 1-2 sentences before any questions decigned to acheive the ...
â±ï¸ [TIMING] TRANSITION_EVAL: 456ms
â±ï¸ [19:25:55.960] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 7:25 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
ğŸ”§ Replaced {{timeZone}} with Eastern time in content
Using flow node: N500B_AskTimezone_V2_FullyTuned (type: conversation, mode: prompt)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [19:25:55.960] ğŸ“„ About to process content (mode=prompt, length=2269)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500B_AskTimezone_V2_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/27 messages)
â±ï¸ [19:25:56.011] ğŸ’¬ LLM REQUEST START: 27 conversation turns, 10323 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (3237 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: I type - adjust your response accordingly
CONVERSATION STATUS: Turn 14, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 7:25 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Tuesday at 2 PM Eastern is locked inâ€”I'll get that confirmed with Kendrick right away and send o...
ğŸ“   user: User: Sounds great, lock it in!...
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [19:25:57.027] ğŸ’¬ LLM FIRST TOKEN: 1016ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Awesome,
ğŸ“¤ Streamed sentence: [N] Awesome,...
    ğŸ”Š TTS: it's officially locked in for Tuesday at 2 PM Eastern.
ğŸ“¤ Streamed sentence: it's officially locked in for Tuesday at 2 PM East...
    ğŸ”Š TTS: You'll get the invite shortly to kendrickbowman9 at gmail dot comâ€”looking forwar...
ğŸ“¤ Streamed sentence: You'll get the invite shortly to kendrickbowman9 a...
    ğŸ”Š TTS: Does that cover everything on your end?
ğŸ“¤ Streamed final fragment: Does that cover everything on your end?...
â±ï¸ [TIMING] LLM_TOTAL: 1299ms for 245 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_192534 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198398056 in conversation history
LLM response (2.32s): [N] Awesome, it's officially locked in for Tuesday at 2 PM Eastern. You'll get the invite shortly to kendrickbowman9 at gmail dot comâ€”looking forward to helping you get those lead gen sites up and running. Does that cover everything on your end?
Total latency: 2.32s

   ğŸ“ NODE: N500B_AskTimezone_V2_FullyTuned
   ğŸ¤– RESPONSE: [N] Awesome, it's officially locked in for Tuesday at 2 PM Eastern. You'll get the invite shortly to kendrickbowman9 at gmail dot comâ€”looking forward to helping you get those lead gen sites up and run...

============================================================
ğŸ“Š SCRIPT COMPLETE - NODE HISTORY:
============================================================
  Turn 5: Greeting
  Turn 6: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
  Turn 7: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
  Turn 8: N_IntroduceModel_And_AskQuestions_V3_Adaptive
  Turn 9: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
  Turn 13: N_AskCapital_5k_V1_Adaptive
  Turn 15: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 17: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 19: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
  Turn 21: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
  Turn 25: N500A_ProposeDeeperDive_V5_Adaptive
  Turn 28: N500A_ProposeDeeperDive_V5_Adaptive
  Turn 32: N500B_AskTimezone_V2_FullyTuned
  Turn 35: N500B_AskTimezone_V2_FullyTuned

from fastapi import FastAPI, APIRouter, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.staticfiles import StaticFiles
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from typing import List, Optional
from datetime import datetime, timedelta
import httpx
import json
import asyncio
import base64
import websockets
import time
import uuid
# Global state for tracking active calls and their interruption windows
call_states = {}

# Import models
from models import (
    Agent, AgentCreate, Call, CallCreate, PhoneNumber, 
    PhoneNumberCreate, FlowNode, DailyRoomCreate, DailyRoomResponse,
    KnowledgeBaseItem, KnowledgeBaseItemCreate
)

# Import Telnyx models and service
from telnyx_models import (
    PhoneNumberModel, CallLogModel, OutboundCallRequest, 
    CallDirection, CallStatus, CallEndReason, Sentiment
)
from telnyx_service import TelnyxService
from realtime_voice_agent import RealtimeVoiceAgent
from melo_tts_service import MeloTTSService
from dia_tts_service import DiaTTSService

# Import calling service
from calling_service import create_call_session, get_call_session, close_call_session, CallSession

# Import Deepgram config
from deepgram_config import DEEPGRAM_CONFIG

# Import Redis service for multi-worker state sharing
from redis_service import redis_service

ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# MongoDB connection
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# Helper function to get user-specific API keys from database
async def get_user_api_key(user_id: str, service_name: str) -> Optional[str]:
    """
    Get user-specific API key for a service from database
    NO FALLBACK to platform keys - users must provide their own keys
    
    Args:
        user_id: User ID who owns the key
        service_name: Service name (openai, deepgram, elevenlabs, etc.)
        
    Returns:
        Decrypted API key or None if not found
    """
    from key_encryption import decrypt_api_key
    
    try:
        key_doc = await db.api_keys.find_one({
            "user_id": user_id,
            "service_name": service_name,
            "is_active": True
        })
        
        if key_doc and key_doc.get("api_key"):
            encrypted_key = key_doc.get("api_key")
            # Decrypt the key before returning
            decrypted_key = decrypt_api_key(encrypted_key)
            logger.debug(f"üîë Retrieved {service_name} key for user {user_id[:8]}...")
            return decrypted_key
        else:
            logger.warning(f"‚ö†Ô∏è  No {service_name} API key found for user {user_id[:8]}...")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Error fetching API key for {service_name} (user: {user_id[:8]}...): {e}")
        return None

# API Keys (fallback to env vars)
DEEPGRAM_API_KEY = os.environ.get('DEEPGRAM_API_KEY')
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')

TELNYX_API_KEY = os.environ.get('TELNYX_API_KEY')

ELEVEN_API_KEY = os.environ.get('ELEVEN_API_KEY')
DAILY_API_KEY = os.environ.get('DAILY_API_KEY')

# Create the main app
app = FastAPI(title="Retell AI Clone API")

# Mount static files directory for serving generated TTS audio
app.mount("/api/tts-audio", StaticFiles(directory="/tmp"), name="tts-audio")

# Pre-generate comfort noise on startup for immediate availability
@app.on_event("startup")
async def startup_event():
    """Pre-generate comfort noise file on server startup"""
    try:
        from comfort_noise import generate_continuous_comfort_noise
        import os
        
        comfort_noise_path = "/tmp/comfort_noise_continuous.mp3"
        if not os.path.exists(comfort_noise_path) or os.path.getsize(comfort_noise_path) == 0:
            logger.info("üéµ Pre-generating comfort noise file on startup (5 minutes for seamless loops)...")
            # Generate 5-minute file so it rarely loops during typical calls
            generate_continuous_comfort_noise(duration_seconds=300, output_path=comfort_noise_path)
            logger.info("‚úÖ Comfort noise file ready for immediate use")
        else:
            logger.info("‚úÖ Comfort noise file already exists")
    except Exception as e:
        logger.error(f"Error pre-generating comfort noise: {e}")

# Create a router with the /api prefix
api_router = APIRouter(prefix="/api")

# Import auth modules
from auth_models import (
    UserCreate, UserLogin, User, UserResponse, 
    PasswordResetRequest, PasswordReset, PasswordResetToken, TokenResponse
)
from auth_utils import hash_password, verify_password, create_access_token, generate_reset_token
from auth_middleware import get_current_user, get_optional_user
from fastapi import Depends, Response, Request

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Pre-load RAG service at startup to avoid cold start delays (optional for deployment)
RAG_ENABLED = os.environ.get('ENABLE_RAG', 'false').lower() == 'true'
if RAG_ENABLED:
    logger.info("üöÄ Pre-loading RAG service and KB router to avoid cold start...")
    try:
        import rag_service
        import kb_router
        logger.info("‚úÖ RAG service pre-loaded successfully (embedding model loaded)")
    except Exception as e:
        logger.error(f"‚ö†Ô∏è  Failed to pre-load RAG service: {e}")
        logger.warning("‚ö†Ô∏è  RAG service disabled - Knowledge Base will use full content instead of semantic search")
        RAG_ENABLED = False
else:
    logger.info("‚ÑπÔ∏è  RAG service disabled (set ENABLE_RAG=true to enable semantic search)")

# ============ AUTHENTICATION ENDPOINTS ============

@api_router.post("/auth/signup", response_model=TokenResponse)
async def signup(user_data: UserCreate, response: Response):
    """Create a new user account"""
    # Check if user already exists
    existing_user = await db.users.find_one({"email": user_data.email})
    if existing_user:
        raise HTTPException(status_code=400, detail="Email already registered")
    
    # Create new user
    user = User(
        email=user_data.email,
        password_hash=hash_password(user_data.password)
    )
    await db.users.insert_one(user.dict())
    logger.info(f"Created user: {user.email}")
    
    # Create JWT token
    token = create_access_token(user.id, user.email, user_data.remember_me)
    
    # Set httpOnly cookie
    max_age = 30 * 24 * 60 * 60 if user_data.remember_me else 30 * 60  # 30 days or 30 minutes
    # Secure flag based on environment (True for production HTTPS)
    is_production = os.environ.get('ENVIRONMENT', 'development') == 'production'
    response.set_cookie(
        key="access_token",
        value=token,
        httponly=True,
        secure=True,  # Always secure for HTTPS
        samesite="none",  # Allow cross-domain cookies (frontend at li-ai.org, backend at api.li-ai.org)
        max_age=max_age,
        domain=".li-ai.org"  # Share cookie across subdomains
    )
    
    return TokenResponse(
        message="User created successfully",
        user=UserResponse(
            id=user.id,
            email=user.email,
            created_at=user.created_at,
            last_login=None
        )
    )

@api_router.post("/auth/login", response_model=TokenResponse)
async def login(credentials: UserLogin, response: Response):
    """Login with email and password"""
    # Find user
    user_data = await db.users.find_one({"email": credentials.email})
    if not user_data:
        raise HTTPException(status_code=401, detail="Invalid email or password")
    
    user = User(**user_data)
    
    # Verify password
    if not verify_password(credentials.password, user.password_hash):
        raise HTTPException(status_code=401, detail="Invalid email or password")
    
    # Check if user is active
    if not user.is_active:
        raise HTTPException(status_code=403, detail="Account is deactivated")
    
    # Update last login
    await db.users.update_one(
        {"id": user.id},
        {"$set": {"last_login": datetime.utcnow()}}
    )
    
    # Create JWT token
    token = create_access_token(user.id, user.email, credentials.remember_me)
    
    # Set httpOnly cookie
    max_age = 30 * 24 * 60 * 60 if credentials.remember_me else 30 * 60  # 30 days or 30 minutes
    # Secure flag based on environment (True for production HTTPS)
    is_production = os.environ.get('ENVIRONMENT', 'development') == 'production'
    response.set_cookie(
        key="access_token",
        value=token,
        httponly=True,
        secure=True,  # Always secure for HTTPS
        samesite="none",  # Allow cross-domain cookies (frontend at li-ai.org, backend at api.li-ai.org)
        max_age=max_age,
        domain=".li-ai.org"  # Share cookie across subdomains
    )
    
    return TokenResponse(
        message="Login successful",
        user=UserResponse(
            id=user.id,
            email=user.email,
            created_at=user.created_at,
            last_login=datetime.utcnow()
        )
    )

@api_router.post("/auth/logout")
async def logout(response: Response, current_user: dict = Depends(get_current_user)):
    """Logout user"""
    response.delete_cookie(key="access_token")
    return {"message": "Logout successful"}

@api_router.get("/auth/me", response_model=UserResponse)
async def get_current_user_info(current_user: dict = Depends(get_current_user)):
    """Get current user info"""
    user_data = await db.users.find_one({"id": current_user["id"]})
    if not user_data:
        raise HTTPException(status_code=404, detail="User not found")
    
    user = User(**user_data)
    return UserResponse(
        id=user.id,
        email=user.email,
        created_at=user.created_at,
        last_login=user.last_login
    )

@api_router.post("/auth/forgot-password")
async def forgot_password(request_data: PasswordResetRequest):
    """Request password reset"""
    # Find user
    user_data = await db.users.find_one({"email": request_data.email})
    if not user_data:
        # Don't reveal if email exists or not
        return {"message": "If the email exists, a password reset link will be sent"}
    
    user = User(**user_data)
    
    # Generate reset token
    token = generate_reset_token()
    reset_token = PasswordResetToken(
        user_id=user.id,
        token=token,
        expires_at=datetime.utcnow() + timedelta(hours=1)
    )
    
    # Save reset token
    await db.password_reset_tokens.insert_one(reset_token.dict())
    
    # In production, send email with reset link
    # For now, just log it
    logger.info(f"Password reset token for {user.email}: {token}")
    logger.info(f"Reset link: /reset-password?token={token}")
    
    return {"message": "If the email exists, a password reset link will be sent"}

@api_router.post("/auth/reset-password")
async def reset_password(reset_data: PasswordReset):
    """Reset password with token"""
    # Find reset token
    token_data = await db.password_reset_tokens.find_one({
        "token": reset_data.token,
        "used": False
    })
    
    if not token_data:
        raise HTTPException(status_code=400, detail="Invalid or expired reset token")
    
    reset_token = PasswordResetToken(**token_data)
    
    # Check if token is expired
    if reset_token.expires_at < datetime.utcnow():
        raise HTTPException(status_code=400, detail="Reset token has expired")
    
    # Update user password
    new_password_hash = hash_password(reset_data.new_password)
    await db.users.update_one(
        {"id": reset_token.user_id},
        {"$set": {"password_hash": new_password_hash}}
    )
    
    # Mark token as used
    await db.password_reset_tokens.update_one(
        {"id": reset_token.id},
        {"$set": {"used": True}}
    )
    
    logger.info(f"Password reset successful for user: {reset_token.user_id}")
    
    return {"message": "Password reset successful"}

# ============ AGENT ENDPOINTS ============

@api_router.post("/agents", response_model=Agent)
async def create_agent(agent_data: AgentCreate, current_user: dict = Depends(get_current_user)):
    """Create a new AI agent"""
    agent_dict = agent_data.dict()
    agent_dict['user_id'] = current_user['id']
    agent = Agent(**agent_dict)
    await db.agents.insert_one(agent.dict())
    logger.info(f"Created agent: {agent.id} for user: {current_user['email']}")
    return agent

@api_router.get("/agents", response_model=List[Agent])
async def list_agents(current_user: dict = Depends(get_current_user)):
    """List all agents for current user"""
    agents = await db.agents.find({"user_id": current_user['id']}).to_list(1000)
    return [Agent(**agent) for agent in agents]

@api_router.get("/agents/{agent_id}", response_model=Agent)
async def get_agent(agent_id: str, current_user: dict = Depends(get_current_user)):
    """Get agent by ID"""
    agent = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
    if not agent:
        raise HTTPException(status_code=404, detail="Agent not found")
    return Agent(**agent)

@api_router.put("/agents/{agent_id}", response_model=Agent)
async def update_agent(agent_id: str, agent_data: dict, current_user: dict = Depends(get_current_user)):
    """Update agent"""
    agent = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
    if not agent:
        raise HTTPException(status_code=404, detail="Agent not found")
    
    agent_data["updated_at"] = datetime.utcnow()
    # Prevent user_id modification
    agent_data.pop('user_id', None)
    await db.agents.update_one({"id": agent_id, "user_id": current_user['id']}, {"$set": agent_data})
    
    updated_agent = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
    return Agent(**updated_agent)

@api_router.delete("/agents/{agent_id}")
async def delete_agent(agent_id: str, current_user: dict = Depends(get_current_user)):
    """Delete agent"""
    result = await db.agents.delete_one({"id": agent_id, "user_id": current_user['id']})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Agent not found")
    return {"message": "Agent deleted successfully"}

@api_router.put("/agents/{agent_id}/flow")
async def update_agent_flow(agent_id: str, flow: List[FlowNode], current_user: dict = Depends(get_current_user)):
    """Update agent call flow"""
    agent = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
    if not agent:
        raise HTTPException(status_code=404, detail="Agent not found")
    
    await db.agents.update_one(
        {"id": agent_id, "user_id": current_user['id']},
        {"$set": {"call_flow": [node.dict() for node in flow], "updated_at": datetime.utcnow()}}
    )
    return {"message": "Flow updated successfully"}

@api_router.get("/agents/{agent_id}/flow")
async def get_agent_flow(agent_id: str, current_user: dict = Depends(get_current_user)):
    """Get agent call flow"""
    agent = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
    if not agent:
        raise HTTPException(status_code=404, detail="Agent not found")
    return {"flow": agent.get("call_flow", [])}

# Web-based conversation sessions (for WebCaller)
web_sessions = {}

@api_router.post("/agents/{agent_id}/message")
async def agent_message(agent_id: str, request: dict, current_user: dict = Depends(get_current_user)):
    """Handle web-based conversation with agent"""
    try:
        # Get agent (verify ownership)
        agent = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
        if not agent:
            raise HTTPException(status_code=404, detail="Agent not found")
        
        message = request.get("message", "")
        session_id = request.get("session_id")
        
        logger.info(f"üí¨ Web message from agent {agent_id}: {message}")
        
        # Create or get session
        if not session_id or session_id not in web_sessions:
            session_id = f"web_{agent_id}_{datetime.utcnow().timestamp()}"
            session = CallSession(session_id, agent, agent_id=agent_id, user_id=agent.get("user_id"), db=db)
            web_sessions[session_id] = session
            logger.info(f"‚ú® Created new web session: {session_id}")
        else:
            session = web_sessions[session_id]
            logger.info(f"‚ôªÔ∏è Using existing session: {session_id}")
        
        # Process message
        response = await session.process_user_input(message)
        
        logger.info(f"ü§ñ AI response: {response.get('text', '')[:100]}...")
        
        return {
            "session_id": session_id,
            "text": response.get("text", ""),
            "should_end_call": session.should_end_call
        }
        
    except Exception as e:
        logger.error(f"Error processing web message: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

@api_router.post("/agents/{agent_id}/process")
async def process_message(agent_id: str, request_data: dict, current_user: dict = Depends(get_current_user)):
    """Process a user message and return AI response"""
    try:
        # Get agent (verify ownership)
        agent = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
        if not agent:
            raise HTTPException(status_code=404, detail="Agent not found")
        
        # Get conversation history and user message
        message = request_data.get("message", "")
        conversation_history = request_data.get("conversation_history", [])
        
        logger.info(f"üì• Received message: {message}")
        logger.info(f"üì• Received history length: {len(conversation_history)}")
        logger.info(f"üì• Received history: {conversation_history}")
        
        # Call the calling service to process with KB loading
        session = await create_call_session(f"temp_{agent_id}", agent, agent_id=agent_id, user_id=agent.get("user_id"), db=db)
        
        # Set conversation history if provided
        if conversation_history:
            session.conversation_history = conversation_history
            logger.info(f"‚úÖ Set session history, length: {len(session.conversation_history)}")
        
        response = await session.process_user_input(message)
        
        return {
            "response": response["text"],
            "latency": response["latency"],
            "should_end_call": response.get("end_call", False)
        }
        
    except Exception as e:
        logger.error(f"Error processing message: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============ KNOWLEDGE BASE ENDPOINTS ============

from fastapi import UploadFile, File

@api_router.post("/agents/{agent_id}/kb/upload")
async def upload_kb_file(agent_id: str, file: UploadFile = File(...), current_user: dict = Depends(get_current_user)):
    """Upload a file (PDF/TXT/DOCX) to agent's knowledge base"""
    try:
        # Verify agent exists and user owns it
        agent_doc = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
        if not agent_doc:
            raise HTTPException(status_code=404, detail="Agent not found")
        
        filename = file.filename
        file_content = await file.read()
        
        # Determine file type and extract text
        file_ext = filename.lower().split('.')[-1]
        content = ""
        
        if file_ext == "txt":
            # Text file - direct read
            content = file_content.decode('utf-8', errors='ignore')
        
        elif file_ext == "pdf":
            # PDF extraction using PyPDF2
            import io
            import PyPDF2
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_content))
            content = ""
            for page in pdf_reader.pages:
                content += page.extract_text() + "\n"
        
        elif file_ext == "docx":
            # DOCX extraction using python-docx
            import io
            import docx
            doc = docx.Document(io.BytesIO(file_content))
            content = "\n".join([paragraph.text for paragraph in doc.paragraphs])
        
        else:
            raise HTTPException(status_code=400, detail=f"Unsupported file type: {file_ext}")
        
        if not content.strip():
            raise HTTPException(status_code=400, detail="No text content extracted from file")
        
        # Create KB item
        kb_item = KnowledgeBaseItem(
            user_id=current_user['id'],
            agent_id=agent_id,
            source_type="file",
            source_name=filename,
            content=content,
            file_size=len(file_content)
        )
        
        # Store in database
        await db.knowledge_base.insert_one(kb_item.dict())
        
        logger.info(f"üìö KB file uploaded for agent {agent_id}: {filename} ({len(content)} chars)")
        
        # Index with RAG for fast retrieval (if enabled)
        if RAG_ENABLED:
            try:
                from rag_service import index_knowledge_base
                kb_items = await db.knowledge_base.find({"agent_id": agent_id, "user_id": current_user['id']}).to_list(100)
                chunks_indexed = index_knowledge_base(agent_id, kb_items)
                logger.info(f"üîç RAG: Indexed {chunks_indexed} chunks for agent {agent_id}")
            except Exception as e:
                logger.error(f"‚ùå RAG indexing error: {e}")
        else:
            logger.info("‚ÑπÔ∏è  RAG disabled - KB stored without semantic indexing")
        
        return {
            "id": kb_item.id,
            "agent_id": kb_item.agent_id,
            "source_type": kb_item.source_type,
            "source_name": kb_item.source_name,
            "content_length": len(content),
            "file_size": kb_item.file_size,
            "created_at": kb_item.created_at
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error uploading KB file: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.post("/agents/{agent_id}/kb/url")
async def add_kb_url(agent_id: str, url: str, current_user: dict = Depends(get_current_user)):
    """Add a website URL to agent's knowledge base (scrapes content)"""
    try:
        # Verify agent exists and user owns it
        agent_doc = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
        if not agent_doc:
            raise HTTPException(status_code=404, detail="Agent not found")
        
        if not url or not url.startswith(("http://", "https://")):
            raise HTTPException(status_code=400, detail="Valid URL required")
        
        # Scrape website content using httpx
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(url)
            response.raise_for_status()
            
            # Simple HTML text extraction (remove tags)
            import re
            html_content = response.text
            # Remove script and style elements
            html_content = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
            html_content = re.sub(r'<style[^>]*>.*?</style>', '', html_content, flags=re.DOTALL | re.IGNORECASE)
            # Remove HTML tags
            content = re.sub(r'<[^>]+>', ' ', html_content)
            # Clean up whitespace
            content = re.sub(r'\s+', ' ', content).strip()
        
        if not content.strip():
            raise HTTPException(status_code=400, detail="No text content extracted from URL")
        
        # Create KB item
        kb_item = KnowledgeBaseItem(
            user_id=current_user['id'],
            agent_id=agent_id,
            source_type="url",
            source_name=url,
            content=content,
            file_size=len(content.encode('utf-8'))
        )
        
        # Store in database
        await db.knowledge_base.insert_one(kb_item.dict())
        
        logger.info(f"üåê KB URL added for agent {agent_id}: {url} ({len(content)} chars)")
        
        # Index with RAG for fast retrieval (if enabled)
        if RAG_ENABLED:
            try:
                from rag_service import index_knowledge_base
                kb_items = await db.knowledge_base.find({"agent_id": agent_id, "user_id": current_user['id']}).to_list(100)
                chunks_indexed = index_knowledge_base(agent_id, kb_items)
                logger.info(f"üîç RAG: Indexed {chunks_indexed} chunks for agent {agent_id}")
            except Exception as e:
                logger.error(f"‚ùå RAG indexing error: {e}")
        else:
            logger.info("‚ÑπÔ∏è  RAG disabled - KB stored without semantic indexing")
        
        return {
            "id": kb_item.id,
            "agent_id": kb_item.agent_id,
            "source_type": kb_item.source_type,
            "source_name": kb_item.source_name,
            "content_length": len(content),
            "file_size": kb_item.file_size,
            "created_at": kb_item.created_at
        }
        
    except HTTPException:
        raise
    except httpx.HTTPError as e:
        logger.error(f"Error fetching URL: {e}")
        raise HTTPException(status_code=400, detail=f"Failed to fetch URL: {str(e)}")
    except Exception as e:
        logger.error(f"Error adding KB URL: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.post("/agents/{agent_id}/kb/reindex")
async def reindex_agent_kb(agent_id: str, current_user: dict = Depends(get_current_user)):
    """Force re-index all KB items for an agent with RAG"""
    try:
        # Verify agent ownership
        agent = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
        if not agent:
            raise HTTPException(status_code=404, detail="Agent not found")
        
        kb_items = await db.knowledge_base.find({"agent_id": agent_id, "user_id": current_user['id']}).to_list(100)
        
        if not kb_items:
            raise HTTPException(status_code=404, detail="No KB items found for this agent")
        
        # Index with RAG (if enabled)
        if RAG_ENABLED:
            from rag_service import index_knowledge_base
            chunks_indexed = index_knowledge_base(agent_id, kb_items)
            logger.info(f"üîç RAG: Re-indexed {chunks_indexed} chunks for agent {agent_id}")
        else:
            chunks_indexed = 0
            logger.info(f"‚ÑπÔ∏è  RAG disabled - reindexing skipped")
        
        return {
            "agent_id": agent_id,
            "kb_items": len(kb_items),
            "chunks_indexed": chunks_indexed,
            "status": "success"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error re-indexing KB: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.get("/agents/{agent_id}/kb")
async def list_kb_items(agent_id: str, current_user: dict = Depends(get_current_user)):
    """List all knowledge base items for an agent"""
    try:
        # Verify agent exists and user owns it
        agent_doc = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
        if not agent_doc:
            raise HTTPException(status_code=404, detail="Agent not found")
        
        # Get all KB items for this agent
        kb_items = await db.knowledge_base.find({"agent_id": agent_id, "user_id": current_user['id']}).to_list(100)
        
        # Return without full content (just metadata)
        return [{
            "id": item.get("id"),
            "agent_id": item.get("agent_id"),
            "source_type": item.get("source_type"),
            "source_name": item.get("source_name"),
            "content_length": len(item.get("content", "")),
            "file_size": item.get("file_size", 0),
            "created_at": item.get("created_at")
        } for item in kb_items]
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing KB items: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.get("/agents/{agent_id}/kb/{kb_id}")
async def get_kb_item(agent_id: str, kb_id: str, current_user: dict = Depends(get_current_user)):
    """Get specific knowledge base item with full content"""
    try:
        kb_item = await db.knowledge_base.find_one({"id": kb_id, "agent_id": agent_id, "user_id": current_user['id']})
        if not kb_item:
            raise HTTPException(status_code=404, detail="KB item not found")
        
        # Convert MongoDB document to JSON-serializable format
        return {
            "id": kb_item.get("id"),
            "agent_id": kb_item.get("agent_id"),
            "source_type": kb_item.get("source_type"),
            "source_name": kb_item.get("source_name"),
            "content": kb_item.get("content"),
            "file_size": kb_item.get("file_size", 0),
            "created_at": kb_item.get("created_at")
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching KB item: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.delete("/agents/{agent_id}/kb/{kb_id}")
async def delete_kb_item(agent_id: str, kb_id: str, current_user: dict = Depends(get_current_user)):
    """Delete a knowledge base item"""
    try:
        # Verify ownership
        agent = await db.agents.find_one({"id": agent_id, "user_id": current_user['id']})
        if not agent:
            raise HTTPException(status_code=404, detail="Agent not found")
        
        result = await db.knowledge_base.delete_one({"id": kb_id, "agent_id": agent_id, "user_id": current_user['id']})
        if result.deleted_count == 0:
            raise HTTPException(status_code=404, detail="KB item not found")
        
        logger.info(f"üóëÔ∏è KB item deleted: {kb_id} for agent {agent_id}")
        
        # Re-index remaining KB items (if RAG enabled)
        if RAG_ENABLED:
            try:
                from rag_service import index_knowledge_base
                kb_items = await db.knowledge_base.find({"agent_id": agent_id, "user_id": current_user['id']}).to_list(100)
                if kb_items:
                    chunks_indexed = index_knowledge_base(agent_id, kb_items)
                    logger.info(f"üîç RAG: Re-indexed {chunks_indexed} chunks for agent {agent_id}")
                else:
                    # No more KB items, delete the collection
                    from rag_service import delete_agent_kb
                    delete_agent_kb(agent_id)
                    logger.info(f"üîç RAG: Deleted empty KB collection for agent {agent_id}")
            except Exception as e:
                logger.error(f"‚ùå RAG re-indexing error: {e}")
        
        return {"message": "KB item deleted successfully", "id": kb_id}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting KB item: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============ API KEY MANAGEMENT ENDPOINTS ============

from models import APIKey, APIKeyCreate

async def get_api_key(user_id: str, service_name: str) -> str:
    """
    Retrieve and decrypt an API key for a user and service.
    Returns None if key not found.
    """
    from key_encryption import decrypt_api_key
    
    key_doc = await db.api_keys.find_one({
        "user_id": user_id,
        "service_name": service_name,
        "is_active": True
    })
    
    if not key_doc:
        return None
    
    # Decrypt and return the key
    encrypted_key = key_doc.get("encrypted_key") or key_doc.get("api_key")
    if not encrypted_key:
        return None
    
    try:
        return decrypt_api_key(encrypted_key)
    except Exception as e:
        # If decryption fails, assume it's plaintext (for backward compatibility)
        logger.warning(f"Failed to decrypt {service_name}, using as plaintext: {str(e)[:50]}")
        return encrypted_key

@api_router.get("/settings/api-keys")
async def list_api_keys(current_user: dict = Depends(get_current_user)):
    """List all configured API keys (returns service names only, not actual keys)"""
    keys = await db.api_keys.find({"user_id": current_user['id']}).to_list(100)
    return [{
        "id": key.get("id"),
        "service_name": key.get("service_name"),
        "is_active": key.get("is_active", True),
        "created_at": key.get("created_at"),
        "has_key": bool(key.get("api_key"))
    } for key in keys]

@api_router.post("/settings/api-keys")
async def create_or_update_api_key(api_key_data: APIKeyCreate, current_user: dict = Depends(get_current_user)):
    """Create or update an API key for a service (keys are encrypted at rest)"""
    from key_encryption import encrypt_api_key
    
    # Encrypt the API key before storing
    encrypted_key = encrypt_api_key(api_key_data.api_key)
    
    # Check if key already exists for this service and user
    existing = await db.api_keys.find_one({"service_name": api_key_data.service_name, "user_id": current_user['id']})
    
    if existing:
        # Update existing key
        await db.api_keys.update_one(
            {"service_name": api_key_data.service_name, "user_id": current_user['id']},
            {"$set": {
                "api_key": encrypted_key,
                "updated_at": datetime.utcnow(),
                "is_active": True
            }}
        )
        logger.info(f"‚úÖ Updated API key for {api_key_data.service_name} (user: {current_user['email']})")
        return {"message": f"API key for {api_key_data.service_name} updated successfully"}
    else:
        # Create new key
        new_key = APIKey(
            user_id=current_user['id'],
            service_name=api_key_data.service_name,
            api_key=encrypted_key
        )
        await db.api_keys.insert_one(new_key.dict())
        logger.info(f"‚úÖ Created API key for {api_key_data.service_name} (user: {current_user['email']})")
        return {"message": f"API key for {api_key_data.service_name} created successfully"}

@api_router.delete("/settings/api-keys/{service_name}")
async def delete_api_key(service_name: str, current_user: dict = Depends(get_current_user)):
    """Delete an API key for a service"""
    result = await db.api_keys.delete_one({"service_name": service_name, "user_id": current_user['id']})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail=f"No API key found for {service_name}")
    logger.info(f"üóëÔ∏è  Deleted API key for {service_name}")
    return {"message": f"API key for {service_name} deleted successfully"}

@api_router.post("/settings/api-keys/test/{service_name}")
async def test_api_key(service_name: str, current_user: dict = Depends(get_current_user)):
    """Test if an API key is valid by making a simple API call"""
    import httpx
    from key_encryption import decrypt_api_key
    
    # Get the API key
    key_doc = await db.api_keys.find_one({"service_name": service_name, "user_id": current_user['id']})
    if not key_doc:
        raise HTTPException(status_code=404, detail=f"No API key found for {service_name}")
    
    # Decrypt the key before testing
    encrypted_key = key_doc.get("api_key")
    api_key = decrypt_api_key(encrypted_key)
    
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            if service_name == "openai":
                response = await client.get(
                    "https://api.openai.com/v1/models",
                    headers={"Authorization": f"Bearer {api_key}"}
                )
            elif service_name == "deepgram":
                response = await client.get(
                    "https://api.deepgram.com/v1/projects",
                    headers={"Authorization": f"Token {api_key}"}
                )
            elif service_name == "elevenlabs":
                response = await client.get(
                    "https://api.elevenlabs.io/v1/voices",
                    headers={"xi-api-key": api_key}
                )
            elif service_name == "grok" or service_name == "xai":
                response = await client.get(
                    "https://api.x.ai/v1/models",
                    headers={"Authorization": f"Bearer {api_key}"}
                )
            elif service_name == "hume":
                response = await client.get(
                    "https://api.hume.ai/v0/batch/jobs",
                    headers={"X-Hume-Api-Key": api_key}
                )
            elif service_name == "soniox":
                # Soniox doesn't have a simple test endpoint, check if key format is valid
                # Valid keys are 32+ chars alphanumeric
                if len(api_key) >= 32 and api_key.replace('-', '').replace('_', '').isalnum():
                    return {"valid": True, "message": f"API key for {service_name} appears valid (format check)"}
                else:
                    return {"valid": False, "error": "Invalid key format"}
            elif service_name == "assemblyai":
                response = await client.get(
                    "https://api.assemblyai.com/v2/user",
                    headers={"authorization": api_key}
                )
            elif service_name == "telnyx":
                response = await client.get(
                    "https://api.telnyx.com/v2/phone_numbers",
                    headers={"Authorization": f"Bearer {api_key}"}
                )
            elif service_name == "cartesia":
                response = await client.get(
                    "https://api.cartesia.ai/voices",
                    headers={"X-API-Key": api_key}
                )
            else:
                return {"valid": False, "error": f"Unknown service: {service_name}"}
            
            if response.status_code == 200:
                return {"valid": True, "message": f"‚úÖ API key for {service_name} is valid"}
            elif response.status_code == 401 or response.status_code == 403:
                return {"valid": False, "error": f"‚ùå Invalid API key (401/403 Unauthorized)"}
            elif response.status_code == 404:
                return {"valid": False, "error": f"‚ö†Ô∏è Test endpoint not found, but key format OK"}
            else:
                return {"valid": False, "error": f"‚ö†Ô∏è API returned status {response.status_code}"}
                
    except Exception as e:
        logger.error(f"Error testing {service_name} API key: {e}")
        return {"valid": False, "error": str(e)}

# ============ SPEECH-TO-TEXT ENDPOINT ============

from fastapi import File, UploadFile

@api_router.post("/speech-to-text")
async def speech_to_text(audio: UploadFile = File(...)):
    """Convert speech to text using Deepgram"""
    import tempfile
    from pydub import AudioSegment
    
    try:
        if not DEEPGRAM_API_KEY:
            raise HTTPException(status_code=500, detail="Deepgram API key not configured")
        
        # Read audio file
        audio_data = await audio.read()
        logger.info(f"Received audio: {len(audio_data)} bytes, type: {audio.content_type}")
        
        # Convert webm to WAV using pydub
        with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as temp_webm:
            temp_webm.write(audio_data)
            temp_webm_path = temp_webm.name
        
        try:
            # Load and convert to WAV
            audio_segment = AudioSegment.from_file(temp_webm_path, format="webm")
            
            # Convert to mono, 16kHz, 16-bit PCM
            audio_segment = audio_segment.set_channels(1)
            audio_segment = audio_segment.set_frame_rate(16000)
            audio_segment = audio_segment.set_sample_width(2)  # 16-bit
            
            # Export as WAV
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
                audio_segment.export(temp_wav.name, format="wav")
                temp_wav_path = temp_wav.name
            
            # Read WAV data
            with open(temp_wav_path, 'rb') as f:
                wav_data = f.read()
            
            logger.info(f"Converted to WAV: {len(wav_data)} bytes")
            
            # Clean up temp files
            import os
            os.unlink(temp_webm_path)
            os.unlink(temp_wav_path)
            
        except Exception as conv_error:
            logger.error(f"Audio conversion error: {conv_error}")
            # Try sending original audio anyway
            wav_data = audio_data
        
        # Call Deepgram API with Nova-3
        url = "https://api.deepgram.com/v1/listen"
        headers = {
            "Authorization": f"Token {DEEPGRAM_API_KEY}",
            "Content-Type": "audio/wav"
        }
        params = {
            "model": "nova-3",
            "smart_format": "true",
            "language": "en",
            "punctuate": "true"
        }
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, headers=headers, params=params, content=wav_data)
            
            if response.status_code == 200:
                result = response.json()
                transcript = result.get("results", {}).get("channels", [{}])[0].get("alternatives", [{}])[0].get("transcript", "")
                logger.info(f"‚úÖ Transcript: {transcript}")
                return {"transcript": transcript}
            else:
                logger.error(f"‚ùå Deepgram error ({response.status_code}): {response.text}")
                raise HTTPException(status_code=500, detail="Speech recognition failed")
        
    except Exception as e:
        logger.error(f"Error in speech-to-text: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============ TEXT-TO-SPEECH ENDPOINT ============

@api_router.post("/text-to-speech")
async def text_to_speech(request_data: dict):
    """Convert text to speech using ElevenLabs"""
    try:
        if not ELEVEN_API_KEY:
            raise HTTPException(status_code=500, detail="ElevenLabs API key not configured")
        
        text = request_data.get("text", "")
        voice = request_data.get("voice", "Rachel")
        
        # Map voice names to ElevenLabs voice IDs
        voice_map = {
            "Rachel": "21m00Tcm4TlvDq8ikWAM",
            "Joseph": "Zlb1dXrM653N07WRdFW3",
            "Emily": "LcfcDJNUP1GQjkzn1xUU",
            "Daniel": "onwK4e9ZLuTAKqWW03F9",
        }
        
        voice_id = voice_map.get(voice, voice_map["Rachel"])
        
        # Call ElevenLabs API
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
        headers = {
            "Accept": "audio/mpeg",
            "Content-Type": "application/json",
            "xi-api-key": ELEVEN_API_KEY
        }
        data = {
            "text": text,
            "model_id": "eleven_monolingual_v1",
            "voice_settings": {
                "stability": 0.5,
                "similarity_boost": 0.5
            }
        }
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, headers=headers, json=data)
            
            if response.status_code == 200:
                from fastapi.responses import Response
                return Response(content=response.content, media_type="audio/mpeg")
            else:
                logger.error(f"ElevenLabs error: {response.text}")
                raise HTTPException(status_code=500, detail="Text-to-speech failed")
        
    except Exception as e:
        logger.error(f"Error in text-to-speech: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ============ CALL ENDPOINTS ============

@api_router.post("/calls", response_model=Call)
async def create_call(call_data: CallCreate, current_user: dict = Depends(get_current_user)):
    """Create/start a new call"""
    # Get agent details (verify ownership)
    agent = await db.agents.find_one({"id": call_data.agent_id, "user_id": current_user['id']})
    if not agent:
        raise HTTPException(status_code=404, detail="Agent not found")
    
    # Create call record
    call = Call(
        user_id=current_user['id'],
        agent_id=call_data.agent_id,
        agent_name=agent["name"],
        phone_number=call_data.phone_number,
        direction=call_data.direction
    )
    
    await db.calls.insert_one(call.dict())
    
    # Update agent stats
    await db.agents.update_one(
        {"id": call_data.agent_id, "user_id": current_user['id']},
        {"$inc": {"stats.calls_handled": 1}}
    )
    
    logger.info(f"Created call: {call.id} for user: {current_user['email']}")
    return call

@api_router.get("/calls", response_model=List[Call])
async def list_calls(limit: int = 100, current_user: dict = Depends(get_current_user)):
    """List all calls for current user"""
    calls = await db.calls.find({"user_id": current_user['id']}).sort("timestamp", -1).limit(limit).to_list(limit)
    return [Call(**call) for call in calls]

@api_router.get("/calls/{call_id}", response_model=Call)
async def get_call(call_id: str, current_user: dict = Depends(get_current_user)):
    """Get call by ID"""
    call = await db.calls.find_one({"id": call_id, "user_id": current_user['id']})
    if not call:
        raise HTTPException(status_code=404, detail="Call not found")
    return Call(**call)

@api_router.post("/calls/{call_id}/end")
async def end_call(call_id: str, call_data: dict):
    """End a call and update stats"""
    call = await db.calls.find_one({"id": call_id})
    if not call:
        raise HTTPException(status_code=404, detail="Call not found")
    
    update_data = {
        "status": "completed",
        "duration": call_data.get("duration", 0),
        "sentiment": call_data.get("sentiment", "neutral"),
        "latency": call_data.get("latency", 0.0),
        "transcript": call_data.get("transcript", [])
    }
    
    await db.calls.update_one({"id": call_id}, {"$set": update_data})
    
    # Update agent stats
    agent = await db.agents.find_one({"id": call["agent_id"]})
    if agent:
        stats = agent.get("stats", {})
        total_calls = stats.get("calls_handled", 1)
        avg_latency = stats.get("avg_latency", 0.0)
        
        # Calculate new average latency
        new_avg_latency = ((avg_latency * (total_calls - 1)) + call_data.get("latency", 0.0)) / total_calls
        
        await db.agents.update_one(
            {"id": call["agent_id"]},
            {"$set": {"stats.avg_latency": round(new_avg_latency, 2)}}
        )
    
    return {"message": "Call ended successfully"}

# ============ PHONE NUMBER ENDPOINTS ============

@api_router.post("/phone-numbers", response_model=PhoneNumber)
async def create_phone_number(number_data: PhoneNumberCreate, current_user: dict = Depends(get_current_user)):
    """Add a new phone number"""
    phone_number = PhoneNumber(
        user_id=current_user['id'],
        number=number_data.number,
        inbound_agent_id=number_data.inbound_agent_id,
        outbound_agent_id=number_data.outbound_agent_id,
        status="active"
    )
    
    # Get inbound agent name if assigned (verify ownership)
    if number_data.inbound_agent_id:
        agent = await db.agents.find_one({"id": number_data.inbound_agent_id, "user_id": current_user['id']})
        if agent:
            phone_number.inbound_agent_name = agent["name"]
    
    # Get outbound agent name if assigned (verify ownership)
    if number_data.outbound_agent_id:
        agent = await db.agents.find_one({"id": number_data.outbound_agent_id, "user_id": current_user['id']})
        if agent:
            phone_number.outbound_agent_name = agent["name"]
    
    await db.phone_numbers.insert_one(phone_number.dict())
    return phone_number

@api_router.get("/phone-numbers", response_model=List[PhoneNumber])
async def list_phone_numbers(current_user: dict = Depends(get_current_user)):
    """List all phone numbers for current user"""
    numbers = await db.phone_numbers.find({"user_id": current_user['id']}).to_list(1000)
    return [PhoneNumber(**num) for num in numbers]

@api_router.put("/phone-numbers/{number_id}")
async def update_phone_number(number_id: str, update_data: dict, current_user: dict = Depends(get_current_user)):
    """Update phone number agent assignments"""
    number = await db.phone_numbers.find_one({"id": number_id, "user_id": current_user['id']})
    if not number:
        raise HTTPException(status_code=404, detail="Phone number not found")
    
    updated_fields = {}
    
    # Handle inbound agent assignment (verify ownership)
    if "inbound_agent_id" in update_data:
        inbound_agent_id = update_data["inbound_agent_id"]
        updated_fields["inbound_agent_id"] = inbound_agent_id
        
        if inbound_agent_id:
            agent = await db.agents.find_one({"id": inbound_agent_id, "user_id": current_user['id']})
            if agent:
                updated_fields["inbound_agent_name"] = agent["name"]
        else:
            updated_fields["inbound_agent_name"] = None
    
    # Handle outbound agent assignment (verify ownership)
    if "outbound_agent_id" in update_data:
        outbound_agent_id = update_data["outbound_agent_id"]
        updated_fields["outbound_agent_id"] = outbound_agent_id
        
        if outbound_agent_id:
            agent = await db.agents.find_one({"id": outbound_agent_id, "user_id": current_user['id']})
            if agent:
                updated_fields["outbound_agent_name"] = agent["name"]
        else:
            updated_fields["outbound_agent_name"] = None
    
    # Handle number update
    if "number" in update_data:
        updated_fields["number"] = update_data["number"]
    
    await db.phone_numbers.update_one({"id": number_id, "user_id": current_user['id']}, {"$set": updated_fields})
    
    # Return updated phone number
    updated_number = await db.phone_numbers.find_one({"id": number_id, "user_id": current_user['id']})
    return PhoneNumber(**updated_number)

@api_router.delete("/phone-numbers/{number_id}")
async def delete_phone_number(number_id: str, current_user: dict = Depends(get_current_user)):
    """Delete a phone number"""
    result = await db.phone_numbers.delete_one({"id": number_id, "user_id": current_user['id']})
    if result.deleted_count == 0:
        raise HTTPException(status_code=404, detail="Phone number not found")
    return {"message": "Phone number deleted successfully"}

# ============ DAILY.CO INTEGRATION ============

async def create_daily_room(agent_id: str) -> dict:
    """Create a Daily.co room for testing"""
    url = "https://api.daily.co/v1/rooms"
    headers = {
        "Authorization": f"Bearer {DAILY_API_KEY}",
        "Content-Type": "application/json"
    }
    
    data = {
        "name": f"retell-{agent_id.replace('-', '')}",
        "privacy": "public",
        "properties": {
            "enable_recording": "cloud",
            "enable_chat": False,
            "enable_knocking": False,
            "start_audio_off": False,
            "start_video_off": True
        }
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=data, headers=headers)
            if response.status_code == 200:
                room_data = response.json()
                return {
                    "room_url": room_data["url"],
                    "room_name": room_data["name"],
                    "config": room_data
                }
            else:
                logger.error(f"Failed to create Daily room: {response.text}")
                return {
                    "room_url": os.environ.get("DAILY_ROOM_URL", "https://aqlyf.daily.co/test"),
                    "room_name": "default",
                    "config": {}
                }
    except Exception as e:
        logger.error(f"Error creating Daily room: {str(e)}")
        return {
            "room_url": os.environ.get("DAILY_ROOM_URL", "https://aqlyf.daily.co/test"),
            "room_name": "default",
            "config": {}
        }

@api_router.post("/test/create-room")
async def create_test_room(agent_id: str):
    """Create a Daily.co room for testing an agent"""
    room = await create_daily_room(agent_id)
    return room

# ============ DEEPGRAM WEBSOCKET PROXY ============

@api_router.websocket("/deepgram-live")
async def deepgram_live_stream(websocket: WebSocket):
    """
    WebSocket proxy for Deepgram Live Streaming with configurable endpointing
    Frontend sends audio chunks, backend forwards to Deepgram and returns transcripts
    """
    await websocket.accept()
    logger.info("üéôÔ∏è Client connected for live streaming")
    
    if not DEEPGRAM_API_KEY:
        await websocket.close(code=1008, reason="Deepgram API key not configured")
        return
    
    import aiohttp
    import asyncio
    from deepgram_config import get_deepgram_url, get_config_summary, DEEPGRAM_CONFIG
    
    # Log current configuration
    config_summary = get_config_summary()
    logger.info(f"üìä Deepgram Config: {config_summary}")
    
    deepgram_ws = None
    
    try:
        # Connect to Deepgram
        deepgram_url = get_deepgram_url()
        headers = {"Authorization": f"Token {DEEPGRAM_API_KEY}"}
        
        async with aiohttp.ClientSession() as session:
            async with session.ws_connect(deepgram_url, headers=headers) as deepgram_ws:
                logger.info("‚úÖ Connected to Deepgram Live API")
                
                # Send config info to client
                await websocket.send_json({
                    "type": "config",
                    "config": config_summary
                })
                
                async def forward_from_client():
                    """Forward audio from client to Deepgram"""
                    try:
                        while True:
                            data = await websocket.receive()
                            
                            if data["type"] == "websocket.receive":
                                if "bytes" in data:
                                    # Forward audio bytes to Deepgram
                                    await deepgram_ws.send_bytes(data["bytes"])
                                elif "text" in data:
                                    # Handle control messages
                                    msg = json.loads(data["text"])
                                    if msg.get("type") == "close":
                                        break
                    except WebSocketDisconnect:
                        logger.info("Client disconnected")
                    except Exception as e:
                        logger.error(f"Error forwarding from client: {e}")
                
                async def forward_from_deepgram():
                    """Forward transcription results from Deepgram to client"""
                    try:
                        async for msg in deepgram_ws:
                            if msg.type == aiohttp.WSMsgType.TEXT:
                                # Forward Deepgram response to client
                                await websocket.send_text(msg.data)
                            elif msg.type == aiohttp.WSMsgType.ERROR:
                                logger.error(f"Deepgram WS error: {deepgram_ws.exception()}")
                                break
                    except Exception as e:
                        logger.error(f"Error forwarding from Deepgram: {e}")
                
                # Run both directions concurrently
                await asyncio.gather(
                    forward_from_client(),
                    forward_from_deepgram(),
                    return_exceptions=True
                )
                
    except Exception as e:
        logger.error(f"Deepgram streaming error: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        logger.info("üîå Deepgram live stream closed")

# ============ HEALTH CHECK ============

@api_router.get("/")
async def root():
    return {
        "message": "Retell AI Clone API",
        "version": "1.0.0",
        "status": "operational"
    }

@api_router.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "database": "connected",
        "deepgram": "configured" if DEEPGRAM_API_KEY else "not configured",
        "openai": "configured" if OPENAI_API_KEY else "not configured",
        "elevenlabs": "configured" if ELEVEN_API_KEY else "not configured",
        "daily": "configured" if DAILY_API_KEY else "not configured"
    }

# ============ WEBSOCKET FOR REAL-TIME CALLING ============

@app.websocket("/ws/call/{call_id}")
async def websocket_call(websocket: WebSocket, call_id: str):
    """WebSocket endpoint for real-time audio streaming and transcription"""
    await websocket.accept()
    logger.info(f"WebSocket connection established for call {call_id}")
    
    call_session = None
    
    try:
        # Get call details from database
        call = await db.calls.find_one({"id": call_id})
        if not call:
            await websocket.send_json({"error": "Call not found"})
            await websocket.close()
            return
        
        # Get agent configuration
        agent = await db.agents.find_one({"id": call["agent_id"]})
        if not agent:
            await websocket.send_json({"error": "Agent not found"})
            await websocket.close()
            return
        
        # Create call session with audio pipeline, passing agent_id for config refresh and KB
        call_session = await create_call_session(call_id, agent, agent_id=call["agent_id"], user_id=agent.get("user_id"), db=db)
        
        # Send ready signal
        await websocket.send_json({
            "type": "ready",
            "message": "Call session initialized"
        })
        
        # Handle incoming messages
        while True:
            message = await websocket.receive()
            
            if "text" in message:
                # Handle text messages (control signals)
                data = json.loads(message["text"])
                msg_type = data.get("type")
                
                if msg_type == "end_call":
                    logger.info(f"Ending call {call_id}")
                    break
                    
                elif msg_type == "user_message":
                    # Process text input from user
                    user_text = data.get("text", "")
                    response = await call_session.process_user_input(user_text)
                    
                    if response:
                        await websocket.send_json({
                            "type": "agent_response",
                            "text": response["text"],
                            "latency": response["latency"]
                        })
                        
                        # Update call transcript
                        await db.calls.update_one(
                            {"id": call_id},
                            {
                                "$push": {
                                    "transcript": {
                                        "role": "user",
                                        "text": user_text,
                                        "timestamp": datetime.utcnow()
                                    }
                                }
                            }
                        )
                        
                        await db.calls.update_one(
                            {"id": call_id},
                            {
                                "$push": {
                                    "transcript": {
                                        "role": "assistant",
                                        "text": response["text"],
                                        "timestamp": datetime.utcnow()
                                    }
                                }
                            }
                        )
            
            elif "bytes" in message:
                # Handle audio data
                audio_data = message["bytes"]
                await call_session.send_audio_chunk(audio_data)
                
    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected for call {call_id}")
    except Exception as e:
        logger.error(f"WebSocket error for call {call_id}: {e}")
        await websocket.send_json({"error": str(e)})
    finally:
        # Clean up call session
        if call_session:
            await close_call_session(call_id)
        await websocket.close()
        logger.info(f"WebSocket closed for call {call_id}")

# ============ TELNYX PHONE SYSTEM ENDPOINTS ============

# Lazy initialize Telnyx service (only when needed)
_telnyx_service = None

def get_telnyx_service(api_key: str = None, connection_id: str = None):
    # For per-user API keys, create a new instance
    if api_key and connection_id:
        return TelnyxService(api_key=api_key, connection_id=connection_id)
    
    # For environment-based keys (webhooks), use singleton
    global _telnyx_service
    if _telnyx_service is None:
        _telnyx_service = TelnyxService()
    return _telnyx_service

# Active calls are now stored in Redis for multi-worker state sharing
# Legacy in-memory dict kept as fallback only (not used when Redis is available)
active_telnyx_calls = {}  # Fallback only - Redis is primary storage

def update_call_state(call_control_id: str, updates: dict):
    """
    Update call state in both Redis and in-memory storage
    Helper function to keep both storages in sync
    """
    # Update Redis
    redis_service.update_call_data(call_control_id, updates)
    
    # Update in-memory fallback
    if call_control_id in active_telnyx_calls:
        active_telnyx_calls[call_control_id].update(updates)

@api_router.post("/telnyx/call/outbound")
async def initiate_outbound_call(
    request: OutboundCallRequest,
    current_user: dict = Depends(get_current_user)
):
    """Initiate an outbound call via Telnyx"""
    try:
        # Get agent and verify ownership
        agent = await db.agents.find_one({"id": request.agent_id, "user_id": current_user["id"]})
        if not agent:
            raise HTTPException(status_code=404, detail="Agent not found")
        
        # Get from_number
        from_number = request.from_number or "+14048000152"
        
        # Create webhook URL - use environment variable for deployment flexibility
        backend_url = os.environ.get("BACKEND_URL")
        if not backend_url:
            raise ValueError("BACKEND_URL environment variable must be set for outbound calls")
        
        # Ensure backend_url has protocol for webhook
        if not backend_url.startswith("http://") and not backend_url.startswith("https://"):
            backend_url = f"https://{backend_url}"
        
        webhook_url = f"{backend_url}/api/telnyx/webhook"
        
        # Create WebSocket streaming URL - use generic endpoint
        # Handle both with and without protocol prefix
        if backend_url.startswith("https://"):
            ws_url = backend_url.replace("https://", "wss://")
        elif backend_url.startswith("http://"):
            ws_url = backend_url.replace("http://", "ws://")
        else:
            # No protocol prefix, assume HTTPS/WSS
            ws_url = f"wss://{backend_url}"
        
        stream_url = f"{ws_url}/api/telnyx/audio-stream"
        logger.info(f"üåê Created WebSocket stream URL: {stream_url}")
        
        # Get user's Telnyx API keys from database
        telnyx_api_key = await get_api_key(current_user["id"], "telnyx")
        telnyx_connection_id = await get_api_key(current_user["id"], "telnyx_connection_id")
        
        if not telnyx_api_key or not telnyx_connection_id:
            raise HTTPException(
                status_code=400, 
                detail="Telnyx API key and Connection ID must be configured in API Keys settings"
            )
        
        # Get voicemail detection settings
        vm_settings = agent.get("settings", {}).get("voicemail_detection", {})
        enable_amd = vm_settings.get("enabled", True) and vm_settings.get("use_telnyx_amd", True)
        amd_mode = vm_settings.get("telnyx_amd_mode", "premium")
        
        # Initiate call via Telnyx WITH streaming parameters AND AMD
        # Pass user's API keys to the service
        telnyx_service = get_telnyx_service(api_key=telnyx_api_key, connection_id=telnyx_connection_id)
        call_result = await telnyx_service.initiate_outbound_call(
            to_number=request.to_number,
            from_number=from_number,
            webhook_url=webhook_url,
            custom_variables=request.custom_variables,
            stream_url=stream_url,
            enable_amd=enable_amd,
            amd_mode=amd_mode
        )
        
        if not call_result.get("success"):
            raise HTTPException(status_code=500, detail=call_result.get("error"))
        
        call_control_id = call_result["call_control_id"]
        
        # Create call log using helper function
        await create_call_log(
            call_id=call_control_id,
            agent_id=request.agent_id,
            direction="outbound",
            from_number=from_number,
            to_number=request.to_number,
            user_id=current_user["id"]
        )
        
        # Store in Redis for multi-worker access
        # Sanitize agent data to remove non-serializable fields (MongoDB ObjectId, datetime)
        agent_sanitized = {}
        for key, value in agent.items():
            if key == "_id":
                continue  # Skip MongoDB ObjectId
            # Convert datetime objects to ISO string
            if isinstance(value, datetime):
                agent_sanitized[key] = value.isoformat()
            else:
                agent_sanitized[key] = value
        
        call_data = {
            "agent_id": request.agent_id,
            "agent": agent_sanitized,
            "custom_variables": request.custom_variables,
            "session": None
        }
        
        # Store in Redis (primary) and in-memory (fallback)
        try:
            redis_service.set_call_data(call_control_id, call_data, ttl=3600)
            active_telnyx_calls[call_control_id] = call_data  # Fallback
            logger.info(f"üì¶ Call data stored in Redis and memory")
        except Exception as e:
            logger.error(f"‚ùå Error storing call data: {e}")
            # Still store in-memory as fallback
            active_telnyx_calls[call_control_id] = call_data
            logger.info(f"‚ö†Ô∏è Stored in memory only (Redis failed)")
        
        logger.info(f"üìû Outbound call initiated: {call_control_id}")
        
        return {
            "success": True,
            "call_id": call_control_id,
            "status": "queued",
            "from_number": from_number,
            "to_number": request.to_number
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error initiating outbound call: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@api_router.websocket("/telnyx/voice-agent-stream/{call_control_id}")
async def telnyx_voice_agent_stream(websocket: WebSocket, call_control_id: str):
    """
    WebSocket endpoint for Telnyx bidirectional RTP streaming + Deepgram Voice Agent
    This is the NEW architecture using unified STT+LLM+TTS
    """
    await websocket.accept()
    logger.info(f"üéôÔ∏è Telnyx Voice Agent WebSocket connected for call: {call_control_id}")
    
    bridge = None
    
    try:
        # Get call data
        if call_control_id not in active_telnyx_calls:
            logger.error(f"‚ùå Call {call_control_id} not found")
            await websocket.close(code=1000, reason="Call not found")
            return
        
        call_data = active_telnyx_calls[call_control_id]
        session = call_data.get("session")
        
        if not session:
            logger.error(f"‚ùå No session for call {call_control_id}")
            await websocket.close(code=1000, reason="No session")
            return
        
        # Get Deepgram API key
        deepgram_api_key = os.environ.get('DEEPGRAM_API_KEY')
        if not deepgram_api_key:
            logger.error("‚ùå DEEPGRAM_API_KEY not set")
            await websocket.close(code=1011, reason="Missing API key")
            return
        
        # Create and start the bridge
        from telnyx_deepgram_bridge import TelnyxDeepgramBridge
        
        bridge = TelnyxDeepgramBridge(
            telnyx_ws=websocket,
            call_control_id=call_control_id,
            session=session,
            deepgram_api_key=deepgram_api_key
        )
        
        logger.info("üåâ Starting Telnyx-Deepgram bridge...")
        await bridge.start()
        
    except Exception as e:
        logger.error(f"‚ùå Error in voice agent stream: {e}", exc_info=True)
    finally:
        logger.info(f"üßπ Cleaning up voice agent stream for {call_control_id}")
        
        if bridge:
            # Get conversation data before closing
            conversation_data = await bridge.stop()
            
            # Save to database
            if call_control_id in active_telnyx_calls:
                await db.call_logs.update_one(
                    {"call_id": call_control_id},
                    {"$set": {
                        "user_transcript": conversation_data.get("user_transcript", []),
                        "agent_transcript": conversation_data.get("agent_transcript", []),
                        "conversation_history": conversation_data.get("conversation_history", [])
                    }}
                )
        
        try:
            await websocket.close()
        except:
            pass


async def handle_assemblyai_streaming(websocket: WebSocket, session, call_id: str, call_control_id: str):
    """Handle streaming with AssemblyAI"""
    from assemblyai_service import AssemblyAIStreamingService
    
    agent_config = session.agent_config
    assemblyai_settings = agent_config.get("settings", {}).get("assemblyai_settings", {})
    threshold = assemblyai_settings.get("threshold", 0.0)
    disable_partial = assemblyai_settings.get("disable_partial_transcripts", False)
    # Smart Endpointing parameters
    end_of_turn_confidence = assemblyai_settings.get("end_of_turn_confidence_threshold", 0.8)
    min_silence_confident = assemblyai_settings.get("min_end_of_turn_silence_when_confident", 500)
    max_silence = assemblyai_settings.get("max_turn_silence", 2000)
    
    # Get user's AssemblyAI API key
    assemblyai_api_key = await get_api_key(session.user_id, "assemblyai")
    if not assemblyai_api_key:
        logger.error("‚ùå No AssemblyAI API key found for user")
        await websocket.close(code=1011, reason="AssemblyAI API key not configured")
        return
    
    logger.info(f"üîë Using user's AssemblyAI API key (first 10 chars): {assemblyai_api_key[:10]}...")
    
    # Initialize AssemblyAI service with user's API key
    assemblyai = AssemblyAIStreamingService(api_key=assemblyai_api_key)
    connected = await assemblyai.connect(
        sample_rate=8000,
        threshold=threshold,
        disable_partial_transcripts=disable_partial,
        end_of_turn_confidence_threshold=end_of_turn_confidence,
        min_end_of_turn_silence_when_confident=min_silence_confident,
        max_turn_silence=max_silence
    )
    
    if not connected:
        logger.error("‚ùå Failed to connect to AssemblyAI")
        await websocket.close(code=1011, reason="AssemblyAI connection failed")
        return
    
    # Transcript accumulation buffer (same conversational logic as Deepgram)
    transcript_buffer = []
    last_transcript_time = None
    processing_task = None
    is_agent_speaking = False
    
    async def process_accumulated_transcript():
        """Process accumulated transcript after a brief delay"""
        nonlocal is_agent_speaking, transcript_buffer, last_transcript_time
        
        await asyncio.sleep(0.8)
        
        if last_transcript_time and (asyncio.get_event_loop().time() - last_transcript_time) < 0.7:
            return
        
        if not transcript_buffer:
            return
        
        full_transcript = " ".join(transcript_buffer).strip()
        transcript_buffer = []
        
        # Filter short utterances and fillers
        if len(full_transcript) < 4:
            logger.info(f"‚è≠Ô∏è  Skipping short: '{full_transcript}'")
            return
        
        fillers = ["um", "uh", "hmm", "mhm", "yeah", "yep", "nope", "ok", "okay"]
        if full_transcript.lower() in fillers:
            logger.info(f"‚è≠Ô∏è  Skipping filler: '{full_transcript}'")
            return
        
        logger.info(f"üìù User said: {full_transcript}")
        
        llm_start_time = time.time()
        
        # Save user transcript to database
        await db.call_logs.update_one(
            {"call_id": call_control_id},
            {"$push": {
                "transcript": {
                    "role": "user",
                    "text": full_transcript,
                    "timestamp": datetime.utcnow().isoformat()
                }
            }}
        )
        logger.info(f"üìù Saved user transcript to database")
        
        is_agent_speaking = True
        response = await session.process_user_input(full_transcript)
        response_text = response.get("text", "")
        response_latency = response.get("latency", 0)
        llm_latency_ms = int((time.time() - llm_start_time) * 1000)  # Convert to ms
        
        logger.info(f"ü§ñ AI response: {response_text}")
        
        # Save agent transcript to database
        await db.call_logs.update_one(
            {"call_id": call_control_id},
            {"$push": {
                "transcript": {
                    "role": "assistant",
                    "text": response_text,
                    "timestamp": datetime.utcnow().isoformat()
                },
                "logs": {
                    "timestamp": datetime.utcnow().isoformat(),
                    "level": "info",
                    "message": f"E2E latency for this turn: {llm_latency_ms}ms (LLM: {int(response_latency * 1000)}ms) | User: '{full_transcript[:60]}...' -> Agent: '{response_text[:60]}...'"
                }
            }}
        )
        logger.info(f"üìù Saved assistant transcript and latency to database")
        
        # Agent config already refreshed at call start - no need to refresh again
        telnyx_service = get_telnyx_service()
        agent_config = session.agent_config
        await telnyx_service.speak_text(call_control_id, response_text, agent_config=agent_config)
        
        if session.should_end_call:
            logger.info("üìû Ending call...")
            await asyncio.sleep(2)
            await telnyx_service.hangup_call(call_control_id)
        
        is_agent_speaking = False
    
    # Callbacks for AssemblyAI messages
    async def on_final_transcript(text, data):
        nonlocal transcript_buffer, last_transcript_time, processing_task
        
        transcript_buffer.append(text)
        last_transcript_time = asyncio.get_event_loop().time()
        
        if processing_task and not processing_task.done():
            processing_task.cancel()
            try:
                await processing_task
            except asyncio.CancelledError:
                pass
        
        processing_task = asyncio.create_task(process_accumulated_transcript())
    
    async def forward_telnyx_to_assemblyai():
        """Forward audio from Telnyx to AssemblyAI with resampling and buffering"""
        from audio_resampler import convert_mulaw_8khz_to_pcm_16khz
        import base64
        audio_packet_count = 0
        buffer = bytearray()  # Buffer to accumulate audio chunks
        BUFFER_SIZE = 3  # Accumulate 3x 20ms chunks = 60ms before sending (optimized from 100ms)
        chunk_counter = 0
        
        try:
            while True:
                # Receive JSON text from Telnyx (same as Deepgram handler)
                message = await websocket.receive_text()
                data = json.loads(message)
                event = data.get("event")
                
                # Telnyx sends: {"event": "media", "media": {"payload": "base64..."}  }
                if event == "media" and "media" in data:
                    # Telnyx sends base64 encoded 8kHz mulaw audio (20ms chunks)
                    mulaw_data = base64.b64decode(data["media"]["payload"])
                    
                    # Convert 8kHz mulaw ‚Üí 16kHz linear PCM for AssemblyAI
                    pcm_16khz = convert_mulaw_8khz_to_pcm_16khz(mulaw_data)
                    
                    # Buffer audio to combine small chunks (20ms ‚Üí 100ms)
                    buffer.extend(pcm_16khz)
                    chunk_counter += 1
                    
                    # Send buffered audio every BUFFER_SIZE chunks (60ms)
                    if chunk_counter >= BUFFER_SIZE:
                        await assemblyai.send_audio(bytes(buffer))
                        audio_packet_count += 1
                        
                        if audio_packet_count == 1:
                            logger.info(f"‚úÖ Started forwarding audio (8kHz mulaw ‚Üí 16kHz PCM, buffered 60ms)")
                        if audio_packet_count % 33 == 0:  # Log every ~2 seconds (33 * 60ms)
                            logger.info(f"üì§ Sent {audio_packet_count} buffered packets to AssemblyAI")
                        
                        # Clear buffer
                        buffer = bytearray()
                        chunk_counter = 0
                        
        except WebSocketDisconnect:
            logger.info(f"üìû WebSocket disconnected. Sent {audio_packet_count} total buffered packets")
        except Exception as e:
            logger.error(f"‚ùå Error forwarding audio to AssemblyAI: {type(e).__name__}: {e}")
    
    # Run both tasks
    try:
        await asyncio.gather(
            forward_telnyx_to_assemblyai(),
            assemblyai.receive_messages(on_final_transcript=on_final_transcript)
        )
    except Exception as e:
        logger.error(f"‚ùå Error in AssemblyAI streaming: {e}")
    finally:
        await assemblyai.close()


async def handle_soniox_streaming(websocket: WebSocket, session, call_id: str, call_control_id: str):
    """Handle streaming with Soniox"""
    from soniox_service import SonioxStreamingService
    from dead_air_monitor import monitor_dead_air
    
    agent_config = session.agent_config
    soniox_settings = agent_config.get("settings", {}).get("soniox_settings", {})
    
    # Extract Soniox settings
    model = soniox_settings.get("model", "stt-rt-preview-v2")
    audio_format = soniox_settings.get("audio_format", "mulaw")
    sample_rate = soniox_settings.get("sample_rate", 8000)
    num_channels = soniox_settings.get("num_channels", 1)
    enable_endpoint_detection = soniox_settings.get("enable_endpoint_detection", True)
    enable_speaker_diarization = soniox_settings.get("enable_speaker_diarization", False)
    language_hints = soniox_settings.get("language_hints", ["en"])
    context = soniox_settings.get("context", "")
    
    # ‚è±Ô∏è  LATENCY TRACKING: Track time of last audio packet received
    last_audio_received_time = None
    stt_start_time = None
    
    # üö¶ INTERRUPTION HANDLING: Track agent speaking state locally
    is_agent_speaking = False
    agent_generating_response = False
    current_playback_ids = set()  # Use set for easier add/remove
    call_ending = False
    
    # Also store in global state for webhook access
    call_states[call_control_id] = {
        "agent_generating_response": False,
        "current_playback_ids": set()
    }
    
    # Get user's Soniox API key
    soniox_api_key = await get_api_key(session.user_id, "soniox")
    if not soniox_api_key:
        logger.error("‚ùå No Soniox API key found for user")
        await websocket.close(code=1011, reason="Soniox API key not configured")
        return
    
    logger.info(f"üîë Using user's Soniox API key (first 10 chars): {soniox_api_key[:10]}...")
    
    # Initialize Soniox service with user's API key
    soniox = SonioxStreamingService(api_key=soniox_api_key)
    connected = await soniox.connect(
        model=model,
        audio_format=audio_format,
        sample_rate=sample_rate,
        num_channels=num_channels,
        enable_endpoint_detection=enable_endpoint_detection,
        enable_speaker_diarization=enable_speaker_diarization,
        language_hints=language_hints,
        context=context
    )
    
    if not connected:
        logger.error("‚ùå Failed to connect to Soniox")
        await websocket.close(code=1011, reason="Soniox connection failed")
        return
    
    # Keep track of accumulated transcript
    accumulated_transcript = ""
    partial_transcript = ""  # Track partial transcripts for interruption detection
    
    # Dead air prevention: Start background monitoring task
    dead_air_task = None
    
    async def check_in_callback(message):
        """Callback for sending check-in messages through TTS"""
        nonlocal current_playback_ids
        try:
            telnyx_service = get_telnyx_service()
            agent_config = session.agent_config
            
            settings = agent_config.get("settings", {})
            tts_provider = settings.get("tts_provider")
            
            # TTS provider is REQUIRED
            if not tts_provider:
                logger.error("‚ùå No TTS provider configured for agent")
                return
            
            use_websocket_tts = False
            if tts_provider == "sesame":
                use_websocket_tts = True
            elif tts_provider == "elevenlabs":
                use_websocket_tts = settings.get("elevenlabs_settings", {}).get("use_websocket_tts", False)
            
            result = await telnyx_service.speak_text(
                call_control_id,
                message,
                agent_config=agent_config,
                use_websocket_tts=use_websocket_tts
            )
            
            if isinstance(result, dict) and "playback_id" in result:
                playback_id = result["playback_id"]
                current_playback_ids.add(playback_id)
                call_states[call_control_id]["current_playback_ids"].add(playback_id)
                
                # Calculate expected duration for check-in message
                word_count = len(message.split())
                estimated_duration = max(0.5, (word_count * 0.15) + 0.3)
                call_states[call_control_id]["playback_expected_end_time"] = time.time() + estimated_duration
                
                logger.info(f"üé¨ Check-in playback ID: {playback_id} (expected duration: {estimated_duration:.2f}s)")
        except Exception as e:
            logger.error(f"Error in check-in callback: {e}")
    
    # Start dead air monitoring in background
    telnyx_svc = get_telnyx_service()
    dead_air_task = asyncio.create_task(
        monitor_dead_air(session, websocket, call_control_id, check_in_callback, telnyx_svc)
    )
    
    # Callback for partial transcripts (for interruption detection)
    async def on_partial_transcript(text, data):
        nonlocal partial_transcript, is_agent_speaking, agent_generating_response, current_playback_ids
        
        # Update partial transcript
        partial_transcript = text
        
        # Dead air prevention: Mark user as speaking when we get any transcript
        if text.strip() and not session.user_speaking:
            session.mark_user_speaking_start()
        
        # DEBUG: Log ALL partials to see if they're coming through
        logger.info(f"üîç PARTIAL TRANSCRIPT: '{text}' | Generating: {agent_generating_response}")
        
        # üö¶ INTERRUPTION DETECTION: Check partial transcripts for interruptions
        # Check BOTH local and global state (webhook might have cleared it)
        currently_generating = agent_generating_response and call_states.get(call_control_id, {}).get("agent_generating_response", False)
        
        if currently_generating and partial_transcript.strip():
            word_count = len(partial_transcript.strip().split())
            logger.info(f"üö¶ BARGE-IN CHECK during response generation: {word_count} words - '{partial_transcript}'")
            
            # ECHO FILTER: Check if this matches recent agent speech (speakerphone echo)
            recent_agent_texts = call_states.get(call_control_id, {}).get("recent_agent_texts", [])
            is_echo = False
            
            if recent_agent_texts:
                import string
                transcript_lower = partial_transcript.lower().strip()
                transcript_normalized = ''.join(c for c in transcript_lower if c not in string.punctuation).strip()
                transcript_words = set(transcript_normalized.split())
                
                for agent_text in recent_agent_texts:
                    agent_lower = agent_text.lower().strip()
                    agent_normalized = ''.join(c for c in agent_lower if c not in string.punctuation).strip()
                    agent_words = set(agent_normalized.split())
                    
                    if len(agent_words) >= 2:
                        common_words = agent_words.intersection(transcript_words)
                        
                        # More aggressive echo detection:
                        # 1. Word similarity check (30% threshold - more sensitive)
                        similarity = len(common_words) / len(agent_words) if len(agent_words) > 0 else 0
                        
                        # 2. Substring match check (if transcript contains significant part of agent text)
                        transcript_in_agent = transcript_normalized in agent_normalized
                        agent_in_transcript = agent_normalized in transcript_normalized
                        
                        # 3. Check if ANY 3+ word phrase matches
                        has_phrase_match = False
                        if len(transcript_words) >= 3:
                            transcript_trigrams = set()
                            words_list = transcript_normalized.split()
                            for i in range(len(words_list) - 2):
                                trigram = ' '.join(words_list[i:i+3])
                                if trigram in agent_normalized:
                                    has_phrase_match = True
                                    break
                        
                        if similarity > 0.3 or transcript_in_agent or agent_in_transcript or has_phrase_match:
                            logger.info(f"üîá ECHO DETECTED (similarity: {similarity:.2f}, substring: {transcript_in_agent or agent_in_transcript}, phrase: {has_phrase_match}) - Ignoring: '{partial_transcript}'")
                            is_echo = True
                            break
            
            # Only trigger interruption if >= 2 words AND not an echo
            if word_count >= 2 and not is_echo:
                logger.info(f"üõë INTERRUPTION TRIGGERED - User said {word_count} words: '{partial_transcript}'")
                logger.info(f"üõë Stopping agent IMMEDIATELY...")
                
                # Stop all active playbacks IMMEDIATELY (but NOT comfort noise)
                telnyx_service = get_telnyx_service()
                comfort_noise_id = call_states.get(call_control_id, {}).get("comfort_noise_playback_id")
                
                stop_tasks = []
                for playback_id in current_playback_ids:
                    # Skip comfort noise - it should keep playing
                    if playback_id != comfort_noise_id:
                        stop_tasks.append(telnyx_service.stop_playback(call_control_id, playback_id))
                
                # Execute all stops concurrently for speed
                if stop_tasks:
                    await asyncio.gather(*stop_tasks, return_exceptions=True)
                    logger.info(f"‚úã Stopped {len(stop_tasks)} playbacks (kept comfort noise)")
                
                current_playback_ids.clear()
                call_states[call_control_id]["current_playback_ids"].clear()
                is_agent_speaking = False
                agent_generating_response = False
                call_states[call_control_id]["agent_generating_response"] = False
                
                # CRITICAL: Do NOT set interruption_triggered = True
                # We just stop playback and let the user's full utterance be processed normally
                # Add brief pause to simulate human reaction time
                await asyncio.sleep(0.4)
                logger.info(f"‚úÖ Agent stopped, user can continue speaking")
    
    # Callback for endpoint detection (when Soniox detects end of utterance)
    async def on_endpoint_detected():
        nonlocal accumulated_transcript, last_audio_received_time, is_agent_speaking, agent_generating_response, current_playback_ids, call_ending, stt_start_time
        
        logger.info(f"üé§ Endpoint detected by Soniox - processing transcript: {accumulated_transcript}")
        
        # Dead air prevention: Mark user as stopped speaking
        session.mark_user_speaking_end()
        
        # Detect "hold on" phrases in user transcript
        if accumulated_transcript.strip():
            session.hold_on_detected = session._detect_hold_on_phrase(accumulated_transcript)
            if session.hold_on_detected:
                logger.info(f"‚è∏Ô∏è 'Hold on' phrase detected - using longer timeout")
            
            # Voicemail/IVR detection (runs in parallel, zero latency)
            should_disconnect, detection_type, confidence = session.voicemail_detector.analyze_transcript(
                accumulated_transcript,
                call_start_time=session.call_start_time
            )
            if should_disconnect:
                logger.warning(f"ü§ñ {detection_type.upper()} DETECTED ({confidence:.2f}) - Disconnecting call")
                call_ending = True
                session.should_end_call = True
                
                # Update call log with detection info
                try:
                    await db.call_logs.update_one(
                        {"call_id": call_control_id},
                        {"$set": {
                            "status": "voicemail_detected",
                            "end_reason": f"{detection_type}_detected_ai",
                            "voicemail_detection": {
                                "method": "ai_pattern_matching",
                                "detection_type": detection_type,
                                "confidence": confidence,
                                "detected_at": datetime.utcnow().isoformat()
                            },
                            "ended_at": datetime.utcnow(),
                            "updated_at": datetime.utcnow()
                        }}
                    )
                except Exception as e:
                    logger.error(f"Error updating call log for voicemail detection: {e}")
                
                # Immediately hang up
                telnyx_svc = get_telnyx_service()
                try:
                    await asyncio.sleep(0.5)  # Brief pause
                    result = await telnyx_svc.hangup_call(call_control_id)
                    logger.info(f"üìû Call hung up due to {detection_type} detection: {result}")
                except Exception as e:
                    logger.error(f"‚ùå Error hanging up call: {e}")
                return
        
        # CRITICAL: Reset agent speaking flag when user starts a new turn
        # This ensures interruption detection is disabled during user turns
        if is_agent_speaking:
            logger.info(f"‚úÖ User starting new turn - resetting agent speaking flag")
            is_agent_speaking = False
            current_playback_ids.clear()
        
        # Skip processing if call is ending
        if call_ending:
            logger.info(f"‚è≠Ô∏è  Skipping processing - call is ending")
            accumulated_transcript = ""
            return
        
        # ‚è±Ô∏è  Calculate STT latency (last audio ‚Üí endpoint detection)
        stt_end_time = time.time()
        stt_latency_ms = 0
        if last_audio_received_time:
            stt_latency_ms = int((stt_end_time - last_audio_received_time) * 1000)
            logger.info(f"‚è±Ô∏è  STT LATENCY: {stt_latency_ms}ms (Soniox)")
        
        # Process with LLM
        if accumulated_transcript.strip():
            try:
                llm_start_time = time.time()
                first_sentence_played = False
                full_response_text = ""
                
                # Log when user stopped speaking
                logger.info(f"‚è±Ô∏è  USER STOPPED SPEAKING at T=0ms")
                
                # üö¶ CRITICAL: Set flags BEFORE LLM starts (enables interruption detection)
                is_agent_speaking = True
                agent_generating_response = True
                call_states[call_control_id]["agent_generating_response"] = True
                logger.info(f"üéôÔ∏è Agent generating response - interruption detection active")
                
                # Dead air prevention: Mark agent as speaking
                session.mark_agent_speaking_start()
                
                # ‚è±Ô∏è  Track TTS start
                tts_start_time = None
                
                # Real-time streaming: Start TTS as sentences arrive
                sentence_queue = []
                tts_tasks = []  # Track TTS generation tasks
                first_tts_started = False
                
                # Stream callback: Generate TTS IMMEDIATELY as sentences arrive
                async def stream_sentence_to_tts(sentence):
                    nonlocal current_playback_ids, first_sentence_played, full_response_text, tts_start_time
                    nonlocal first_tts_started, tts_tasks
                    
                    if not tts_start_time:
                        tts_start_time = time.time()
                    
                    full_response_text += sentence + " "
                    sentence_queue.append(sentence)
                    logger.info(f"üì§ Sentence arrived from LLM: {sentence[:50]}...")
                    
                    # üöÄ START TTS GENERATION IMMEDIATELY (don't wait for LLM to finish!)
                    if not first_tts_started:
                        # First sentence: start immediately
                        first_tts_started = True
                        logger.info(f"‚ö° Starting REAL-TIME TTS for first sentence")
                    
                    # Generate TTS in background (non-blocking)
                    agent_config = session.agent_config
                    tts_task = asyncio.create_task(generate_tts_audio(sentence, agent_config))
                    tts_tasks.append(tts_task)
                    
                    tts_ready_time = int((time.time() - tts_start_time) * 1000)
                    logger.info(f"üéµ TTS task #{len(tts_tasks)} started at +{tts_ready_time}ms")
                
                # Function to play a single sentence (assumes audio is already generated)
                async def play_sentence(sentence, is_first=False):
                    nonlocal current_playback_ids, first_sentence_played
                    
                    telnyx_service = get_telnyx_service()
                    agent_config = session.agent_config
                    
                    # Check if WebSocket TTS is enabled (check provider-specific settings)
                    settings = agent_config.get("settings", {})
                    tts_provider = settings.get("tts_provider")
                    
                    # TTS provider is REQUIRED
                    if not tts_provider:
                        logger.error("‚ùå No TTS provider configured for agent")
                        return
                    
                    if tts_provider == "sesame":
                        # For Sesame, always use WebSocket streaming
                        use_websocket_tts = True
                    elif tts_provider == "elevenlabs":
                        # For ElevenLabs, check the setting
                        use_websocket_tts = settings.get("elevenlabs_settings", {}).get("use_websocket_tts", False)
                    else:
                        use_websocket_tts = False
                    
                    # Play the sentence (this returns playback_id)
                    try:
                        result = await telnyx_service.speak_text(
                            call_control_id, 
                            sentence, 
                            agent_config=agent_config,
                            use_websocket_tts=use_websocket_tts
                        )
                        # Track playback ID if available (in both local and global state)
                        if isinstance(result, dict) and "playback_id" in result:
                            playback_id = result["playback_id"]
                            current_playback_ids.add(playback_id)
                            call_states[call_control_id]["current_playback_ids"].add(playback_id)
                            
                            # Calculate expected duration for this sentence
                            word_count = len(sentence.split())
                            estimated_duration = max(0.5, (word_count * 0.15) + 0.3)
                            call_states[call_control_id]["playback_expected_end_time"] = time.time() + estimated_duration
                            
                            logger.info(f"üé¨ Tracking playback ID for interruption: {playback_id} (expected duration: {estimated_duration:.2f}s)")
                        
                        if is_first and not first_sentence_played:
                            first_sentence_played = True
                            # Calculate TTFT + TTS for first sentence
                            first_audio_ms = int((time.time() - llm_start_time) * 1000)
                            logger.info(f"‚è±Ô∏è  FIRST AUDIO: {first_audio_ms}ms (LLM TTFT + TTS)")
                            
                        return result
                    except Exception as e:
                        logger.error(f"Error playing sentence: {e}")
                        return None
                
                # Save user transcript to database
                await db.call_logs.update_one(
                    {"call_id": call_control_id},
                    {"$push": {
                        "transcript": {
                            "role": "user",
                            "text": accumulated_transcript,
                            "timestamp": datetime.utcnow().isoformat()
                        }
                    }}
                )
                logger.info(f"üìù Saved user transcript to database")
                
                # Process with streaming (TTS generation happens in parallel!)
                response = await session.process_user_input(accumulated_transcript, stream_callback=stream_sentence_to_tts)
                response_text = response.get("text", "")
                response_latency = response.get("latency", 0)
                llm_latency_ms = int((time.time() - llm_start_time) * 1000)
                
                logger.info(f"‚úÖ LLM finished in {llm_latency_ms}ms, TTS tasks already running in background")
                
                # üöÄ STREAMING PLAYBACK: Play chunks as they complete!
                if sentence_queue and tts_tasks:
                    telnyx_service = get_telnyx_service()
                    agent_config = session.agent_config
                    
                    logger.info(f"üéµ Streaming {len(tts_tasks)} TTS chunks as they complete...")
                    
                    # Helper function to save and play audio
                    async def save_and_play(sentence, audio_bytes, sentence_num, total_chunks):
                        import hashlib
                        
                        tts_provider = agent_config.get('settings', {}).get('tts_provider', 'unknown')
                        combined_string = f"{tts_provider}_{sentence}"
                        audio_hash = hashlib.md5(combined_string.encode()).hexdigest()
                        
                        audio_filename = f"tts_{tts_provider}_{audio_hash}.mp3"
                        audio_path = f"/tmp/{audio_filename}"
                        
                        # Save audio
                        with open(audio_path, 'wb') as f:
                            f.write(audio_bytes)
                        
                        backend_url = os.environ.get('BACKEND_URL')
                        if not backend_url:
                            raise ValueError("BACKEND_URL environment variable must be set")
                        audio_url = f"{backend_url}/api/tts-audio/{audio_filename}"
                        
                        playback_start = time.time()
                        result = await telnyx_service.play_audio_url(call_control_id, audio_url)
                        playback_time = int((time.time() - playback_start) * 1000)
                        
                        if isinstance(result, dict) and "playback_id" in result:
                            playback_id = result["playback_id"]
                            current_playback_ids.add(playback_id)
                            call_states[call_control_id]["current_playback_ids"].add(playback_id)
                            
                            # Calculate expected audio duration based on text length
                            word_count = len(sentence.split())
                            estimated_duration = max(0.5, (word_count * 0.15) + 0.3)  # words * 150ms + padding
                            expected_end_time = time.time() + estimated_duration
                            call_states[call_control_id]["playback_expected_end_time"] = expected_end_time
                            
                            timestamp_str = datetime.datetime.now().strftime("%H:%M:%S.%f")[:-3]
                            logger.info(f"‚è±Ô∏è [{timestamp_str}] üîä AGENT AUDIO PLAYBACK STARTED (chunk {sentence_num}/{total_chunks}, API call: {playback_time}ms, expected duration: {estimated_duration:.2f}s)")
                        
                        return result
                    
                    # Wait for ALL tasks to complete IN ORDER
                    # Use gather to preserve order of audio chunks
                    try:
                        # Gather waits for all tasks and returns results in the SAME ORDER as input
                        logger.info(f"üîÑ Waiting for {len(tts_tasks)} TTS tasks to complete...")
                        logger.info(f"   Sentence queue: {[s[:30] + '...' for s in sentence_queue]}")
                        
                        audio_results = await asyncio.gather(*tts_tasks, return_exceptions=True)
                        logger.info(f"‚úÖ All {len(audio_results)} TTS chunks completed")
                        logger.info(f"   Audio sizes: {[len(a) if isinstance(a, bytes) else 'ERROR' for a in audio_results]}")
                        
                        # Now play all in order
                        for i, (sentence, audio_bytes) in enumerate(zip(sentence_queue, audio_results), 1):
                            logger.info(f"üéµ Playing sentence {i}/{len(sentence_queue)}: {sentence[:50]}...")
                            if isinstance(audio_bytes, Exception) or audio_bytes is None:
                                logger.error(f"Error generating TTS for sentence {i}")
                                continue
                            
                            if not audio_bytes or len(audio_bytes) < 1000:
                                logger.warning(f"Invalid audio for sentence {i}, skipping")
                                continue
                            
                            try:
                                await save_and_play(sentence, audio_bytes, i, len(sentence_queue))
                                
                                # Log first audio timing
                                if i == 1 and not first_sentence_played:
                                    first_sentence_played = True
                                    first_audio_ms = int((time.time() - llm_start_time) * 1000)
                                    logger.info(f"‚è±Ô∏è  FIRST AUDIO STARTED: {first_audio_ms}ms from user stop üöÄ")
                            except Exception as e:
                                logger.error(f"Error playing sentence {i}: {e}")
                        
                        logger.info(f"‚úÖ All {len(sentence_queue)} chunks played successfully")
                    
                    except Exception as e:
                        logger.error(f"Error in streaming playback: {e}")
                
                # ‚è±Ô∏è  Calculate total pause and TTS latency
                tts_latency_ms = int((time.time() - tts_start_time) * 1000) if tts_start_time else 0
                total_pause_ms = int((time.time() - stt_end_time) * 1000)
                
                # ‚è±Ô∏è  Log LLM latency breakdown
                logger.info(f"‚è±Ô∏è  LLM LATENCY: {llm_latency_ms}ms (includes processing)")
                logger.info(f"ü§ñ AI Response: {response_text[:100]}...")
                logger.info(f"‚è±Ô∏è  TTS LATENCY: {tts_latency_ms}ms (ElevenLabs)")
                logger.info(f"‚è±Ô∏è  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
                logger.info(f"‚è±Ô∏è  TOTAL PAUSE: {total_pause_ms}ms (user stopped ‚Üí agent speaking)")
                logger.info(f"‚è±Ô∏è  Breakdown: STT={stt_latency_ms}ms + LLM={llm_latency_ms}ms + TTS={tts_latency_ms}ms")
                logger.info(f"‚è±Ô∏è  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
                
                # Save assistant transcript to database
                await db.call_logs.update_one(
                    {"call_id": call_control_id},
                    {"$push": {
                        "transcript": {
                            "role": "assistant",
                            "text": response_text,
                            "timestamp": datetime.utcnow().isoformat()
                        },
                        "logs": {
                            "timestamp": datetime.utcnow().isoformat(),
                            "level": "info",
                            "message": f"E2E latency for this turn: {llm_latency_ms}ms (LLM: {int(response_latency * 1000)}ms) | User: '{accumulated_transcript[:60]}...' -> Agent: '{response_text[:60]}...'"
                        }
                    }}
                )
                
                # Save detailed latency metrics to database
                await db.call_logs.update_one(
                    {"call_id": call_control_id},
                    {"$push": {
                        "logs": {
                            "timestamp": datetime.utcnow().isoformat(),
                            "level": "metrics",
                            "message": f"LATENCY BREAKDOWN - TOTAL: {total_pause_ms}ms | STT: {stt_latency_ms}ms | LLM: {llm_latency_ms}ms | TTS: {tts_latency_ms}ms | Transcript: '{accumulated_transcript[:50]}...'"
                        }
                    }}
                )
                
                logger.info(f"üìù Saved assistant transcript and latency to database")
                
                # Interruption window stays open until Telnyx playback.ended webhooks arrive
                # The webhooks will clear agent_generating_response when ALL audio finishes
                logger.info(f"üîä Agent finished generating, {len(current_playback_ids)} playbacks active - waiting for webhooks to close window")
                
                # Check if we should end call (flow ending node or dead air max checks)
                if session.should_end_call or session.should_end_call_max_checkins() or session.should_end_call_max_duration():
                    call_ending = True
                    
                    # Determine goodbye message
                    if session.should_end_call_max_checkins():
                        logger.info("üìû Ending call - max check-ins reached")
                    elif session.should_end_call_max_duration():
                        logger.info("üìû Ending call - max duration reached")
                    else:
                        logger.info("üìû Ending call - flow ending node")
                    
                    logger.info("üìû Ending call now - waiting for goodbye audio to complete...")
                    await asyncio.sleep(3.5)  # Wait longer to ensure audio fully plays
                    telnyx_svc = get_telnyx_service()
                    logger.info("üìû Now hanging up call...")
                    result = await telnyx_svc.hangup_call(call_control_id)
                    logger.info(f"üìû Hangup result: {result}")
                
                # Reset for next turn
                accumulated_transcript = ""
            
            except Exception as e:
                logger.error(f"‚ùå Error processing transcript: {e}")
                accumulated_transcript = ""
                is_agent_speaking = False
    
    # Callback for final transcript
    async def on_final_transcript(text, data):
        nonlocal accumulated_transcript, last_audio_received_time, stt_start_time, is_agent_speaking, agent_generating_response, current_playback_ids, call_ending
        
        # ‚è±Ô∏è TIMESTAMP: Final transcript received from STT
        transcript_received_time = time.time()
        import datetime
        timestamp_str = datetime.datetime.now().strftime("%H:%M:%S.%f")[:-3]
        
        # Calculate STT latency
        stt_end_time = time.time()
        stt_latency_ms = int((stt_end_time - last_audio_received_time) * 1000) if last_audio_received_time else 0
        
        logger.info(f"‚è±Ô∏è [{timestamp_str}] üìù FINAL TRANSCRIPT RECEIVED: '{text}'")
        logger.info(f"‚è±Ô∏è [{timestamp_str}] STT endpoint detection latency: {stt_latency_ms}ms")
        logger.info(f"‚è±Ô∏è [{timestamp_str}] üé§ USER STOPPED SPEAKING - Beginning processing pipeline")
        
        accumulated_transcript += text
        
        # üö¶ INTERRUPTION DETECTION: Check if agent audio is actively playing
        # Use LOCAL state only (current_playback_ids) - it's the source of truth in this worker
        # Global call_states can be stale due to webhook timing
        has_active_playbacks = len(current_playback_ids) > 0
        word_count = len(accumulated_transcript.strip().split())
        
        # CRITICAL: Also check if agent is GENERATING (before playback starts)
        # If agent_generating_response is False, treat as silent even if playback tracked
        # This prevents race condition where playback.ended webhook hasn't arrived yet
        if has_active_playbacks and not agent_generating_response:
            logger.info(f"‚ö†Ô∏è Playback tracked but agent_generating_response=False - treating as agent SILENT")
            has_active_playbacks = False
        
        # RACE CONDITION FIX: Check if playback should be finished based on calculated duration
        # Don't wait for webhook - calculate when audio should be done and use that
        if has_active_playbacks:
            expected_end_time = call_states.get(call_control_id, {}).get("playback_expected_end_time", 0)
            current_time = time.time()
            
            if expected_end_time > 0 and current_time >= expected_end_time:
                time_overdue = current_time - expected_end_time
                logger.info(f"‚è∞ Audio should be finished (ended {time_overdue:.2f}s ago) - treating as SILENT (webhook delayed)")
                has_active_playbacks = False
                # Clear stale playback IDs
                current_playback_ids.clear()
                if call_control_id in call_states:
                    call_states[call_control_id]["current_playback_ids"] = []
        
        if has_active_playbacks:
            # Agent is actively speaking (audio playing)
            logger.info(f"üö¶ Agent SPEAKING - User said {word_count} word(s), active_playbacks: {len(current_playback_ids)}")
            
            if word_count >= 2:
                # Real interruption (2+ words) - stop agent immediately
                logger.info(f"üõë INTERRUPTION DETECTED - User said {word_count} words: '{accumulated_transcript}'")
                logger.info(f"üõë Stopping {len(current_playback_ids)} active playbacks immediately...")
                
                # Stop all active playbacks IMMEDIATELY (but NOT comfort noise)
                telnyx_service = get_telnyx_service()
                comfort_noise_id = call_states.get(call_control_id, {}).get("comfort_noise_playback_id")
                
                stop_tasks = []
                for playback_id in current_playback_ids:
                    # Skip comfort noise - it should keep playing
                    if playback_id != comfort_noise_id:
                        stop_tasks.append(telnyx_service.stop_playback(call_control_id, playback_id))
                
                if stop_tasks:
                    await asyncio.gather(*stop_tasks, return_exceptions=True)
                    logger.info(f"‚úã Stopped {len(stop_tasks)} playbacks (kept comfort noise)")
                
                current_playback_ids.clear()
                call_states[call_control_id]["current_playback_ids"].clear()
                is_agent_speaking = False
                agent_generating_response = False
                call_states[call_control_id]["agent_generating_response"] = False
                
                await asyncio.sleep(0.4)
                logger.info(f"‚úÖ Agent interrupted, processing user's message: '{accumulated_transcript}'")
                # Fall through to process the transcript
            else:
                # Single-word during agent speech (acknowledgment like "yeah", "okay") - ignore
                logger.info(f"üîï Ignoring 1-word acknowledgment during agent speech: '{accumulated_transcript}'")
                accumulated_transcript = ""
                return  # Don't process
        else:
            # Agent is NOT speaking (no active audio) - process ALL transcripts, including 1-word
            logger.info(f"‚úÖ Agent SILENT - User said {word_count} word(s): '{accumulated_transcript}' - Processing...")
    
    # Forward audio from Telnyx to Soniox
    async def forward_telnyx_to_soniox():
        """Forward audio from Telnyx to Soniox (no resampling needed for mulaw!)"""
        import base64
        audio_packet_count = 0
        nonlocal last_audio_received_time, stt_start_time
        
        try:
            while True:
                # Receive JSON text from Telnyx
                message = await websocket.receive_text()
                data = json.loads(message)
                event = data.get("event")
                
                # Telnyx sends: {"event": "media", "media": {"payload": "base64..."}}
                if event == "media" and "media" in data:
                    # Telnyx sends base64 encoded 8kHz mulaw audio (20ms chunks)
                    mulaw_data = base64.b64decode(data["media"]["payload"])
                    
                    # ‚è±Ô∏è  Track last audio received time for STT latency calculation
                    last_audio_received_time = time.time()
                    if stt_start_time is None:
                        stt_start_time = last_audio_received_time
                    
                    # Send directly to Soniox (no resampling needed!)
                    await soniox.send_audio(mulaw_data)
                    audio_packet_count += 1
                    
                    if audio_packet_count == 1:
                        logger.info(f"‚úÖ Started forwarding audio (8kHz mulaw ‚Üí Soniox, NO BUFFERING)")
                    if audio_packet_count % 50 == 0:  # Log every 1 second (50 * 20ms)
                        logger.info(f"üì§ Sent {audio_packet_count} packets to Soniox")
                        
        except WebSocketDisconnect:
            logger.info(f"üìû WebSocket disconnected. Sent {audio_packet_count} total packets")
        except Exception as e:
            logger.error(f"‚ùå Error forwarding audio to Soniox: {type(e).__name__}: {e}")
    
    # Run both tasks with auto-reconnect for Soniox
    try:
        # Create receive task
        async def receive_with_reconnect():
            """Keep receiving messages, reconnect if Soniox closes"""
            reconnect_attempts = 0
            max_reconnects = 3
            
            while reconnect_attempts < max_reconnects:
                try:
                    await soniox.receive_messages(
                        on_partial_transcript=on_partial_transcript,
                        on_final_transcript=on_final_transcript,
                        on_endpoint_detected=on_endpoint_detected
                    )
                    # If we get here, connection closed normally
                    logger.info("‚úÖ Soniox connection closed normally")
                    break
                except Exception as e:
                    reconnect_attempts += 1
                    logger.warning(f"‚ö†Ô∏è  Soniox connection lost (attempt {reconnect_attempts}/{max_reconnects}): {e}")
                    
                    if reconnect_attempts < max_reconnects:
                        # Reconnect to Soniox
                        logger.info("üîÑ Reconnecting to Soniox...")
                        await soniox.connect()
                        logger.info("‚úÖ Soniox reconnected successfully")
                    else:
                        logger.error("‚ùå Max Soniox reconnect attempts reached")
                        break
        
        await asyncio.gather(
            forward_telnyx_to_soniox(),
            receive_with_reconnect()
        )
    except Exception as e:
        logger.error(f"‚ùå Error in Soniox streaming: {e}")
    finally:
        # Cancel dead air monitoring task
        if dead_air_task:
            dead_air_task.cancel()
            try:
                await dead_air_task
            except asyncio.CancelledError:
                pass
            logger.info(f"üîá Dead air monitoring task cancelled")
        
        await soniox.close()


@api_router.websocket("/telnyx/audio-stream")
async def telnyx_audio_stream_generic(websocket: WebSocket):
    """
    Generic WebSocket endpoint for Telnyx audio streaming
    Telnyx sends call_control_id in the 'start' event, not the URL
    """
    import traceback
    logger.info(f"üîåüîåüîå WEBSOCKET CONNECTION ATTEMPT")
    logger.info(f"   Client: {websocket.client}")
    logger.info(f"   Headers: {dict(websocket.headers)}")
    logger.info(f"   Path: {websocket.url.path}")
    logger.info(f"üîå Incoming Telnyx WebSocket connection")
    
    # Accept the WebSocket connection immediately
    await websocket.accept()
    logger.info(f"‚úÖ WebSocket accepted, waiting for Telnyx events")
    
    call_control_id = None
    deepgram_ws = None
    is_agent_speaking = False
    
    try:
        # First, handle the "connected" event from Telnyx
        while True:
            try:
                message = await asyncio.wait_for(websocket.receive_text(), timeout=60)
                data = json.loads(message)
                event = data.get("event")
                
                logger.info(f"üì¨ Received Telnyx event: {event}")
                
                if event == "connected":
                    logger.info(f"üìû Telnyx connected event received, waiting for 'start'...")
                    continue  # Keep waiting for the "start" event
                
                elif event == "start":
                    # Extract call_control_id from start event
                    call_control_id = data.get("start", {}).get("call_control_id")
                    if not call_control_id:
                        logger.error(f"‚ùå No call_control_id in start event")
                        await websocket.close(code=1000, reason="No call_control_id")
                        return
                    
                    logger.info(f"üé¨ Stream started for call: {call_control_id}")
                    break  # Exit loop and proceed with stream handling
                
                else:
                    logger.warning(f"‚ö†Ô∏è Unexpected event before start: {event}")
                    
            except asyncio.TimeoutError:
                logger.error(f"‚ùå Timeout waiting for events (60s)")
                await websocket.close(code=1000, reason="Timeout")
                return
        
        # Wait for call data to be ready (check Redis for cross-worker support)
        max_wait = 15
        wait_time = 0
        call_data = None
        
        while not call_data:
            # Check Redis first (cross-worker), then in-memory fallback
            call_data = redis_service.get_call_data(call_control_id) or active_telnyx_calls.get(call_control_id)
            
            if wait_time >= max_wait:
                logger.error(f"‚ùå Timeout waiting for call data after {max_wait}s")
                await websocket.close(code=1000, reason="Call data timeout")
                return
            
            if not call_data:
                await asyncio.sleep(0.2)
                wait_time += 0.2
        
        logger.info(f"‚úÖ Call data found after {wait_time}s wait")
        
        # Get session from call_data (created by webhook handler in same or different worker)
        # Check if session already exists (created by webhook)
        from calling_service import get_call_session, create_call_session
        
        session = await get_call_session(call_control_id)
        
        if not session:
            # Session doesn't exist yet - WebSocket arrived before webhook finished
            # Wait for session ready flag from webhook handler
            logger.info("‚è≥ Session not found locally, waiting for webhook to create it...")
            
            max_session_wait = 10
            session_wait = 0
            session_ready = redis_service.is_session_ready(call_control_id)
            
            while not session_ready and session_wait < max_session_wait:
                await asyncio.sleep(0.5)
                session_wait += 0.5
                session_ready = redis_service.is_session_ready(call_control_id)
            
            logger.info(f"üîç Session ready flag: {session_ready}, waited {session_wait}s")
            
            if session_ready:
                logger.info(f"‚úÖ Session marked ready by webhook after {session_wait}s")
                # Try to get session again
                session = await get_call_session(call_control_id)
                logger.info(f"üîç Session after get_call_session: {session is not None}")
            
            logger.info(f"üîç Session status before fallback: {session is not None}")
            
            if not session:
                # Still no session - create it ourselves in this worker
                logger.warning("‚ö†Ô∏è Session not found after waiting, creating in WebSocket worker...")
                
                # Re-fetch call_data from Redis to ensure we have latest data
                call_data_fresh = redis_service.get_call_data(call_control_id)
                if not call_data_fresh:
                    logger.error("‚ùå Cannot retrieve call data from Redis")
                    await websocket.close(code=1000, reason="No call data")
                    return
                
                agent = call_data_fresh.get("agent")
                agent_id = call_data_fresh.get("agent_id")
                
                if not agent or not agent_id:
                    logger.error(f"‚ùå No agent data in call_data. Keys: {list(call_data_fresh.keys())}")
                    await websocket.close(code=1000, reason="No agent data")
                    return
                
                # Get user_id from agent
                user_id = agent.get("user_id")
                
                logger.info(f"üìù Creating session with agent_id={agent_id}, user_id={user_id}")
                
                # Create session in this worker
                session = await create_call_session(
                    call_control_id,
                    agent,
                    agent_id=agent_id,
                    user_id=user_id,
                    db=db
                )
                
                # Update custom variables
                custom_variables = call_data_fresh.get("custom_variables", {})
                session.session_variables.update(custom_variables)
                
                logger.info("‚úÖ Session created in WebSocket worker")
        else:
            logger.info("‚úÖ Session found in this worker's active_sessions")
        
        # Get agent configuration and check STT provider
        agent_config = session.agent_config
        stt_provider = agent_config.get("settings", {}).get("stt_provider")
        
        # STT provider is REQUIRED - no defaults
        if not stt_provider:
            logger.error("‚ùå No STT provider configured for agent")
            await websocket.close(code=1011, reason="STT provider not configured in agent settings")
            return
        
        logger.info(f"üìû Call data loaded, starting {stt_provider.upper()} connection...")
        
        # Route to appropriate STT provider based on agent configuration
        if stt_provider == "assemblyai":
            # Use AssemblyAI for STT
            from assemblyai_service import AssemblyAIStreamingService
            await handle_assemblyai_streaming(websocket, session, call_control_id, call_control_id)
            return
        elif stt_provider == "soniox":
            # Use Soniox for STT
            from soniox_service import SonioxStreamingService
            await handle_soniox_streaming(websocket, session, call_control_id, call_control_id)
            return
        elif stt_provider == "deepgram":
            # Use Deepgram for STT (explicitly configured)
            deepgram_settings = agent_config.get("settings", {}).get("deepgram_settings", {})
            endpointing = deepgram_settings.get("endpointing", 500)
            interim_results = deepgram_settings.get("interim_results", False)
            punctuate = deepgram_settings.get("punctuate", True)
            smart_format = deepgram_settings.get("smart_format", True)
        vad_events = deepgram_settings.get("vad_events", True)
        
        logger.info(f"‚öôÔ∏è  Deepgram settings: endpointing={endpointing}ms, interim={interim_results}, punctuate={punctuate}, smart_format={smart_format}, vad_events={vad_events}")
        
        # Get user's Deepgram API key
        deepgram_api_key = await get_api_key(session.user_id, "deepgram")
        if not deepgram_api_key:
            logger.error("‚ùå No Deepgram API key found for user")
            await websocket.close(code=1011, reason="Deepgram API key not configured")
            return
        
        logger.info(f"üîë Using user's Deepgram API key (first 10 chars): {deepgram_api_key[:10]}...")
        
        # Connect to Deepgram using raw websockets (SDK has issues with v2)
        deepgram_ws = None
        
        try:
            # Build Deepgram WebSocket URL with agent-specific settings
            # NOTE: utterance_end_ms and vad_turnoff parameters removed - cause HTTP 400 error on WebSocket API
            deepgram_url = (
                f"wss://api.deepgram.com/v1/listen?"
                f"model=nova-3&"
                f"encoding=mulaw&"
                f"sample_rate=8000&"
                f"channels=1&"
                f"punctuate={'true' if punctuate else 'false'}&"
                f"interim_results={'true' if interim_results else 'false'}&"
                f"endpointing={endpointing}&"
                f"vad_events={'true' if vad_events else 'false'}&"
                f"smart_format={'true' if smart_format else 'false'}"
            )
            
            logger.info(f"üîó Deepgram URL: {deepgram_url[:150]}...")
            
            # Connect with user's API key
            deepgram_ws = await websockets.connect(
                deepgram_url,
                extra_headers={"Authorization": f"Token {deepgram_api_key}"}
            )
            
            logger.info("‚úÖ Connected to Deepgram live streaming")
            logger.info("üöÄ Starting bidirectional audio streaming...")
            
            # Task to forward audio from Telnyx to Deepgram
            async def forward_telnyx_to_deepgram():
                nonlocal is_agent_speaking
                try:
                    audio_packet_count = 0
                    logger.info(f"üëÇ Starting to listen for Telnyx media...")
                    
                    while True:
                        message = await websocket.receive_text()
                        data = json.loads(message)
                        event = data.get("event")
                        
                        if event == "media":
                            if not is_agent_speaking:
                                media = data.get("media", {})
                                payload = media.get("payload", "")
                                if payload:
                                    # Decode base64 audio and send to Deepgram
                                    audio_bytes = base64.b64decode(payload)
                                    await deepgram_ws.send(audio_bytes)
                                    audio_packet_count += 1
                                    if audio_packet_count % 100 == 0:
                                        logger.info(f"üì° Forwarded {audio_packet_count} packets")
                        elif event == "stop":
                            logger.info(f"‚èπÔ∏è Telnyx stream stopped")
                            break
                            
                except Exception as e:
                    logger.error(f"‚ùå Error forwarding audio: {e}")
            
            # Task to receive transcripts from Deepgram
            # Accumulation buffer for natural conversation flow
            transcript_buffer = []
            last_transcript_time = None
            processing_task = None
            
            async def process_accumulated_transcript():
                """Process accumulated transcript after a brief delay"""
                nonlocal is_agent_speaking, transcript_buffer, last_transcript_time
                
                await asyncio.sleep(0.8)  # Wait 800ms to see if more speech comes
                
                # Check if new speech came in during wait
                if last_transcript_time and (asyncio.get_event_loop().time() - last_transcript_time) < 0.7:
                    return  # More speech coming, don't process yet
                
                if not transcript_buffer:
                    return
                
                # Combine accumulated transcripts
                full_transcript = " ".join(transcript_buffer).strip()
                transcript_buffer = []
                
                # Filter out very short utterances (um, uh, yeah, etc.)
                if len(full_transcript) < 4:
                    logger.info(f"‚è≠Ô∏è  Skipping short utterance: '{full_transcript}'")
                    return
                
                # Filter out common filler words when alone
                fillers = ["um", "uh", "hmm", "mhm", "yeah", "yep", "nope", "ok", "okay"]
                if full_transcript.lower() in fillers:
                    logger.info(f"‚è≠Ô∏è  Skipping filler word: '{full_transcript}'")
                    return
                
                logger.info(f"üìù User said: {full_transcript}")
                
                llm_start_time = time.time()
                
                # Save user transcript to database
                await db.call_logs.update_one(
                    {"call_id": call_control_id},
                    {"$push": {
                        "transcript": {
                            "role": "user",
                            "text": full_transcript,
                            "timestamp": datetime.utcnow().isoformat()
                        }
                    }}
                )
                logger.info(f"üìù Saved user transcript to database")
                
                # Process with AI
                is_agent_speaking = True
                response = await session.process_user_input(full_transcript)
                response_text = response.get("text", "")
                response_latency = response.get("latency", 0)
                llm_latency_ms = int((time.time() - llm_start_time) * 1000)  # Convert to ms
                
                logger.info(f"ü§ñ AI response: {response_text}")
                
                # Save agent transcript to database
                await db.call_logs.update_one(
                    {"call_id": call_control_id},
                    {"$push": {
                        "transcript": {
                            "role": "assistant",
                            "text": response_text,
                            "timestamp": datetime.utcnow().isoformat()
                        },
                        "logs": {
                            "timestamp": datetime.utcnow().isoformat(),
                            "level": "info",
                            "message": f"E2E latency for this turn: {llm_latency_ms}ms (LLM: {int(response_latency * 1000)}ms) | User: '{full_transcript[:60]}...' -> Agent: '{response_text[:60]}...'"
                        }
                    }}
                )
                logger.info(f"üìù Saved assistant transcript and latency to database")
                
                # Speak response with agent config for TTS routing
                telnyx_service = get_telnyx_service()
                agent_config = session.agent_config
                await telnyx_service.speak_text(call_control_id, response_text, agent_config=agent_config)
                
                # Check if we should end call
                if session.should_end_call:
                    logger.info("üìû Ending call...")
                    await asyncio.sleep(2)
                    await telnyx_service.hangup_call(call_control_id)
                
                is_agent_speaking = False
            
            async def process_deepgram_transcripts():
                nonlocal is_agent_speaking, transcript_buffer, last_transcript_time, processing_task
                try:
                    async for message in deepgram_ws:
                        result = json.loads(message)
                        msg_type = result.get("type")
                        
                        # Check if it's a transcript result
                        if msg_type == "Results":
                            transcript = result.get("channel", {}).get("alternatives", [{}])[0].get("transcript", "")
                            is_final = result.get("is_final", False)
                            
                            # Accumulate final transcripts
                            if transcript and is_final:
                                transcript_buffer.append(transcript)
                                last_transcript_time = asyncio.get_event_loop().time()
                                
                                # Cancel any pending processing and schedule new one
                                if processing_task and not processing_task.done():
                                    processing_task.cancel()
                                    try:
                                        await processing_task
                                    except asyncio.CancelledError:
                                        pass
                                
                                # Schedule processing with delay
                                processing_task = asyncio.create_task(process_accumulated_transcript())
                                
                except Exception as e:
                    logger.error(f"‚ùå Error processing transcripts: {e}")
            
            # Run both tasks concurrently
            await asyncio.gather(
                forward_telnyx_to_deepgram(),
                process_deepgram_transcripts()
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error in streaming: {e}", exc_info=True)
        finally:
            if deepgram_ws:
                await deepgram_ws.close()
                logger.info("üîå Deepgram connection closed")
        
    except Exception as e:
        logger.error(f"‚ùå Error in WebSocket handler: {e}", exc_info=True)
    finally:
        if deepgram_ws:
            await deepgram_ws.close()
        logger.info(f"üîå Telnyx WebSocket disconnected")


@api_router.websocket("/telnyx/audio-stream/{call_control_id}")
async def telnyx_audio_stream(websocket: WebSocket, call_control_id: str):
    """
    WebSocket endpoint for bidirectional real-time audio streaming with Telnyx
    Telnyx ‚Üí Our WS ‚Üí Deepgram STT ‚Üí AI ‚Üí Telnyx TTS
    """
    logger.info(f"üîå Incoming WebSocket connection for call: {call_control_id}")
    
    # Accept the WebSocket connection immediately
    await websocket.accept()
    logger.info(f"‚úÖ WebSocket accepted for call: {call_control_id}")
    
    deepgram_ws = None
    is_agent_speaking = False
    last_agent_text = ""
    
    try:
        # Accept connection immediately and respond to keep-alive
        logger.info(f"üìû WebSocket connection accepted, ready for Telnyx")
        
        # Send immediate acknowledgment (helps with connection validation)
        try:
            await websocket.send_text(json.dumps({
                "event": "ready",
                "timestamp": datetime.utcnow().isoformat()
            }))
        except:
            pass  # Telnyx might not expect this, but doesn't hurt
        
        # Wait for call data to be ready (Telnyx tests connection during API call)
        max_wait = 15  # 15 seconds to allow for setup
        wait_time = 0
        
        while call_control_id not in active_telnyx_calls:
            if wait_time >= max_wait:
                logger.error(f"‚ùå Timeout waiting for call data after {max_wait}s")
                # Don't close immediately - maybe Telnyx is just testing
                try:
                    await websocket.close(code=1000, reason="Ready but no call data")
                except:
                    pass
                return
            
            await asyncio.sleep(0.2)
            wait_time += 0.2
            
            if wait_time % 2 == 0 and wait_time > 0:
                logger.info(f"‚è≥ Waiting for call data... ({wait_time:.1f}s)")
        
        call_data = active_telnyx_calls[call_control_id]
        session = call_data.get("session")
        
        if not session:
            # Wait a bit more for session to be created
            await asyncio.sleep(1)
            session = call_data.get("session")
            
            if not session:
                logger.error(f"‚ùå No session for call {call_control_id} - closing")
                await websocket.close(code=1000, reason="No session")
                return
        
        last_agent_text = call_data.get("last_agent_text", "")
        agent_config = session.agent_config
        logger.info(f"üìû Call data loaded, starting Deepgram connection...")
        
        # Get Deepgram settings from agent configuration
        deepgram_settings = agent_config.get("settings", {}).get("deepgram_settings", {})
        endpointing = deepgram_settings.get("endpointing", 500)
        interim_results = deepgram_settings.get("interim_results", False)
        punctuate = deepgram_settings.get("punctuate", True)
        smart_format = deepgram_settings.get("smart_format", True)
        vad_events = deepgram_settings.get("vad_events", True)
        
        logger.info(f"‚öôÔ∏è Deepgram settings: endpointing={endpointing}ms, interim={interim_results}, punctuate={punctuate}, smart_format={smart_format}, vad_events={vad_events}")
        
        # Connect to Deepgram's live streaming API with agent-specific settings
        # NOTE: utterance_end_ms and vad_turnoff parameters removed - cause HTTP 400 error on WebSocket API
        deepgram_url = (
            f"wss://api.deepgram.com/v1/listen?"
            f"model=nova-3&"
            f"encoding=mulaw&"
            f"sample_rate=8000&"
            f"channels=1&"
            f"punctuate={'true' if punctuate else 'false'}&"
            f"interim_results={'true' if interim_results else 'false'}&"
            f"endpointing={endpointing}&"
            f"vad_events={'true' if vad_events else 'false'}&"
            f"smart_format={'true' if smart_format else 'false'}"
        )
        
        logger.info(f"üîó Deepgram URL: {deepgram_url[:150]}...")
        logger.info(f"‚öôÔ∏è Deepgram settings: endpointing={endpointing}ms, interim={interim_results}, punctuate={punctuate}, smart_format={smart_format}, vad_events={vad_events}")
        logger.info(f"üåê Connecting to Deepgram...")
        
        try:
            deepgram_ws = await websockets.connect(
                deepgram_url,
                extra_headers={"Authorization": f"Token {DEEPGRAM_API_KEY}"},
                ping_interval=20,
                ping_timeout=10
            )
            logger.info(f"‚úÖ Connected to Deepgram live streaming")
        except Exception as e:
            logger.error(f"‚ùå Failed to connect to Deepgram: {e}")
            await websocket.close(code=1011, reason="Deepgram connection failed")
            return
        
        # Task to receive audio from Telnyx and forward to Deepgram
        async def forward_telnyx_to_deepgram():
            nonlocal is_agent_speaking
            try:
                audio_packet_count = 0
                logger.info(f"üëÇ Starting to listen for Telnyx messages...")
                while True:
                    # Receive message from Telnyx
                    message = await websocket.receive_text()
                    data = json.loads(message)
                    
                    event = data.get("event")
                    logger.info(f"üì¨ Received Telnyx event: {event}")
                    
                    if event == "connected":
                        logger.info(f"üìû Telnyx stream connected: {data}")
                    
                    elif event == "start":
                        logger.info(f"üé¨ Telnyx stream started: {data}")
                    
                    elif event == "media":
                        # Only forward audio when agent is NOT speaking
                        if not is_agent_speaking:
                            media = data.get("media", {})
                            payload = media.get("payload", "")
                            
                            if payload:
                                # Decode base64 audio and send to Deepgram
                                audio_bytes = base64.b64decode(payload)
                                await deepgram_ws.send(audio_bytes)
                                
                                audio_packet_count += 1
                                if audio_packet_count % 100 == 0:
                                    logger.info(f"üì° Forwarded {audio_packet_count} packets")
                        else:
                            if audio_packet_count % 200 == 0:
                                logger.debug(f"üîá Skipping media (agent speaking)")
                    
                    elif event == "stop":
                        logger.info(f"‚èπÔ∏è Telnyx stream stopped")
                        break
                    else:
                        logger.info(f"üì• Unknown Telnyx event: {event}, full data: {json.dumps(data)[:200]}")
                        
            except WebSocketDisconnect:
                logger.info(f"üîå Telnyx WebSocket disconnected")
            except Exception as e:
                logger.error(f"‚ùå Error forwarding Telnyx audio: {e}", exc_info=True)
        
        # Task to receive transcripts from Deepgram and process
        async def process_deepgram_transcripts():
            nonlocal is_agent_speaking, last_agent_text
            
            try:
                async for message in deepgram_ws:
                    result = json.loads(message)
                    msg_type = result.get("type")
                    
                    if msg_type == "Results":
                        channel = result.get("channel", {})
                        alternatives = channel.get("alternatives", [])
                        
                        if alternatives:
                            transcript = alternatives[0].get("transcript", "")
                            is_final = channel.get("is_final", False)
                            speech_final = result.get("speech_final", False)
                            
                            # Only process when we have final speech
                            if transcript and speech_final:
                                logger.info(f"üìù User said (final): {transcript}")
                                
                                # Echo filter
                                if last_agent_text:
                                    transcript_lower = transcript.lower()
                                    agent_words = set(last_agent_text.lower().split())
                                    transcript_words = set(transcript_lower.split())
                                    
                                    if transcript_words and agent_words:
                                        overlap = len(transcript_words & agent_words)
                                        overlap_ratio = overlap / len(transcript_words)
                                        
                                        if overlap_ratio > 0.7:
                                            logger.warning(f"üîá Filtered echo: {transcript} ({overlap_ratio:.0%})")
                                            continue
                                
                                # Mark agent as speaking to stop audio forwarding
                                is_agent_speaking = True
                                
                                # Save user transcript
                                await db.call_logs.update_one(
                                    {"call_id": call_control_id},
                                    {"$push": {
                                        "transcript": {
                                            "role": "user",
                                            "text": transcript,
                                            "timestamp": datetime.utcnow().isoformat()
                                        }
                                    }}
                                )
                                
                                # Process through AI
                                response = await session.process_user_input(transcript)
                                response_text = response.get("text", "I'm sorry, I didn't understand that.")
                                
                                logger.info(f"ü§ñ AI response: {response_text}")
                                
                                # Save agent transcript
                                await db.call_logs.update_one(
                                    {"call_id": call_control_id},
                                    {"$push": {
                                        "transcript": {
                                            "role": "assistant",
                                            "text": response_text,
                                            "timestamp": datetime.utcnow().isoformat()
                                        }
                                    }}
                                )
                                
                                # Get agent config for TTS routing
                                agent_config = session.agent_config
                                
                                # Speak via Telnyx with agent config for TTS routing
                                telnyx_service = get_telnyx_service()
                                logger.info(f"üîç About to call speak_text with agent_config type: {type(agent_config)}, is None: {agent_config is None}")
                                if agent_config:
                                    logger.info(f"üîç agent_config has settings: {'settings' in agent_config}")
                                await telnyx_service.speak_text(
                                    call_control_id, 
                                    response_text,
                                    agent_config=agent_config
                                )
                                logger.info(f"üîä Spoke response")
                                
                                last_agent_text = response_text
                                call_data["last_agent_text"] = response_text
                                
                                # Check if should end call
                                if session.should_end_call:
                                    logger.info(f"üìû Ending node reached - hanging up")
                                    # Wait for speech to finish
                                    word_count = len(response_text.split())
                                    speech_duration = max(2, (word_count * 0.15) + 1)
                                    await asyncio.sleep(speech_duration)
                                    
                                    # Hangup
                                    await telnyx_service.hangup_call(call_control_id)
                                    
                                    # Cleanup
                                    # Clean up from Redis and in-memory
                                    redis_service.delete_call_data(call_control_id)
                                    if call_control_id in active_telnyx_calls:
                                        del active_telnyx_calls[call_control_id]
                                    break
                                
                                # Wait for speech to complete
                                word_count = len(response_text.split())
                                speech_duration = max(2, (word_count * 0.15) + 1)
                                await asyncio.sleep(speech_duration)
                                
                                # Resume listening
                                is_agent_speaking = False
                                logger.info(f"üëÇ Listening for next input...")
                    
                    elif msg_type == "SpeechStarted":
                        logger.debug(f"üé§ Speech started (VAD)")
                    
                    elif msg_type == "UtteranceEnd":
                        logger.debug(f"‚è∏Ô∏è Utterance ended (VAD)")
                        
            except Exception as e:
                logger.error(f"‚ùå Error processing Deepgram: {e}", exc_info=True)
        
        # Run both tasks concurrently
        logger.info(f"üöÄ Starting bidirectional audio streaming...")
        await asyncio.gather(
            forward_telnyx_to_deepgram(),
            process_deepgram_transcripts()
        )
        
    except Exception as e:
        logger.error(f"‚ùå Fatal error in audio stream: {e}", exc_info=True)
    finally:
        logger.info(f"üßπ Cleaning up audio stream for {call_control_id}")
        if deepgram_ws:
            await deepgram_ws.close()
        try:
            await websocket.close()
        except:
            pass


async def transcribe_audio_deepgram(audio_data: bytes) -> str:
    """Transcribe audio using Deepgram Nova-3"""
    try:
        url = "https://api.deepgram.com/v1/listen"
        headers = {
            "Authorization": f"Token {DEEPGRAM_API_KEY}",
            "Content-Type": "audio/raw"
        }
        
        params = {
            "model": "nova-3",
            "encoding": "mulaw",
            "sample_rate": 8000,
            "channels": 1,
            "punctuate": True,
            "utterances": False
        }
        
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                url,
                headers=headers,
                params=params,
                content=audio_data
            )
            
            if response.status_code == 200:
                result = response.json()
                transcript = result.get("results", {}).get("channels", [{}])[0].get("alternatives", [{}])[0].get("transcript", "")
                return transcript
            else:
                logger.error(f"Deepgram error: {response.status_code} - {response.text}")
                return ""
                
    except Exception as e:
        logger.error(f"Error transcribing audio: {e}")
        return ""


async def transcribe_audio_deepgram_file(audio_data: bytes) -> str:
    """Transcribe audio file (WAV/MP3) using Deepgram Nova-3 with enhanced settings"""
    try:
        url = "https://api.deepgram.com/v1/listen"
        headers = {
            "Authorization": f"Token {DEEPGRAM_API_KEY}",
            "Content-Type": "audio/wav"
        }
        
        params = {
            "model": "nova-3",
            "punctuate": True,
            "utterances": False,
            "smart_format": True,
            "language": "en-US"
        }
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                url,
                headers=headers,
                params=params,
                content=audio_data
            )
            
            if response.status_code == 200:
                result = response.json()
                transcript = result.get("results", {}).get("channels", [{}])[0].get("alternatives", [{}])[0].get("transcript", "")
                confidence = result.get("results", {}).get("channels", [{}])[0].get("alternatives", [{}])[0].get("confidence", 0)
                logger.info(f"‚úÖ Deepgram transcription (confidence: {confidence:.2f}): {transcript[:100]}...")
                return transcript
            else:
                logger.error(f"Deepgram error: {response.status_code} - {response.text}")
                return ""
                
    except Exception as e:
        logger.error(f"Error transcribing audio file: {e}")
        return ""


async def generate_audio_elevenlabs_streaming(text: str, settings: dict = None, user_id: str = None):
    """Generate audio using ElevenLabs TTS streaming API for lower latency"""
    try:
        # Get ElevenLabs settings from agent or use defaults
        elevenlabs_settings = settings.get("elevenlabs_settings", {}) if settings else {}
        
        voice_id = elevenlabs_settings.get("voice_id", "21m00Tcm4TlvDq8ikWAM")
        model = elevenlabs_settings.get("model", "eleven_turbo_v2_5")
        
        # Don't override if user explicitly chose a model
        # Just log what we're using
        if model == "eleven_v3":
            logger.info(f"üöÄ Using Eleven v3 (Alpha - most expressive, not for real-time)")
        elif model == "eleven_turbo_v2":
            logger.info(f"‚ö° Using Turbo v2 (balanced)")
        elif model == "eleven_multilingual_v3":
            # Legacy handling if someone has this in their config
            model = "eleven_v3"
            logger.info(f"üöÄ Upgraded to Eleven v3 (Alpha)")
        elif model == "eleven_turbo_v2_5":
            logger.info(f"‚ö° Using Turbo v2.5 (high quality)")
        elif model == "eleven_flash_v2_5":
            logger.info(f"‚ö° Using Flash v2.5 (fastest - 75ms)")
        elif model == "eleven_flash_v2":
            logger.info(f"‚ö° Using Flash v2 (fast)")
        
        stability = elevenlabs_settings.get("stability", 0.5)
        similarity_boost = elevenlabs_settings.get("similarity_boost", 0.75)
        style = elevenlabs_settings.get("style", 0.0)
        speed = elevenlabs_settings.get("speed", 1.0)
        use_speaker_boost = elevenlabs_settings.get("use_speaker_boost", True)
        enable_normalization = elevenlabs_settings.get("enable_normalization", True)
        enable_ssml_parsing = elevenlabs_settings.get("enable_ssml_parsing", False)
        
        # Convert boolean to ElevenLabs API format
        # apply_text_normalization accepts: 'auto', 'on', 'off'
        normalization_value = "on" if enable_normalization else "off"
        
        logger.info(f"üéôÔ∏è ElevenLabs streaming TTS: voice={voice_id}, model={model}, speed={speed}, normalization={normalization_value}, ssml={enable_ssml_parsing}")
        
        # Use streaming endpoint
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream"
        
        # Get API key from user's keys or fallback to env
        if user_id:
            try:
                eleven_key = await get_user_api_key(user_id, "elevenlabs")
            except Exception as e:
                logger.error(f"Failed to get user ElevenLabs key: {e}")
                eleven_key = None
        else:
            eleven_key = os.environ.get('ELEVEN_API_KEY')
        
        if not eleven_key:
            logger.error("ElevenLabs API key not found")
            return None
        
        headers = {
            "xi-api-key": eleven_key,
            "Content-Type": "application/json"
        }
        
        data = {
            "text": text,
            "model_id": model,
            "voice_settings": {
                "stability": stability,
                "similarity_boost": similarity_boost,
                "use_speaker_boost": use_speaker_boost,
                "speed": speed
            },
            "apply_text_normalization": normalization_value,
            "enable_ssml_parsing": enable_ssml_parsing,
            "optimize_streaming_latency": 4  # Maximum optimization
        }
        
        # Add style for v2 models only (v3 doesn't support it)
        if "v2" in model or "turbo" in model or "flash" in model:
            data["voice_settings"]["style"] = style
        
        # CRITICAL DEBUGGING: Log exact payload being sent
        logger.info(f"üì¶ ElevenLabs Request Payload:")
        logger.info(f"   Text length: {len(text)} chars")
        logger.info(f"   Text content: {repr(text)}")  # repr shows hidden chars
        logger.info(f"   Text bytes: {text.encode('utf-8')[:100]}")  # Check encoding
        logger.info(f"   Model: {model}")
        logger.info(f"   Voice ID: {voice_id}")
        logger.info(f"   URL: {url}")
        logger.info(f"   Full data: {data}")
        
        # Stream the response and collect chunks with retry logic
        max_retries = 2
        for attempt in range(max_retries):
            try:
                timeout_seconds = 10.0  # Reduced from 30s
                logger.info(f"üîå Attempting ElevenLabs connection (attempt {attempt + 1}/{max_retries})")
                logger.info(f"   Timeout: {timeout_seconds}s")
                
                import time
                start_time = time.time()
                
                async with httpx.AsyncClient(timeout=timeout_seconds) as client:
                    logger.info(f"   ‚úì HTTP client created ({time.time() - start_time:.3f}s)")
                    
                    logger.info(f"   ‚Üí Sending POST request to ElevenLabs...")
                    async with client.stream('POST', url, headers=headers, json=data) as response:
                        logger.info(f"   ‚úì Connection established ({time.time() - start_time:.3f}s)")
                        logger.info(f"   ‚úì Response status: {response.status_code}")
                        if response.status_code == 200:
                            chunks = []
                            chunk_count = 0
                            logger.info(f"   ‚Üí Streaming audio chunks...")
                            async for chunk in response.aiter_bytes():
                                chunk_count += 1
                                chunks.append(chunk)
                                if chunk_count == 1:
                                    logger.info(f"   ‚úì First chunk received ({time.time() - start_time:.3f}s, {len(chunk)} bytes)")
                            
                            logger.info(f"   ‚úì All chunks received: {chunk_count} chunks ({time.time() - start_time:.3f}s)")
                            audio_data = b''.join(chunks)
                            logger.info(f"   ‚úì Total audio size: {len(audio_data)} bytes")
                            
                            if len(audio_data) > 0:
                                return audio_data
                            else:
                                logger.warning(f"ElevenLabs returned empty audio (attempt {attempt + 1}/{max_retries})")
                        else:
                            error_text = await response.aread()
                            logger.error(f"ElevenLabs error: {response.status_code} - {error_text}")
                            
            except httpx.TimeoutException:
                logger.error(f"ElevenLabs timeout after {timeout_seconds}s (attempt {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5)  # Brief pause before retry
                    continue
            except Exception as e:
                logger.error(f"Error generating ElevenLabs audio (attempt {attempt + 1}/{max_retries}): {e}")
                import traceback
                logger.error(traceback.format_exc())
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5)
                    continue
        
        # All retries failed
        logger.error(f"ElevenLabs TTS failed after {max_retries} attempts")
        return None
                
    except Exception as e:
        logger.error(f"Unexpected error in ElevenLabs TTS: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None

async def generate_audio_elevenlabs(text: str, settings: dict = None, user_id: str = None) -> bytes:
    """Generate audio using ElevenLabs TTS with advanced settings"""
    # Use streaming version for lower latency
    return await generate_audio_elevenlabs_streaming(text, settings, user_id)

async def generate_audio_hume(text: str, settings: dict = None, user_id: str = None) -> bytes:
    """Generate audio using Hume AI TTS with emotional voice synthesis"""
    try:
        # Get Hume settings from agent or use defaults
        hume_settings = settings.get("hume_settings", {}) if settings else {}
        
        voice_name = hume_settings.get("voice_name", "ITO")
        description = hume_settings.get("description", "warm and friendly")
        speed = hume_settings.get("speed", 1.0)
        
        logger.info(f"üé≠ Hume AI TTS: voice={voice_name}, emotion={description}, speed={speed}")
        
        # Get API key from user's keys or fallback to env
        if user_id:
            try:
                hume_key = await get_user_api_key(user_id, "hume")
            except Exception as e:
                logger.error(f"Failed to get user Hume key: {e}")
                hume_key = None
        else:
            hume_key = os.environ.get("HUME_API_KEY")
        
        if not hume_key:
            logger.error("Hume API key not found")
            return b""
        
        try:
            from hume.client import AsyncHumeClient
            from hume.tts.types import PostedUtterance, PostedUtteranceVoiceWithId
            
            client = AsyncHumeClient(api_key=hume_key)
            
            # voice_name is actually the voice_id from Hume
            voice_id = voice_name  # The setting stores the voice ID
            
            # Create utterance object with text and voice ID
            utterance = PostedUtterance(
                text=text,
                voice=PostedUtteranceVoiceWithId(id=voice_id),  # Use voice ID
                speed=speed
            )
            
            # Use Hume TTS streaming for low latency
            audio_chunks = []
            
            # Use synthesize_json_streaming (the correct method)
            async for chunk in client.tts.synthesize_json_streaming(
                utterances=[utterance],
                version="2",  # Use version 2 for better quality
                strip_headers=True,  # Remove WAV headers for clean concatenation
            ):
                # Chunks can be SnippetAudioChunk or TimestampMessage
                # Debug: check what attributes the chunk has
                if hasattr(chunk, 'snippet') and chunk.snippet is not None:
                    audio_chunks.append(chunk.snippet)
                elif hasattr(chunk, 'data') and chunk.data is not None:
                    audio_chunks.append(chunk.data)
                elif hasattr(chunk, 'audio') and chunk.audio is not None:
                    audio_chunks.append(chunk.audio)
                elif isinstance(chunk, bytes):
                    audio_chunks.append(chunk)
                else:
                    # Log what we got to understand structure
                    logger.debug(f"Unknown chunk type: {type(chunk)}, attrs: {[a for a in dir(chunk) if not a.startswith('_')][:10]}")
            
            # Combine all chunks (convert strings to bytes if needed)
            if audio_chunks:
                # Check if first chunk is string or bytes
                if isinstance(audio_chunks[0], str):
                    # Chunks are base64 encoded strings
                    import base64
                    complete_audio = b''.join([base64.b64decode(chunk) for chunk in audio_chunks])
                else:
                    complete_audio = b''.join(audio_chunks)
            else:
                complete_audio = b''
                
            logger.info(f"‚úÖ Generated {len(complete_audio)} bytes of Hume audio ({len(audio_chunks)} chunks)")
            return complete_audio
            
        except ImportError as e:
            logger.error(f"Hume library not installed correctly: {e}")
            return b""
        except Exception as e:
            logger.error(f"Error with Hume API: {e}")
            logger.exception(e)
            return b""
                
    except Exception as e:
        logger.error(f"Error generating Hume audio: {e}")
        return b""

async def generate_audio_cartesia(text: str, settings: dict = None, user_id: str = None) -> bytes:
    """Generate audio using Cartesia Sonic TTS - Properly formatted for Telnyx"""
    try:
        import time
        import subprocess
        import tempfile
        import os
        
        total_start = time.time()
        
        # Get Cartesia API key from user's keys or fallback to env
        if user_id:
            try:
                cartesia_api_key = await get_user_api_key(user_id, "cartesia")
            except Exception as e:
                logger.error(f"Failed to get user Cartesia key: {e}")
                cartesia_api_key = None
        else:
            cartesia_api_key = os.environ.get("CARTESIA_API_KEY")
        
        if not cartesia_api_key:
            logger.error("No Cartesia API key found")
            return b""
        
        # Initialize Cartesia service
        from cartesia_service import CartesiaService
        cartesia = CartesiaService(api_key=cartesia_api_key)
        
        # Get voice settings
        cartesia_settings = settings.get("cartesia_settings", {}) if settings else {}
        voice_id = cartesia_settings.get("voice_id", "a0e99841-438c-4a64-b679-ae501e7d6091")
        model = cartesia_settings.get("model", "sonic-2")
        
        logger.info(f"üéôÔ∏è Cartesia: Generating with voice {voice_id}, model {model}")
        
        # Request PCM at 22050Hz (Cartesia's native rate)
        output_format = {
            "container": "raw",
            "encoding": "pcm_s16le",  # 16-bit PCM signed little-endian
            "sample_rate": 22050  # Cartesia's native rate
        }
        
        api_start = time.time()
        
        audio_pcm = await cartesia.generate_speech(
            text=text,
            voice_id=voice_id,
            model=model,
            output_format=output_format
        )
        
        api_time = time.time() - api_start
        
        if not audio_pcm or len(audio_pcm) == 0:
            logger.error("Cartesia returned empty audio")
            return b""
        
        logger.info(f"‚úÖ Cartesia: Generated {len(audio_pcm)} bytes PCM 22050Hz")
        
        # Convert PCM 22050Hz to MP3 44100Hz using ffmpeg (standard telephony conversion)
        with tempfile.NamedTemporaryFile(suffix='.pcm', delete=False) as pcm_file:
            pcm_file.write(audio_pcm)
            pcm_path = pcm_file.name
        
        mp3_path = pcm_path.replace('.pcm', '.mp3')
        
        convert_start = time.time()
        
        try:
            # Convert: 22050Hz PCM ‚Üí 44100Hz MP3 (standard rates for quality)
            subprocess.run([
                'ffmpeg',
                '-f', 's16le',        # 16-bit signed PCM
                '-ar', '22050',       # Input: 22050Hz (Cartesia native)
                '-ac', '1',           # Mono
                '-i', pcm_path,       # Input file
                '-ar', '44100',       # Output: 44100Hz (standard for telephony)
                '-b:a', '128k',       # 128kbps bitrate for quality
                '-y',                 # Overwrite
                mp3_path              # Output file
            ], check=True, capture_output=True, timeout=5)
            
            convert_time = time.time() - convert_start
            
            # Read MP3 file
            with open(mp3_path, 'rb') as f:
                mp3_audio = f.read()
            
            total_time = time.time() - total_start
            
            logger.info(f"‚úÖ Cartesia: Converted to {len(mp3_audio)} bytes MP3 44100Hz")
            logger.info(f"‚è±Ô∏è  Cartesia API time: {api_time*1000:.0f}ms")
            logger.info(f"‚è±Ô∏è  Conversion time: {convert_time*1000:.0f}ms")
            logger.info(f"‚è±Ô∏è  Cartesia total time: {total_time*1000:.0f}ms")
            
            return mp3_audio
            
        finally:
            # Cleanup temp files
            try:
                os.remove(pcm_path)
                if os.path.exists(mp3_path):
                    os.remove(mp3_path)
            except:
                pass
                
    except Exception as e:
        logger.error(f"Error generating Cartesia audio: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return b""

async def generate_tts_audio(text: str, agent_config: dict) -> bytes:
    """
    Generate TTS audio based on agent's configured provider
    Routes to ElevenLabs, Hume, Sesame, Cartesia, or MeloTTS based on settings
    Optionally mixes comfort noise if enabled in agent settings
    """
    try:
        settings = agent_config.get("settings", {})
        tts_provider = settings.get("tts_provider")
        user_id = agent_config.get("user_id")  # Get user_id from agent config
        enable_comfort_noise = settings.get("enable_comfort_noise", False)  # Get comfort noise setting
        
        # TTS provider is REQUIRED - no defaults
        if not tts_provider:
            logger.error("‚ùå No TTS provider configured for agent")
            return None
        
        import datetime
        tts_start_time = time.time()
        timestamp_str = datetime.datetime.now().strftime("%H:%M:%S.%f")[:-3]
        logger.info(f"‚è±Ô∏è [{timestamp_str}] üîä TTS REQUEST START: provider={tts_provider}, user={user_id[:8] if user_id else 'unknown'}, comfort_noise={enable_comfort_noise}")
        
        # Generate audio using configured provider
        audio_bytes = None
        
        if tts_provider == "elevenlabs":
            audio_bytes = await generate_audio_elevenlabs_streaming(text, settings, user_id)
        elif tts_provider == "cartesia":
            audio_bytes = await generate_audio_cartesia(text, settings, user_id)
        elif tts_provider == "hume":
            audio_bytes = await generate_audio_hume(text, settings, user_id)
        elif tts_provider == "melo":
            # Use MeloTTS
            try:
                melo_settings = settings.get("melo_settings", {})
                voice = melo_settings.get("voice", "EN-US")
                speed = melo_settings.get("speed", 1.2)
                clone_wav = melo_settings.get("clone_wav", None)
                
                logger.info(f"üé§ Generating MeloTTS audio (Voice: {voice}, Speed: {speed})")
                
                melo_service = MeloTTSService()
                wav_bytes = await melo_service.generate_audio(
                    text=text,
                    voice=voice,
                    speed=speed,
                    clone_wav=clone_wav
                )
                
                logger.info(f"‚úÖ MeloTTS generated {len(wav_bytes)} bytes WAV")
                
                # Convert WAV to MP3 for Telnyx compatibility
                import io
                import tempfile
                import subprocess
                
                # Write WAV to temp file
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as wav_file:
                    wav_path = wav_file.name
                    wav_file.write(wav_bytes)
                
                # Convert to MP3 with 8kHz sample rate for telephony
                mp3_path = wav_path.replace('.wav', '.mp3')
                result = subprocess.run([
                    'ffmpeg', '-y',
                    '-i', wav_path,
                    '-ar', '8000',  # Resample to 8kHz (telephony standard)
                    '-ac', '1',     # Mono
                    '-b:a', '64k',  # 64kbps bitrate
                    mp3_path
                ], capture_output=True, text=True)
                
                if result.returncode != 0:
                    logger.error(f"‚ùå ffmpeg conversion failed: {result.stderr}")
                    os.unlink(wav_path)
                    logger.warning("‚ö†Ô∏è Falling back to ElevenLabs")
                    return await generate_audio_elevenlabs(text, settings, user_id)
                
                # Read MP3 file
                with open(mp3_path, 'rb') as f:
                    mp3_audio = f.read()
                
                # Cleanup
                os.unlink(wav_path)
                os.unlink(mp3_path)
                
                logger.info(f"‚úÖ MeloTTS converted to MP3: {len(mp3_audio)} bytes")
                audio_bytes = mp3_audio
                
            except Exception as e:
                logger.error(f"‚ùå MeloTTS error: {e}")
                logger.warning("‚ö†Ô∏è MeloTTS failed, falling back to ElevenLabs")
                audio_bytes = await generate_audio_elevenlabs(text, settings, user_id)
        elif tts_provider == "dia":
            # Use Dia TTS (OpenAI-compatible API)
            try:
                from dia_tts_service import DiaTTSService
                
                dia_settings = settings.get("dia_settings", {})
                voice = dia_settings.get("voice", "S1")
                speed = dia_settings.get("speed", 1.0)
                response_format = dia_settings.get("response_format", "wav")
                
                logger.info(f"üé§ Generating Dia TTS audio (Voice: {voice}, Speed: {speed}, Format: {response_format})")
                
                dia_service = DiaTTSService()
                audio_bytes = await dia_service.generate_audio(
                    text=text,
                    voice=voice,
                    speed=speed,
                    response_format=response_format
                )
                
                logger.info(f"‚úÖ Dia TTS generated {len(audio_bytes)} bytes ({response_format})")
                
                # If WAV format, convert to MP3 for Telnyx compatibility
                if response_format == "wav":
                    import io
                    import tempfile
                    import subprocess
                    
                    # Write audio to temp file
                    with tempfile.NamedTemporaryFile(suffix=f'.{response_format}', delete=False) as audio_file:
                        audio_path = audio_file.name
                        audio_file.write(audio_bytes)
                    
                    # Convert to MP3 with 8kHz sample rate for telephony
                    mp3_path = audio_path.replace(f'.{response_format}', '.mp3')
                    result = subprocess.run([
                        'ffmpeg', '-y',
                        '-i', audio_path,
                        '-ar', '8000',  # Resample to 8kHz (telephony standard)
                        '-ac', '1',     # Mono
                        '-b:a', '64k',  # 64kbps bitrate
                        mp3_path
                    ], capture_output=True, text=True)
                    
                    if result.returncode != 0:
                        logger.error(f"‚ùå ffmpeg conversion failed: {result.stderr}")
                        os.unlink(audio_path)
                        logger.warning("‚ö†Ô∏è Falling back to ElevenLabs")
                        audio_bytes = await generate_audio_elevenlabs(text, settings, user_id)
                    else:
                        # Read MP3 file
                        with open(mp3_path, 'rb') as f:
                            mp3_audio = f.read()
                        
                        # Cleanup
                        os.unlink(audio_path)
                        os.unlink(mp3_path)
                        
                        logger.info(f"‚úÖ Dia TTS converted to MP3: {len(mp3_audio)} bytes")
                        audio_bytes = mp3_audio
                else:
                    # If already MP3 or other format, use as-is
                    pass  # audio_bytes already set above
                
            except Exception as e:
                logger.error(f"‚ùå Dia TTS error: {e}")
                logger.warning("‚ö†Ô∏è Dia TTS failed, falling back to ElevenLabs")
                audio_bytes = await generate_audio_elevenlabs(text, settings, user_id)
        elif tts_provider == "kokoro":
            # Use Kokoro TTS (Open-source fast TTS)
            try:
                from kokoro_tts_service import KokoroTTSService
                
                kokoro_settings = settings.get("kokoro_settings", {})
                voice = kokoro_settings.get("voice", "af_bella")
                speed = kokoro_settings.get("speed", 1.0)
                response_format = kokoro_settings.get("response_format", "mp3")
                
                logger.info(f"üé§ Generating Kokoro TTS audio (Voice: {voice}, Speed: {speed})")
                
                kokoro_service = KokoroTTSService()
                audio_bytes = await kokoro_service.generate_audio(
                    text=text,
                    voice=voice,
                    speed=speed,
                    response_format=response_format
                )
                
                logger.info(f"‚úÖ Kokoro TTS generated {len(audio_bytes)} bytes")
                # audio_bytes already set
                
            except Exception as e:
                logger.error(f"‚ùå Kokoro TTS error: {e}")
                logger.warning("‚ö†Ô∏è Kokoro TTS failed, falling back to Cartesia")
                audio_bytes = await generate_audio_cartesia(text, settings)
        
        elif tts_provider == "chattts":
            # Use ChatTTS (Ultra-low latency conversational TTS)
            try:
                from chattts_tts_service import ChatTTSClient
                import subprocess
                import tempfile
                
                chattts_settings = settings.get("chattts_settings", {})
                voice = chattts_settings.get("voice", "female_1")
                speed = chattts_settings.get("speed", 1.0)
                temperature = chattts_settings.get("temperature", 0.3)
                
                logger.info(f"üé§ Generating ChatTTS audio (Voice: {voice}, Speed: {speed}, Temp: {temperature})")
                
                # Get API URLs from environment (supports multiple instances)
                chattts_api_urls_str = os.environ.get("CHATTTS_API_URLS", "")
                chattts_api_url = os.environ.get("CHATTTS_API_URL", "http://203.57.40.119:10129")
                
                # Parse multiple URLs if provided
                if chattts_api_urls_str:
                    api_urls = [url.strip() for url in chattts_api_urls_str.split(',') if url.strip()]
                    chattts_client = ChatTTSClient(api_urls=api_urls)
                    logger.info(f"Using {len(api_urls)} ChatTTS instances for load balancing")
                else:
                    chattts_client = ChatTTSClient(api_url=chattts_api_url)
                
                # Request WAV format from ChatTTS
                audio_bytes_wav, metadata = await chattts_client.generate_tts(
                    text=text,
                    voice=voice,
                    speed=speed,
                    temperature=temperature,
                    response_format="wav"  # Get WAV from ChatTTS
                )
                
                logger.info(f"‚úÖ ChatTTS generated {len(audio_bytes_wav)} bytes (WAV)")
                if metadata:
                    logger.info(f"   RTF: {metadata.get('rtf')}, Processing: {metadata.get('processing_time')}s")
                    logger.info(f"   Instance: {metadata.get('instance_url', 'N/A')}")
                
                # Convert ChatTTS WAV (24000Hz) to MP3 (44100Hz) for Telnyx compatibility
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as wav_file:
                    wav_file.write(audio_bytes_wav)
                    wav_path = wav_file.name
                
                mp3_path = wav_path.replace('.wav', '.mp3')
                
                try:
                    # Convert: 24000Hz WAV ‚Üí 8000Hz MP3 (telephony standard for PSTN/Telnyx)
                    subprocess.run([
                        'ffmpeg',
                        '-i', wav_path,           # Input WAV file
                        '-ar', '8000',            # Resample to 8000Hz for telephony
                        '-ac', '1',               # Mono
                        '-b:a', '64k',            # 64kbps bitrate (sufficient for telephony)
                        '-y',                     # Overwrite output
                        mp3_path
                    ], check=True, capture_output=True)
                    
                    # Read converted MP3
                    with open(mp3_path, 'rb') as f:
                        audio_bytes = f.read()
                    
                    logger.info(f"‚úÖ Converted to MP3 8000Hz (telephony): {len(audio_bytes)} bytes")
                    # audio_bytes already set
                    
                finally:
                    # Cleanup temp files
                    import os
                    try:
                        os.unlink(wav_path)
                        os.unlink(mp3_path)
                    except:
                        pass
                
            except Exception as e:
                logger.error(f"‚ùå ChatTTS error: {e}")
                logger.warning("‚ö†Ô∏è ChatTTS failed, falling back to Cartesia")
                audio_bytes = await generate_audio_cartesia(text, settings)

        elif tts_provider == "sesame":
            # Use WebSocket streaming for real-time audio
            from sesame_ws_service import stream_sesame_tts
            import io
            
            try:
                sesame_settings = settings.get("sesame_settings", {})
                speaker_id = sesame_settings.get("speaker_id", 0)
                
                logger.info(f"üöÄ Streaming Sesame TTS via WebSocket (Speaker {speaker_id})")
                
                # Stream audio chunks and aggregate
                audio_chunks = []
                chunk_count = 0
                
                async for chunk in stream_sesame_tts(text, speaker_id):
                    chunk_count += 1
                    audio_chunks.append(chunk)
                    
                    if chunk_count == 1:
                        logger.info(f"‚ö° First audio chunk received (WebSocket streaming)")
                
                if not audio_chunks:
                    logger.error("‚ùå No audio chunks received from Sesame WebSocket")
                    logger.warning("‚ö†Ô∏è Sesame WebSocket failed, falling back to ElevenLabs")
                    audio_bytes = await generate_audio_elevenlabs(text, settings, user_id)
                
                # Combine all chunks into complete audio
                audio_bytes = b''.join(audio_chunks)
                logger.info(f"‚úÖ Sesame WebSocket complete: {chunk_count} chunks, {len(audio_bytes)} bytes")
                
                # Convert raw PCM int16 24kHz to WAV format for Telnyx
                import wave
                import tempfile
                import subprocess
                
                # Create WAV file from raw PCM
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as wav_file:
                    wav_path = wav_file.name
                    with wave.open(wav_path, 'wb') as wav:
                        wav.setnchannels(1)  # Mono
                        wav.setsampwidth(2)  # 16-bit = 2 bytes
                        wav.setframerate(24000)  # 24kHz
                        wav.writeframes(audio_bytes)
                
                logger.info(f"üîÑ Converting Sesame PCM to MP3 ({len(audio_bytes)} bytes)")
                
                # Convert to MP3 with resampling to 8kHz for Telnyx compatibility
                mp3_path = wav_path.replace('.wav', '.mp3')
                result = subprocess.run([
                    'ffmpeg', '-y',
                    '-i', wav_path,
                    '-ar', '8000',  # Resample to 8kHz (Telnyx mulaw rate)
                    '-ac', '1',     # Mono
                    '-b:a', '64k',  # 64kbps bitrate
                    mp3_path
                ], capture_output=True, text=True)
                
                if result.returncode != 0:
                    logger.error(f"‚ùå ffmpeg conversion failed: {result.stderr}")
                    os.unlink(wav_path)
                    logger.warning("‚ö†Ô∏è Falling back to ElevenLabs")
                    audio_bytes = await generate_audio_elevenlabs(text, settings, user_id)
                else:
                    # Read MP3 file
                    with open(mp3_path, 'rb') as f:
                        mp3_audio = f.read()
                    
                    # Cleanup
                    os.unlink(wav_path)
                    os.unlink(mp3_path)
                    
                    logger.info(f"‚úÖ Sesame audio converted to MP3: {len(mp3_audio)} bytes")
                    audio_bytes = mp3_audio
                
            except Exception as e:
                logger.error(f"‚ùå Sesame WebSocket error: {e}")
                logger.warning("‚ö†Ô∏è Falling back to ElevenLabs")
                audio_bytes = await generate_audio_elevenlabs(text, settings, user_id)
        else:
            # Default to ElevenLabs
            audio_bytes = await generate_audio_elevenlabs(text, settings, user_id)
        
        # NOTE: Comfort noise is now handled as continuous background overlay (started at call beginning)
        # No need to mix into each TTS chunk - cleaner and more natural
        
        tts_end_time = time.time()
        tts_latency_ms = int((tts_end_time - tts_start_time) * 1000)
        timestamp_str = datetime.datetime.now().strftime("%H:%M:%S.%f")[:-3]
        logger.info(f"‚è±Ô∏è [{timestamp_str}] üîä TTS COMPLETE: {tts_latency_ms}ms, audio_size={len(audio_bytes) if audio_bytes else 0} bytes")
        
        return audio_bytes
            
    except Exception as e:
        logger.error(f"Error in TTS generation routing: {e}")
        # Fallback to basic ElevenLabs
        audio_bytes = await generate_audio_elevenlabs(text, None, user_id)
        return audio_bytes


# ==================== CALL LOGGING HELPERS ====================

async def create_call_log(
    call_id: str,
    agent_id: str,
    direction: str,
    from_number: str,
    to_number: str,
    user_id: str,
    phone_number_id: Optional[str] = None
) -> dict:
    """Create a new call log entry"""
    try:
        call_log = {
            "id": str(uuid.uuid4()),
            "call_id": call_id,
            "agent_id": agent_id,
            "user_id": user_id,
            "phone_number_id": phone_number_id,
            "direction": direction,
            "from_number": from_number,
            "to_number": to_number,
            "status": "queued",
            "end_reason": None,
            "duration": 0,
            "cost": 0.0,
            "start_time": datetime.utcnow(),
            "end_time": None,
            "answered_at": None,
            "sentiment": "unknown",
            "transcript": [],
            "summary": "",
            "latency_avg": 0.0,
            "latency_p50": 0.0,
            "latency_p90": 0.0,
            "latency_p99": 0.0,
            "user_sentiment_score": 0.0,
            "recording_url": None,
            "recording_duration": 0,
            "custom_variables": {},
            "metadata": {},
            "error_message": None,
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow()
        }
        
        await db.call_logs.insert_one(call_log)
        logger.info(f"üìù Created call log: {call_id}")
        return call_log
    except Exception as e:
        logger.error(f"Error creating call log: {e}")
        return None


async def update_call_log(call_id: str, updates: dict):
    """Update an existing call log"""
    try:
        updates["updated_at"] = datetime.utcnow()
        
        result = await db.call_logs.update_one(
            {"call_id": call_id},
            {"$set": updates}
        )
        
        if result.modified_count > 0:
            logger.info(f"üìù Updated call log: {call_id}")
        
        return result.modified_count > 0
    except Exception as e:
        logger.error(f"Error updating call log: {e}")
        return False


async def append_transcript(call_id: str, role: str, text: str, timestamp: datetime = None):
    """Append a message to the call transcript"""
    try:
        message = {
            "role": role,  # "user" or "assistant"
            "text": text,
            "timestamp": (timestamp or datetime.utcnow()).isoformat()
        }
        
        await db.call_logs.update_one(
            {"call_id": call_id},
            {
                "$push": {"transcript": message},
                "$set": {"updated_at": datetime.utcnow()}
            }
        )
        
        logger.debug(f"üìù Appended transcript for {call_id}: {role}")
    except Exception as e:
        logger.error(f"Error appending transcript: {e}")


async def finalize_call_log(call_id: str, end_reason: str = None, error_message: str = None):
    """Finalize call log with end time and status"""
    try:
        # Get the call log
        call_log = await db.call_logs.find_one({"call_id": call_id})
        
        if not call_log:
            logger.warning(f"‚ö†Ô∏è Call log not found for finalization: {call_id}")
            return False
        
        # Calculate duration from start_time to now
        start_time = call_log.get("start_time")
        answered_at = call_log.get("answered_at")
        end_time = datetime.utcnow()
        duration = 0
        
        # Calculate duration from when call was answered (or started if never answered)
        if answered_at:
            # Use answered time as start for more accurate duration
            if isinstance(answered_at, str):
                answered_at = datetime.fromisoformat(answered_at.replace('Z', '+00:00'))
            duration = int((end_time - answered_at).total_seconds())
        elif start_time:
            # Fall back to start_time if never answered
            if isinstance(start_time, str):
                start_time = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
            duration = int((end_time - start_time).total_seconds())
        
        # Ensure duration is positive
        duration = max(0, duration)
        
        # Determine status
        status = "completed" if end_reason in ["hangup", "completed"] else "failed"
        if error_message:
            status = "failed"
        
        # Calculate cost (rough estimate: $0.01 per minute)
        cost = (duration / 60) * 0.01
        
        updates = {
            "end_time": end_time,
            "duration": duration,
            "cost": round(cost, 4),
            "status": status,
            "end_reason": end_reason or "unknown",
            "error_message": error_message
        }
        
        await update_call_log(call_id, updates)
        logger.info(f"‚úÖ Finalized call log: {call_id} (duration={duration}s, status={status})")
        
        return True
    except Exception as e:
        logger.error(f"‚ùå Error finalizing call log {call_id}: {e}")
        logger.exception(e)
        return False


@api_router.post("/telnyx/webhook")
async def telnyx_webhook(payload: dict):
    """Webhook endpoint for Telnyx call events"""
    try:
        logger.info(f"üì® ========== TELNYX WEBHOOK RECEIVED ==========")
        logger.info(f"üì® Full payload: {payload}")
        
        # Extract event data
        event_type = payload.get("data", {}).get("event_type")
        call_control_id = payload.get("data", {}).get("payload", {}).get("call_control_id")
        
        logger.info(f"üéØ Event type: {event_type}, Call ID: {call_control_id}")
        logger.info(f"üì® ================================================")
        
        # Handle incoming calls - route to assigned inbound agent
        if event_type == "call.initiated":
            webhook_payload = payload.get("data", {}).get("payload", {})
            direction = webhook_payload.get("direction", "")
            from_number = webhook_payload.get("from", "")
            to_number = webhook_payload.get("to", "")
            
            logger.info(f"üìû Call initiated - Direction: {direction}, From: {from_number}, To: {to_number}")
            
            if direction == "incoming":
                logger.info(f"üì• Incoming call to {to_number} from {from_number}")
                
                # Normalize phone number for lookup (remove spaces, parentheses, dashes)
                def normalize_phone(phone):
                    """Normalize phone number to E.164 format for comparison"""
                    if not phone:
                        return ""
                    # Remove all non-digit characters except leading +
                    import re
                    normalized = re.sub(r'[^\d+]', '', phone)
                    return normalized
                
                normalized_to = normalize_phone(to_number)
                logger.info(f"üîç Looking up number: {to_number} ‚Üí normalized: {normalized_to}")
                
                # Try exact match first, then try normalized match
                phone_record = await db.phone_numbers.find_one({"number": to_number})
                
                if not phone_record:
                    # Try to find by normalized number
                    all_numbers = await db.phone_numbers.find().to_list(100)
                    for num_record in all_numbers:
                        if normalize_phone(num_record.get("number")) == normalized_to:
                            phone_record = num_record
                            logger.info(f"‚úÖ Found number via normalization: {num_record.get('number')}")
                            break
                
                if phone_record and phone_record.get("inbound_agent_id"):
                    inbound_agent_id = phone_record.get("inbound_agent_id")
                    inbound_agent_name = phone_record.get("inbound_agent_name", "Unknown Agent")
                    
                    logger.info(f"‚úÖ Found assigned inbound agent: {inbound_agent_name} (ID: {inbound_agent_id})")
                    
                    # Get agent configuration
                    agent = await db.agents.find_one({"id": inbound_agent_id})
                    
                    if agent:
                        logger.info(f"ü§ñ Starting inbound call with agent: {agent.get('name')}")
                        
                        # Answer the call
                        telnyx_service = get_telnyx_service()
                        
                        # Store call data in Redis for multi-worker access
                        # Sanitize agent data to remove non-serializable fields (MongoDB ObjectId, datetime)
                        agent_sanitized = {}
                        for key, value in agent.items():
                            if key == "_id":
                                continue  # Skip MongoDB ObjectId
                            # Convert datetime objects to ISO string
                            if isinstance(value, datetime):
                                agent_sanitized[key] = value.isoformat()
                            else:
                                agent_sanitized[key] = value
                        
                        call_data = {
                            "agent": agent_sanitized,
                            "call_control_id": call_control_id,
                            "direction": "inbound",
                            "from_number": from_number,
                            "to_number": to_number,
                            "custom_variables": {
                                "from_number": from_number,
                                "to_number": to_number,
                                "phone_number": from_number  # For inbound, caller's number
                            }
                        }
                        
                        try:
                            redis_service.set_call_data(call_control_id, call_data, ttl=3600)
                            active_telnyx_calls[call_control_id] = call_data  # Fallback
                            logger.info(f"üì¶ Inbound call data stored in Redis and memory")
                        except Exception as e:
                            logger.error(f"‚ùå Error storing inbound call data: {e}")
                            active_telnyx_calls[call_control_id] = call_data
                            logger.info(f"‚ö†Ô∏è Stored in memory only (Redis failed)")
                        
                        # Create call log
                        try:
                            call_log = CallLogModel(
                                call_id=call_control_id,
                                agent_id=inbound_agent_id,
                                direction="inbound",
                                from_number=from_number,
                                to_number=to_number,
                                status="ringing",  # Valid status for incoming call
                                transcript=[],
                                start_time=datetime.utcnow()
                            )
                            await db.call_logs.insert_one(call_log.dict())
                            logger.info(f"üìù Call log created for inbound call: {call_control_id}")
                        except Exception as e:
                            logger.error(f"‚ùå Error creating call log: {e}")
                        
                        # Answer the call with streaming
                        try:
                            # Get agent settings for STT provider
                            settings = agent.get("settings", {})
                            stt_provider = settings.get("stt_provider", "soniox")
                            
                            # Answer call with real-time streaming
                            if stt_provider == "soniox":
                                # Use Soniox WebSocket streaming via deployed backend
                                backend_url = os.environ.get('BACKEND_URL')
                                if not backend_url:
                                    raise ValueError("BACKEND_URL environment variable must be set for STT streaming")
                                ws_url = backend_url.replace("https://", "wss://").replace("http://", "ws://")
                                stream_url = f"{ws_url}/api/telnyx/audio-stream/{call_control_id}"
                                
                                answer_result = await telnyx_service.answer_call(
                                    call_control_id,
                                    stream_url=stream_url
                                )
                            else:
                                # Standard answer without streaming
                                answer_result = await telnyx_service.answer_call(call_control_id)
                            
                            if answer_result.get("success"):
                                logger.info(f"‚úÖ Inbound call answered: {call_control_id}")
                            else:
                                logger.error(f"‚ùå Failed to answer call: {answer_result.get('error')}")
                        except Exception as e:
                            logger.error(f"‚ùå Error answering inbound call: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                    else:
                        logger.error(f"‚ùå Inbound agent not found: {inbound_agent_id}")
                        # Reject call if agent not found
                        try:
                            telnyx_service = get_telnyx_service()
                            await telnyx_service.reject_call(call_control_id)
                            logger.info(f"üìû Call rejected - agent not found")
                        except Exception as e:
                            logger.error(f"Error rejecting call: {e}")
                else:
                    logger.warning(f"‚ö†Ô∏è No inbound agent assigned to number {to_number}")
                    # Reject call if no agent assigned
                    try:
                        telnyx_service = get_telnyx_service()
                        await telnyx_service.reject_call(call_control_id)
                        logger.info(f"üìû Call rejected - no agent assigned to {to_number}")
                    except Exception as e:
                        logger.error(f"Error rejecting call: {e}")
                
                return {"status": "ok"}
        
        # Handle playback ended - close interruption window when audio finishes
        if event_type == "call.playback.ended":
            playback_id = payload.get("data", {}).get("payload", {}).get("playback_id")
            media_url = payload.get("data", {}).get("payload", {}).get("media_url", "")
            
            if call_control_id in call_states:
                state = call_states[call_control_id]
                
                # Check if this is the comfort noise ending
                # Comfort noise disabled - skip restart
                if False and "comfort_noise_playback_id" in state and playback_id == state["comfort_noise_playback_id"]:
                    # Immediately restart comfort noise to avoid gaps
                    logger.info(f"üéµ Comfort noise ended, restarting immediately...")
                    try:
                        telnyx_service = get_telnyx_service()
                        backend_url = os.environ.get('BACKEND_URL')
                        if not backend_url:
                            raise ValueError("BACKEND_URL environment variable must be set")
                        comfort_noise_url = f"{backend_url}/api/tts-audio/comfort_noise_continuous.mp3"
                        
                        result = await telnyx_service.play_audio_url(
                            call_control_id,
                            comfort_noise_url,
                            loop=True,
                            overlay=True
                        )
                        
                        if result.get("success"):
                            # Update the playback ID
                            state["comfort_noise_playback_id"] = result.get("playback_id")
                            logger.info(f"üéµ Comfort noise restarted seamlessly (new playback_id: {result.get('playback_id')})")
                    except Exception as e:
                        logger.error(f"Error restarting comfort noise: {e}")
                
                # Remove this playback from active set (but not comfort noise)
                if playback_id in state["current_playback_ids"]:
                    state["current_playback_ids"].remove(playback_id)
                    logger.info(f"üîä Playback {playback_id} ended, {len(state['current_playback_ids'])} remaining")
                
                # If NO more playbacks active, close interruption window
                if len(state["current_playback_ids"]) == 0 and state["agent_generating_response"]:
                    state["agent_generating_response"] = False
                    state["is_agent_speaking"] = False
                    logger.info(f"üîä All audio finished - interruption window CLOSED")
                    
                    # Dead air prevention: Mark agent as finished speaking and start silence tracking
                    if call_control_id in active_telnyx_calls:
                        call_data = active_telnyx_calls[call_control_id]
                        if "session" in call_data:
                            session = call_data["session"]
                            session.mark_agent_speaking_end()
                            logger.info(f"üîá Agent finished speaking - silence tracking started")
        
        # Handle AMD (Answering Machine Detection) events
        if event_type == "call.machine.detection.ended":
            result = payload.get("data", {}).get("payload", {}).get("result")
            detection_type = payload.get("data", {}).get("payload", {}).get("detection_type")
            
            logger.info(f"ü§ñ AMD Detection: result={result}, type={detection_type}")
            
            # If machine detected, hang up immediately
            if result == "machine":
                logger.warning(f"üìû Voicemail/Machine detected via Telnyx AMD - hanging up call {call_control_id}")
                telnyx_service = get_telnyx_service()
                try:
                    await asyncio.sleep(0.5)
                    hangup_result = await telnyx_service.hangup_call(call_control_id)
                    logger.info(f"‚úÖ Call hung up: {hangup_result}")
                    
                    # Update call log with detailed AMD info
                    await db.call_logs.update_one(
                        {"call_id": call_control_id},
                        {"$set": {
                            "status": "voicemail_detected",
                            "end_reason": "voicemail_detected_amd",
                            "voicemail_detection": {
                                "method": "telnyx_amd",
                                "result": result,
                                "detection_type": detection_type,
                                "detected_at": datetime.utcnow().isoformat()
                            },
                            "ended_at": datetime.utcnow(),
                            "updated_at": datetime.utcnow()
                        }}
                    )
                except Exception as e:
                    logger.error(f"‚ùå Error hanging up AMD-detected call: {e}")
                
                return {"status": "ok"}
        
        if event_type == "call.machine.greeting.ended":
            # Premium AMD - greeting ended (if we wanted to leave a message, we'd do it here)
            logger.info(f"ü§ñ Premium AMD: Voicemail greeting ended for {call_control_id}")
            # We're not leaving messages, so this is just informational
        
        if event_type == "call.answered":
            # Call was answered - start AI conversation with speech gathering
            logger.info(f"‚úÖ Call answered: {call_control_id}")
            
            # Try Redis first, then fallback to in-memory
            call_data = redis_service.get_call_data(call_control_id)
            
            if not call_data:
                # Fallback to in-memory dictionary
                logger.warning(f"‚ö†Ô∏è Call not found in Redis, checking in-memory fallback...")
                if call_control_id in active_telnyx_calls:
                    call_data = active_telnyx_calls[call_control_id]
                    logger.info(f"‚úÖ Found call in in-memory fallback")
                else:
                    logger.error(f"‚ùå CRITICAL: call_control_id {call_control_id} NOT FOUND in Redis or in-memory!")
                    logger.error(f"‚ùå This means the session was never created or was already cleaned up")
                    return
            else:
                logger.info(f"‚úÖ Found call in Redis (multi-worker state sharing working)")
            agent = call_data["agent"]
            custom_variables = call_data.get("custom_variables", {})
            
            # Extract phone numbers from webhook payload
            webhook_payload = payload.get("data", {}).get("payload", {})
            from_number = webhook_payload.get("from", "")
            to_number = webhook_payload.get("to", "")
            
            # Add phone numbers to custom variables
            if from_number:
                custom_variables["from_number"] = from_number
            if to_number:
                custom_variables["to_number"] = to_number
                custom_variables["phone_number"] = to_number  # Alias for easier use
            
            logger.info(f"üìû Phone numbers added to session: from={from_number}, to={to_number}")
            
            # Update call log
            try:
                await db.call_logs.update_one(
                    {"call_id": call_control_id},
                    {"$set": {
                        "status": "answered",
                        "answered_at": datetime.utcnow(),
                        "updated_at": datetime.utcnow()
                    }}
                )
                logger.info("‚úÖ Call log updated")
            except Exception as e:
                logger.error(f"‚ùå Error updating call log: {e}")
            
            # Get user's Telnyx API keys from database
            user_id = agent.get("user_id")
            logger.info(f"üîß Getting Telnyx API keys for user: {user_id}")
            
            telnyx_api_key = await get_api_key(user_id, "telnyx")
            telnyx_connection_id = await get_api_key(user_id, "telnyx_connection_id")
            
            if not telnyx_api_key or not telnyx_connection_id:
                logger.error(f"‚ùå Telnyx keys not found for user {user_id}")
                return
            
            logger.info("üîß Creating Telnyx service with user's keys...")
            telnyx_service = get_telnyx_service(api_key=telnyx_api_key, connection_id=telnyx_connection_id)
            
            # üîä START CONTINUOUS COMFORT NOISE (if enabled in agent settings)
            agent_settings = agent.get("settings", {})
            enable_comfort_noise = agent_settings.get("enable_comfort_noise", False)
            
            if enable_comfort_noise:
                try:
                    backend_url = os.environ.get('BACKEND_URL')
                    if not backend_url:
                        # Try to construct from REACT_APP_BACKEND_URL
                        backend_url = os.environ.get('REACT_APP_BACKEND_URL', 'http://localhost:8001')
                    
                    comfort_noise_url = f"{backend_url}/api/tts-audio/comfort_noise_continuous.mp3"
                    
                    # Start comfort noise as continuous background overlay (loops indefinitely)
                    result = await telnyx_service.play_audio_url(
                        call_control_id,
                        comfort_noise_url,
                        loop=True,  # Loop continuously
                        overlay=True  # Play as background layer, don't block other audio
                    )
                    
                    if result.get("success"):
                        comfort_noise_playback_id = result.get("playback_id")
                        call_states[call_control_id]["comfort_noise_playback_id"] = comfort_noise_playback_id
                        logger.info(f"üéµ Comfort noise started as continuous background overlay (playback_id: {comfort_noise_playback_id})")
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to start comfort noise: {result}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to start comfort noise: {e}")
            else:
                logger.info("‚è≠Ô∏è Comfort noise disabled for this agent")
            
            # Initialize call data for recording management
            call_data["processing_speech"] = False
            call_data["chunk_count"] = 0
            call_data["recent_agent_texts"] = []  # Track last 3 agent messages for echo filtering
            
            # Start call recording
            try:
                recording_result = await telnyx_service.start_recording(
                    call_control_id=call_control_id,
                    format="mp3",
                    channels="dual"
                )
                if recording_result.get("success"):
                    logger.info(f"üéôÔ∏è Call recording started for {call_control_id}")
                else:
                    logger.warning(f"‚ö†Ô∏è Failed to start recording: {recording_result.get('error')}")
            except Exception as e:
                logger.error(f"‚ùå Error starting recording: {e}")
            
            # Create AI session with custom variables injected and KB loaded
            try:
                logger.info(f"üîß Creating call session for {call_control_id}...")
                logger.info(f"üîç Agent ID: {agent.get('id')}, User ID: {agent.get('user_id')}")
                
                logger.info(f"üîß Calling create_call_session() - START")
                session = await create_call_session(
                    call_control_id, 
                    agent, 
                    agent_id=agent.get("id"), 
                    user_id=agent.get("user_id"), 
                    db=db
                )
                logger.info(f"üîß Calling create_call_session() - COMPLETE")
                
                logger.info(f"‚úÖ Session object created: {type(session).__name__}")
                
                session.session_variables.update(custom_variables)
                
                # CRITICAL: Store serializable data in Redis BEFORE adding session object
                # Session objects can't be JSON-serialized, so update Redis first
                call_data["agent_id"] = agent.get("id")  # For cross-worker session recreation
                call_data["user_id"] = agent.get("user_id")  # For cross-worker session recreation
                redis_service.set_call_data(call_control_id, call_data, ttl=3600)
                logger.info(f"‚úÖ Serializable call_data synced to Redis (agent_id, user_id)")
                
                # THEN add non-serializable session to local worker memory only
                call_data["session"] = session  # Stays in this worker's memory
                active_telnyx_calls[call_control_id] = call_data  # Update local cache
                
                logger.info(f"‚úÖ Session stored in worker memory (not Redis)")
                
                # Mark session as ready in Redis for cross-worker coordination
                redis_service.mark_session_ready(call_control_id, ttl=3600)
                
                logger.info(f"ü§ñ AI session created for call {call_control_id}")
                logger.info(f"üì¶ Custom variables injected: {custom_variables}")
                
            except Exception as e:
                logger.error(f"‚ùå CRITICAL: Failed to create session: {e}")
                logger.exception("Full traceback:")
                # Try to hangup the call gracefully
                try:
                    await telnyx_service.hangup_call(call_control_id)
                except:
                    pass
                return
            
            # Check who speaks first from start node
            flow = agent.get("call_flow", [])
            first_node = flow[0] if flow else {}
            start_node_data = first_node.get("data", {})
            who_speaks_first = start_node_data.get("whoSpeaksFirst", "ai")
            
            logger.info(f"üë§ Who speaks first: {who_speaks_first}")
            
            first_text = ""
            
            if who_speaks_first == "ai":
                # Get first message from agent (greeting)
                first_message = await session.process_user_input("")
                first_text = first_message.get("text", "Hello! How can I help you?")
                
                logger.info(f"üí¨ AI speaks first: {first_text}")
                
                # Save greeting to transcript
                await db.call_logs.update_one(
                    {"call_id": call_control_id},
                    {"$push": {
                        "transcript": {
                            "role": "assistant",
                            "text": first_text,
                            "timestamp": datetime.utcnow().isoformat()
                        }
                    }}
                )
            else:
                logger.info(f"üëÇ User speaks first - waiting for user input...")
                first_text = ""  # No greeting, wait for user
            
            # Check flow type
            is_press_digit_flow = first_node.get("type") == "press_digit"
            
            # For voice flows, WebSocket streaming was already set up in dial command
            if not is_press_digit_flow:
                logger.info("üé§ Voice flow - streaming started via dial command")
                call_data["flow_type"] = "voice_realtime"
                call_data["awaiting_speech"] = True
                call_data["last_agent_text"] = first_text
            
            # Now speak greeting if there is one
            try:
                if "telnyx_service" not in locals():
                    telnyx_service = get_telnyx_service()
                
                if first_text:  # Only speak if there's a greeting
                    agent = session.agent_config
                    
                    await telnyx_service.speak_text(
                        call_control_id, 
                        first_text,
                        agent_config=agent
                    )
                    logger.info("üîä Greeting spoken via Telnyx TTS")
                else:
                    logger.info("ü§ê No greeting - waiting for user to speak first")
                
                if is_press_digit_flow:
                    # DTMF flow
                    logger.info("üì± Press Digit flow - using DTMF")
                    call = telnyx_service.client.calls
                    call.actions.gather_using_speak(
                        call_control_id=call_control_id,
                        payload="",
                        voice="female",
                        language="en-US",
                        minimum_digits=1,
                        maximum_digits=1,
                        timeout_millis=30000,
                        inter_digit_timeout_millis=5000
                    )
                    call_data["flow_type"] = "press_digit"
                else:
                    # Voice flow - already started streaming above
                    logger.info("üé§ Voice flow - WebSocket streaming already initiated")
                    pass
                
            except Exception as e:
                logger.error(f"Error in conversation setup: {e}")
        
        elif event_type == "call.hangup":
            # Call ended
            logger.info(f"üìû Call ended: {call_control_id}")
            
            # Get hangup cause
            hangup_cause = payload.get("data", {}).get("payload", {}).get("hangup_cause", "normal")
            
            # Finalize call log
            await finalize_call_log(call_control_id, end_reason="hangup")
            
            # Clean up active call from Redis and in-memory
            redis_service.delete_call_data(call_control_id)
            if call_control_id in active_telnyx_calls:
                del active_telnyx_calls[call_control_id]
            logger.info(f"üßπ Cleaned up call session from Redis and memory: {call_control_id}")
        
        elif event_type == "call.recording.saved":
            # Recording is ready - download and transcribe it
            logger.info(f"üéôÔ∏è Recording saved for call: {call_control_id}")
            
            # Try to get call data from Redis first, then in-memory fallback
            call_data = redis_service.get_call_data(call_control_id) or active_telnyx_calls.get(call_control_id, {})
            session = call_data.get("session")
            
            # Get recording URL and ID
            recording_data = payload.get("data", {}).get("payload", {})
            recording_urls = recording_data.get("recording_urls", {})
            download_url = recording_urls.get("wav") or recording_urls.get("mp3")
            channels = recording_data.get("channels", "")
            recording_duration = recording_data.get("duration_millis", 0) // 1000  # Convert to seconds
            recording_id = recording_data.get("recording_id")  # Store recording ID for future URL refresh
            
            logger.info(f"üîç Recording check: download_url={bool(download_url)}, channels={channels}, recording_id={recording_id}, call_data={bool(call_data)}")
            
            # Save recording URL and ID to database
            if download_url:
                try:
                    update_data = {
                        "recording_url": download_url,
                        "recording_duration": recording_duration,
                        "updated_at": datetime.utcnow()
                    }
                    if recording_id:
                        update_data["recording_id"] = recording_id
                    
                    await db.call_logs.update_one(
                        {"call_id": call_control_id},
                        {"$set": update_data}
                    )
                    logger.info(f"üíæ Saved recording URL and ID to database: {recording_id}")
                except Exception as e:
                    logger.error(f"‚ùå Error saving recording URL: {e}")
            
            # Handle dual-channel recordings (user + agent separated)
            if download_url and channels == "dual":
                logger.info(f"‚úÖ Entering dual-channel processing")
                
                # Check if we should process (skip if currently speaking)
                if call_data and call_data.get("processing_speech"):
                    logger.info(f"‚è≠Ô∏è  Skipping - currently processing")
                    return {"status": "ok"}
                
                try:
                    logger.info(f"üì• Downloading DUAL-CHANNEL recording...")
                    
                    # Download the recording
                    async with httpx.AsyncClient(timeout=30.0) as client:
                        response = await client.get(download_url)
                        audio_data = response.content
                    
                    logger.info(f"‚úÖ Downloaded {len(audio_data)} bytes")
                    
                    # Extract user channel (channel 0)
                    from pydub import AudioSegment
                    import io
                    
                    audio_format = "mp3" if ".mp3" in download_url else "wav"
                    audio = AudioSegment.from_file(io.BytesIO(audio_data), format=audio_format)
                    channels_split = audio.split_to_mono()
                    
                    logger.info(f"‚úÖ Split into {len(channels_split)} channels")
                    
                    # Try both channels to find user speech
                    transcript_text = None
                    for channel_idx, channel_audio in enumerate(channels_split):
                        channel_bytes = io.BytesIO()
                        channel_audio.export(channel_bytes, format="wav")
                        channel_data = channel_bytes.getvalue()
                        
                        logger.info(f"üìä Channel {channel_idx}: {len(channel_data)} bytes")
                        
                        transcript = await transcribe_audio_deepgram_file(channel_data)
                        
                        if transcript and transcript.strip():
                            logger.info(f"‚úÖ Channel {channel_idx} HAS SPEECH: {transcript}")
                            transcript_text = transcript
                            break
                        else:
                            logger.info(f"‚ùå Channel {channel_idx}: No speech")
                    
                    if not transcript_text or not transcript_text.strip():
                        logger.warning("‚ö†Ô∏è No speech in any channel")
                        return {"status": "ok"}
                    
                    logger.info(f"üìù User said: {transcript_text}")
                    
                    # Echo filtering - ignore if transcript matches recent agent speech
                    recent_agent_texts = call_data.get("recent_agent_texts", [])
                    logger.info(f"üîç Echo filter check: recent_agent_texts = {recent_agent_texts}")
                    
                    if recent_agent_texts:
                        # Check if transcript is too similar to any recent agent speech
                        transcript_lower = transcript_text.lower().strip()
                        # Normalize: remove punctuation and extra spaces
                        import string
                        transcript_normalized = ''.join(c for c in transcript_lower if c not in string.punctuation).strip()
                        transcript_words = set(transcript_normalized.split())
                        
                        for agent_text in recent_agent_texts:
                            agent_lower = agent_text.lower().strip()
                            agent_normalized = ''.join(c for c in agent_lower if c not in string.punctuation).strip()
                            agent_words = set(agent_normalized.split())
                            
                            if len(agent_words) >= 2:  # Lower threshold - even 2 words can be echo
                                common_words = agent_words.intersection(transcript_words)
                                similarity = len(common_words) / len(agent_words) if len(agent_words) > 0 else 0
                                logger.info(f"üîç Checking similarity with '{agent_text[:30]}...': {similarity:.2f}")
                                
                                if similarity > 0.6:  # Lower threshold to 60%
                                    logger.info(f"üîá ECHO DETECTED (similarity: {similarity:.2f}) - Ignoring: {transcript_text[:50]}")
                                    return {"status": "ok"}
                    
                    # Mark as processing (update both Redis and in-memory)
                    update_call_state(call_control_id, {"processing_speech": True})
                    
                    # Save user transcript
                    await db.call_logs.update_one(
                        {"call_id": call_control_id},
                        {"$push": {
                            "transcript": {
                                "role": "user",
                                "text": transcript_text,
                                "timestamp": datetime.utcnow().isoformat()
                            }
                        }}
                    )
                    
                    # Process through AI
                    logger.info(f"üîç Session exists: {bool(session)}, call_data exists: {bool(call_data)}")
                    if session:
                        try:
                            response = await session.process_user_input(transcript_text)
                            response_text = response.get("text", "I'm sorry, I didn't understand.")
                            
                            logger.info(f"ü§ñ AI response: {response_text}")
                            
                            # Save agent transcript
                            await db.call_logs.update_one(
                                {"call_id": call_control_id},
                                {"$push": {
                                    "transcript": {
                                        "role": "assistant",
                                        "text": response_text,
                                        "timestamp": datetime.utcnow().isoformat()
                                    }
                                }}
                            )
                            
                            # Speak response if call still active
                            if call_control_id in active_telnyx_calls:
                                telnyx_service = get_telnyx_service()
                                agent_config = session.agent_config if session else None
                                try:
                                    await telnyx_service.speak_text(call_control_id, response_text, agent_config=agent_config)
                                    logger.info(f"üîä Spoke response successfully")
                                    # Update recent agent texts for echo filtering (keep last 3)
                                    # Get current data from Redis or fallback
                                    call_data = redis_service.get_call_data(call_control_id) or active_telnyx_calls.get(call_control_id, {})
                                    recent_texts = call_data.get("recent_agent_texts", [])
                                    recent_texts.append(response_text)
                                    recent_texts = recent_texts[-3:]  # Keep only last 3
                                    
                                    # Update both Redis and in-memory
                                    update_call_state(call_control_id, {
                                        "recent_agent_texts": recent_texts,
                                        "last_agent_text": response_text
                                    })
                                    
                                    # Also store in call_states for interruption handler echo filtering
                                    if call_control_id not in call_states:
                                        call_states[call_control_id] = {}
                                    call_states[call_control_id]["recent_agent_texts"] = recent_texts
                                except Exception as speak_error:
                                    logger.error(f"‚ùå Error speaking: {speak_error}")
                                
                                # Check ending node
                                logger.info(f"üîç Checking should_end_call: {session.should_end_call}")
                                if session.should_end_call:
                                    logger.info("üìû Ending node - hanging up in 3s")
                                    await asyncio.sleep(3)
                                    try:
                                        await telnyx_service.hangup_call(call_control_id)
                                        logger.info("‚òéÔ∏è Call hung up successfully")
                                    except Exception as e:
                                        logger.error(f"Error hanging up: {e}")
                                    # Clean up from Redis and in-memory
                                    redis_service.delete_call_data(call_control_id)
                                    if call_control_id in active_telnyx_calls:
                                        del active_telnyx_calls[call_control_id]
                                    return {"status": "ok"}
                                
                                # Resume recording after speech completes
                                logger.info("‚è∞ Waiting 2s for speech to complete...")
                                await asyncio.sleep(2)
                                
                                # Check if call still active (Redis or in-memory)
                                call_data = redis_service.get_call_data(call_control_id) or active_telnyx_calls.get(call_control_id)
                                if call_data:
                                    logger.info("üîÑ Resuming recording and continuous loop...")
                                    update_call_state(call_control_id, {"processing_speech": False})
                                    
                                    # Restart the continuous recording loop
                                    async def restart_continuous_recording():
                                        try:
                                            await telnyx_service.start_recording(
                                                call_control_id=call_control_id,
                                                format="wav",
                                                channels="dual"
                                            )
                                            logger.info("üéôÔ∏è Recording resumed successfully")
                                            update_call_state(call_control_id, {"recording_start_time": time.time()})
                                            
                                            # Continue the loop
                                            call_data = redis_service.get_call_data(call_control_id) or active_telnyx_calls.get(call_control_id, {})
                                            chunk = call_data.get("chunk_count", 0)
                                            
                                            while True:
                                                # Check if call still active and not processing
                                                call_data = redis_service.get_call_data(call_control_id) or active_telnyx_calls.get(call_control_id)
                                                if not call_data or call_data.get("processing_speech"):
                                                    break
                                                await asyncio.sleep(3)  # 3-second chunks
                                                
                                                # Check again if still active
                                                call_data = redis_service.get_call_data(call_control_id) or active_telnyx_calls.get(call_control_id)
                                                if call_data and not call_data.get("processing_speech"):
                                                    try:
                                                        await telnyx_service.stop_recording(call_control_id)
                                                        chunk += 1
                                                        update_call_state(call_control_id, {"chunk_count": chunk})
                                                        logger.info(f"‚è±Ô∏è Dual-channel chunk {chunk} stopped (3s)")
                                                        
                                                        await asyncio.sleep(0.3)
                                                        
                                                        # Check once more before restarting
                                                        call_data = redis_service.get_call_data(call_control_id) or active_telnyx_calls.get(call_control_id)
                                                        if call_data and not call_data.get("processing_speech"):
                                                            await telnyx_service.start_recording(
                                                                call_control_id=call_control_id,
                                                                format="wav",
                                                                channels="dual"
                                                            )
                                                            update_call_state(call_control_id, {"recording_start_time": time.time()})
                                                            logger.info(f"üîÑ Chunk {chunk + 1} recording started")
                                                    except Exception as e:
                                                        logger.error(f"‚ùå Error in resumed recording loop: {e}")
                                                        break
                                        except Exception as e:
                                            logger.error(f"‚ùå Error restarting recording: {e}")
                                    
                                    asyncio.create_task(restart_continuous_recording())
                                else:
                                    logger.warning("‚ö†Ô∏è Call no longer active, not resuming recording")
                        except Exception as e:
                            logger.error(f"Error in AI processing: {e}")
                
                except Exception as e:
                    logger.error(f"‚ùå Error processing dual-channel: {e}", exc_info=True)
            else:
                if not download_url:
                    logger.error("No recording URL found in webhook")
                elif channels != "dual":
                    logger.info(f"Skipping {channels} channel recording (not dual-channel)")
        
        elif event_type == "call.gather.ended":
                # Gather ended - could have digits or speech
                logger.info(f"üé§ Gather ended for call: {call_control_id}")
            
                if call_control_id in active_telnyx_calls:
                    call_data = active_telnyx_calls[call_control_id]
                    session = call_data.get("session")
                
                    # Skip first chunk if it's a continuous voice flow (contains greeting)
                    if call_data.get("flow_type") == "voice_continuous" and not call_data.get("first_chunk_processed"):
                        logger.info("‚è≠Ô∏è  Skipping first recording chunk (greeting)")
                        call_data["first_chunk_processed"] = True
                        return {"status": "ok"}
                
                    if session:
                        # Get the gathered result
                        gather_payload = payload.get("data", {}).get("payload", {})
                        digits = gather_payload.get("digits", "")
                        status = gather_payload.get("status", "")
                    
                        logger.info(f"üìù Gather result - status: '{status}', digits: '{digits}'")
                    
                        # Check if it was a speech gather (status = 'call_hangup' or 'timeout')
                        # For speech gathers, we don't get digits - need to use recording or stream
                        # Since gather_using_speak doesn't return speech transcript, we need recording
                    
                        if status == "valid":
                            # DTMF digit was pressed
                            user_input = digits
                            logger.info(f"üî¢ Processing DTMF digit: {user_input}")
                        
                            # Save user input to transcript
                            await db.call_logs.update_one(
                                {"call_id": call_control_id},
                                {"$push": {
                                    "transcript": {
                                        "role": "user",
                                        "text": f"Pressed {user_input}",
                                        "timestamp": datetime.utcnow().isoformat()
                                    }
                                }}
                            )
                        
                            # Process through AI
                            try:
                                response = await session.process_user_input(user_input)
                                response_text = response.get("text", "I'm sorry, I didn't understand that.")
                            
                                logger.info(f"ü§ñ AI response: {response_text}")
                            
                                # Save AI response to transcript
                                await db.call_logs.update_one(
                                    {"call_id": call_control_id},
                                    {"$push": {
                                        "transcript": {
                                            "role": "assistant",
                                            "text": response_text,
                                            "timestamp": datetime.utcnow().isoformat()
                                        }
                                    }}
                                )
                            
                                # Check if should end call
                                if session.should_end_call:
                                    logger.info("üìû Ending node reached - hanging up")
                                    telnyx_service = get_telnyx_service()
                                    agent_config = session.agent_config
                                    await telnyx_service.speak_text(call_control_id, response_text, agent_config=agent_config)
                                    await asyncio.sleep(3)
                                    await telnyx_service.hangup_call(call_control_id)
                                    # Clean up from Redis and in-memory
                                    redis_service.delete_call_data(call_control_id)
                                    if call_control_id in active_telnyx_calls:
                                        del active_telnyx_calls[call_control_id]
                                else:
                                    # Continue conversation
                                    telnyx_service = get_telnyx_service()
                                    await telnyx_service.gather_using_speak(
                                        call_control_id=call_control_id,
                                        text=response_text,
                                        language="en-US",
                                        timeout_secs=5,
                                        max_digits=0
                                    )
                                    logger.info("üîä Spoke AI response and listening for next input")
                            except Exception as e:
                                logger.error(f"Error processing gather result: {e}")
                        else:
                            # Timeout or no input - start recording to capture speech
                            logger.info(f"‚è±Ô∏è Gather timeout - starting recording to capture speech")
                            telnyx_service = get_telnyx_service()
                            await telnyx_service.start_recording(
                                call_control_id=call_control_id,
                                format="wav",
                                channels="single"
                            )
                            call_data["recording_start_time"] = time.time()
                        
                            # Stop after 3 seconds
                            async def stop_gather_recording():
                                await asyncio.sleep(3)
                                if call_control_id in active_telnyx_calls:
                                    try:
                                        await telnyx_service.stop_recording(call_control_id)
                                        logger.info("‚è±Ô∏è Stopped gather recording")
                                    except:
                                        pass
                            asyncio.create_task(stop_gather_recording())
        
        return {"status": "ok"}
        
    except Exception as e:
        logger.error(f"Error processing webhook: {e}")
        return {"status": "error", "message": str(e)}



@api_router.get("/telnyx/call/{call_id}")
async def get_call_log(call_id: str):
    """Get call log details including transcript"""
    try:
        call_log = await db.call_logs.find_one({"call_id": call_id})
        
        if not call_log:
            raise HTTPException(status_code=404, detail="Call log not found")
        
        # Convert ObjectId to string if present
        if "_id" in call_log:
            call_log["_id"] = str(call_log["_id"])
        
        # Convert datetime objects to ISO strings
        for field in ["start_time", "end_time", "answered_at", "created_at", "updated_at"]:
            if field in call_log and call_log[field]:
                call_log[field] = call_log[field].isoformat() if hasattr(call_log[field], 'isoformat') else str(call_log[field])
        
        return call_log
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching call log: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Serve TTS audio files
from fastapi.responses import FileResponse
import os

@api_router.get("/tts-audio/{filename}")
async def serve_tts_audio(filename: str):
    """Serve generated TTS audio files"""
    file_path = f"/tmp/{filename}"
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="Audio file not found")
    return FileResponse(file_path, media_type="audio/mpeg")

# Include the router in the main app


# ==================== CALL HISTORY & ANALYTICS API ====================

@api_router.get("/call-history", response_model=List[dict])
async def get_call_history(
    current_user: dict = Depends(get_current_user),
    agent_id: Optional[str] = None,
    direction: Optional[str] = None,
    status: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    limit: int = 50,
    offset: int = 0
):
    """Get call history with filters"""
    try:
        # Build query - ALWAYS filter by user_id for multi-tenant isolation
        query = {"user_id": current_user['id']}
        
        if agent_id:
            query["agent_id"] = agent_id
        
        if direction:
            query["direction"] = direction
        
        if status:
            query["status"] = status
        
        if start_date:
            query["start_time"] = {"$gte": datetime.fromisoformat(start_date)}
        
        if end_date:
            if "start_time" in query:
                query["start_time"]["$lte"] = datetime.fromisoformat(end_date)
            else:
                query["start_time"] = {"$lte": datetime.fromisoformat(end_date)}
        
        # Query database
        cursor = db.call_logs.find(query).sort("start_time", -1).skip(offset).limit(limit)
        calls = await cursor.to_list(length=limit)
        
        # Convert ObjectId to string and datetime to ISO
        for call in calls:
            if "_id" in call:
                call["_id"] = str(call["_id"])
            if "start_time" in call:
                call["start_time"] = call["start_time"].isoformat()
            if "end_time" in call and call["end_time"]:
                call["end_time"] = call["end_time"].isoformat()
            if "answered_at" in call and call["answered_at"]:
                call["answered_at"] = call["answered_at"].isoformat()
        
        return calls
    except Exception as e:
        logger.error(f"Error fetching call history: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.get("/call-history/{call_id}/recording")
async def get_call_recording(call_id: str, current_user: dict = Depends(get_current_user)):
    """Download and serve recording directly from Telnyx"""
    from fastapi.responses import Response
    
    try:
        call = await db.call_logs.find_one({"call_id": call_id, "user_id": current_user['id']})
        
        if not call:
            raise HTTPException(status_code=404, detail="Call not found")
        
        recording_id = call.get("recording_id")
        if not recording_id:
            raise HTTPException(status_code=404, detail="No recording ID found for this call")
        
        # Download recording from Telnyx
        telnyx_service = get_telnyx_service()
        recording_result = await telnyx_service.get_recording(recording_id)
        
        if not recording_result.get("success"):
            raise HTTPException(status_code=500, detail=f"Failed to fetch recording from Telnyx: {recording_result.get('error')}")
        
        recording_content = recording_result.get("content")
        if not recording_content:
            raise HTTPException(status_code=404, detail="Recording content not available")
        
        # Serve the recording directly
        return Response(
            content=recording_content,
            media_type=recording_result.get("content_type", "audio/mpeg"),
            headers={
                "Content-Disposition": f"inline; filename=recording_{call_id[:20]}.mp3",
                "Cache-Control": "public, max-age=31536000"  # Cache for 1 year
            }
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error serving recording: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.get("/call-history/{call_id}")
async def get_call_detail(call_id: str, current_user: dict = Depends(get_current_user)):
    """Get detailed call information including transcript"""
    try:
        call = await db.call_logs.find_one({"call_id": call_id, "user_id": current_user['id']})
        
        if not call:
            raise HTTPException(status_code=404, detail="Call not found")
        
        # Convert fields
        if "_id" in call:
            call["_id"] = str(call["_id"])
        if "start_time" in call:
            call["start_time"] = call["start_time"].isoformat()
        if "end_time" in call and call["end_time"]:
            call["end_time"] = call["end_time"].isoformat()
        if "answered_at" in call and call["answered_at"]:
            call["answered_at"] = call["answered_at"].isoformat()
        
        # Add computed fields for conversation analysis
        if "call_successful" not in call:
            # Determine if call was successful based on duration and status
            call["call_successful"] = call.get("status") == "completed" and call.get("duration", 0) > 10
        
        if "sentiment" not in call:
            # Simple sentiment based on call completion
            call["sentiment"] = "Positive" if call.get("call_successful") else "Neutral"
        
        if "disconnect_reason" not in call:
            call["disconnect_reason"] = "User_hangup" if call.get("status") == "completed" else "Unknown"
        
        if "e2e_latency" not in call:
            # Compute average latency from logs if available
            latency_values = []
            if call.get("logs"):
                for log in call["logs"]:
                    if "E2E latency" in log.get("message", ""):
                        # Extract latency value from message like "E2E latency for this turn: 1234ms"
                        try:
                            import re
                            match = re.search(r"E2E latency for this turn: (\d+)ms", log["message"])
                            if match:
                                latency_values.append(int(match.group(1)))
                        except:
                            pass
            
            if latency_values:
                call["e2e_latency"] = int(sum(latency_values) / len(latency_values))
            else:
                call["e2e_latency"] = None
        
        # Generate simple logs if not present
        if "logs" not in call or not call["logs"]:
            call["logs"] = []
            
            if call.get("start_time"):
                call["logs"].append({
                    "timestamp": call["start_time"],
                    "level": "info",
                    "message": f"Call started - {call.get('direction', 'unknown')} call from {call.get('from_number', 'unknown')} to {call.get('to_number', 'unknown')}"
                })
            
            if call.get("transcript"):
                for i, msg in enumerate(call["transcript"][:10]):  # First 10 messages
                    # Support both old (speaker) and new (role) format
                    is_user = msg.get('role') == 'user' or msg.get('speaker') == 'user'
                    speaker_label = 'User' if is_user else 'Agent'
                    call["logs"].append({
                        "timestamp": msg.get("timestamp", call.get("start_time")),
                        "level": "info",
                        "message": f"{speaker_label} message: {msg.get('text', '')[:100]}..."
                    })
            
            if call.get("end_time"):
                call["logs"].append({
                    "timestamp": call["end_time"],
                    "level": "info",
                    "message": f"Call ended - Status: {call.get('status', 'unknown')}, Duration: {call.get('duration', 0)}s"
                })
        
        # Add agent name if not present
        if "agent_name" not in call and call.get("agent_id"):
            # Try to fetch agent name
            try:
                agent = await db.agents.find_one({"id": call["agent_id"]})
                if agent:
                    call["agent_name"] = agent.get("name", "Unknown Agent")
            except:
                call["agent_name"] = "Unknown Agent"
        
        # Ensure version field
        if "version" not in call:
            call["version"] = 0
        
        # Ensure cost and llm_tokens
        if "cost" not in call:
            call["cost"] = 0.0
        if "llm_tokens" not in call:
            call["llm_tokens"] = 0.0
        
        return call
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching call detail: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.get("/dashboard/analytics")
async def get_dashboard_analytics(current_user: dict = Depends(get_current_user)):
    """Get real-time dashboard analytics"""
    try:
        from datetime import datetime, timedelta, timezone
        
        # Get today's date range
        now = datetime.now(timezone.utc)
        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        
        # Total calls today - filtered by user_id for multi-tenant isolation
        total_calls_today = await db.call_logs.count_documents({
            "user_id": current_user['id'],
            "start_time": {"$gte": today_start}
        })
        
        # Yesterday's calls for comparison - filtered by user_id
        yesterday_start = today_start - timedelta(days=1)
        yesterday_calls = await db.call_logs.count_documents({
            "user_id": current_user['id'],
            "start_time": {"$gte": yesterday_start, "$lt": today_start}
        })
        calls_change = ((total_calls_today - yesterday_calls) / yesterday_calls * 100) if yesterday_calls > 0 else 0
        
        # Average response time (E2E latency) - filtered by user_id
        pipeline = [
            {"$match": {"user_id": current_user['id'], "logs": {"$exists": True, "$ne": []}}},
            {"$unwind": "$logs"},
            {"$match": {"logs.message": {"$regex": "E2E latency"}}},
            {"$limit": 100}  # Last 100 calls with latency
        ]
        
        latency_calls = await db.call_logs.aggregate(pipeline).to_list(length=100)
        latencies = []
        for call in latency_calls:
            try:
                import re
                match = re.search(r"E2E latency for this turn: (\d+)ms", call["logs"]["message"])
                if match:
                    latencies.append(int(match.group(1)))
            except:
                pass
        
        avg_latency = sum(latencies) / len(latencies) if latencies else 0
        avg_latency_seconds = avg_latency / 1000  # Convert to seconds
        
        # Success rate - filtered by user_id
        total_calls = await db.call_logs.count_documents({"user_id": current_user['id']})
        successful_calls = await db.call_logs.count_documents({"user_id": current_user['id'], "status": "completed"})
        success_rate = (successful_calls / total_calls * 100) if total_calls > 0 else 0
        
        # Active agents count - filtered by user_id
        active_agents = await db.agents.count_documents({"user_id": current_user['id']})
        
        # Get total call count - filtered by user_id
        total_all_time = await db.call_logs.count_documents({"user_id": current_user['id']})
        
        # Voicemail detection stats - filtered by user_id
        voicemail_detected_today = await db.call_logs.count_documents({
            "user_id": current_user['id'],
            "start_time": {"$gte": today_start},
            "status": "voicemail_detected"
        })
        voicemail_detected_all_time = await db.call_logs.count_documents({
            "user_id": current_user['id'],
            "status": "voicemail_detected"
        })
        
        # Calculate voicemail detection rate
        voicemail_rate = (voicemail_detected_today / total_calls_today * 100) if total_calls_today > 0 else 0
        
        return {
            "total_calls_today": total_calls_today,
            "calls_change_percent": round(calls_change, 1),
            "active_agents": active_agents,
            "avg_response_time": round(avg_latency_seconds, 2),
            "success_rate": round(success_rate, 1),
            "total_all_time": total_all_time,
            "voicemail_detected_today": voicemail_detected_today,
            "voicemail_detected_all_time": voicemail_detected_all_time,
            "voicemail_rate": round(voicemail_rate, 1)
        }
    except Exception as e:
        logger.error(f"Error fetching dashboard analytics: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.get("/call-analytics")
async def get_comprehensive_call_analytics(
    agent_id: Optional[str] = None,
    call_id: Optional[str] = None,
    batch_call_id: Optional[str] = None,
    type: Optional[str] = None,
    duration_min: Optional[int] = None,
    duration_max: Optional[int] = None,
    from_number: Optional[str] = None,
    to_number: Optional[str] = None,
    user_sentiment: Optional[str] = None,
    disconnection_reason: Optional[str] = None,
    call_status: Optional[str] = None,
    call_successful: Optional[str] = None,
    e2e_latency_min: Optional[int] = None,
    e2e_latency_max: Optional[int] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
):
    """Get call analytics and metrics with comprehensive filtering"""
    try:
        # Build query
        query = {}
        
        if agent_id:
            query["agent_id"] = agent_id
        
        if call_id:
            query["call_id"] = {"$regex": call_id, "$options": "i"}
        
        if batch_call_id:
            query["batch_call_id"] = batch_call_id
        
        if type:  # direction filter
            query["direction"] = type
        
        if duration_min is not None or duration_max is not None:
            query["duration"] = {}
            if duration_min is not None:
                query["duration"]["$gte"] = duration_min
            if duration_max is not None:
                query["duration"]["$lte"] = duration_max
        
        if from_number:
            query["from_number"] = {"$regex": from_number, "$options": "i"}
        
        if to_number:
            query["to_number"] = {"$regex": to_number, "$options": "i"}
        
        if user_sentiment:
            query["sentiment"] = user_sentiment
        
        if disconnection_reason:
            query["disconnect_reason"] = disconnection_reason
        
        if call_status:
            query["status"] = call_status
        
        if call_successful:
            query["call_successful"] = call_successful == "true"
        
        if e2e_latency_min is not None or e2e_latency_max is not None:
            query["e2e_latency"] = {}
            if e2e_latency_min is not None:
                query["e2e_latency"]["$gte"] = e2e_latency_min
            if e2e_latency_max is not None:
                query["e2e_latency"]["$lte"] = e2e_latency_max
        
        if start_date or end_date:
            query["start_time"] = {}
            if start_date:
                query["start_time"]["$gte"] = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
            if end_date:
                query["start_time"]["$lte"] = datetime.fromisoformat(end_date.replace('Z', '+00:00'))
        
        # Aggregate statistics
        total_calls = await db.call_logs.count_documents(query)
        
        # Get all calls for aggregation
        calls = await db.call_logs.find(query).to_list(length=None)
        
        # Calculate metrics
        successful_calls = sum(1 for c in calls if c.get("status") == "completed")
        failed_calls = sum(1 for c in calls if c.get("status") in ["failed", "busy", "no-answer"])
        total_duration = sum(c.get("duration", 0) for c in calls)
        total_cost = sum(c.get("cost", 0.0) for c in calls)
        
        avg_duration = total_duration / total_calls if total_calls > 0 else 0
        
        # Sentiment breakdown
        sentiment_breakdown = {
            "positive": sum(1 for c in calls if c.get("sentiment") == "positive"),
            "neutral": sum(1 for c in calls if c.get("sentiment") == "neutral"),
            "negative": sum(1 for c in calls if c.get("sentiment") == "negative"),
            "unknown": sum(1 for c in calls if c.get("sentiment") == "unknown")
        }
        
        # Calculate average sentiment score
        sentiment_scores = [c.get("user_sentiment_score", 0) for c in calls if c.get("user_sentiment_score")]
        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0
        
        # Calculate average latency
        latencies = [c.get("latency_avg", 0) for c in calls if c.get("latency_avg")]
        avg_latency = sum(latencies) / len(latencies) if latencies else 0
        
        # Group by status for disconnection reasons
        by_status = {}
        for call in calls:
            status = call.get("status", "unknown")
            by_status[status] = by_status.get(status, 0) + 1
        
        # Group by direction
        by_direction = {}
        for call in calls:
            direction = call.get("direction", "unknown")
            by_direction[direction] = by_direction.get(direction, 0) + 1
        
        # Group calls by date for time series
        from collections import defaultdict
        call_count_by_date = defaultdict(int)
        for call in calls:
            if call.get("start_time"):
                date_key = call["start_time"].strftime("%Y-%m-%d")
                call_count_by_date[date_key] += 1
        
        # Convert to sorted list
        call_count_data = [{"date": date, "count": count} for date, count in sorted(call_count_by_date.items())]
        
        # Calculate success rate
        completed_calls = sum(1 for c in calls if c.get("status") == "completed")
        success_rate = (completed_calls / total_calls * 100) if total_calls > 0 else 0
        
        analytics = {
            "total_calls": total_calls,
            "completed_calls": completed_calls,
            "successful_calls": successful_calls,
            "failed_calls": failed_calls,
            "success_rate": round(success_rate, 1),
            "avg_duration": round(avg_duration, 2),
            "total_duration": total_duration,
            "total_cost": round(total_cost, 2),
            "avg_sentiment": round(avg_sentiment, 3),
            "sentiment_positive": sentiment_breakdown.get("positive", 0),
            "sentiment_negative": sentiment_breakdown.get("negative", 0),
            "sentiment_neutral": sentiment_breakdown.get("neutral", 0),
            "sentiment_unknown": sentiment_breakdown.get("unknown", 0),
            "avg_latency": round(avg_latency, 2),
            "by_status": by_status,
            "by_direction": by_direction,
            "call_count_by_date": call_count_data,
            "period_start": start_date or "all_time",
            "period_end": end_date or "now"
        }
        
        return analytics
    except Exception as e:
        logger.error(f"Error calculating analytics: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@api_router.delete("/call-history/{call_id}")
async def delete_call_log(call_id: str, current_user: dict = Depends(get_current_user)):
    """Delete a call log"""
    try:
        result = await db.call_logs.delete_one({"call_id": call_id, "user_id": current_user['id']})
        
        if result.deleted_count == 0:
            raise HTTPException(status_code=404, detail="Call not found")
        
        return {"message": "Call log deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting call log: {e}")
        raise HTTPException(status_code=500, detail=str(e))


app.include_router(api_router)


# Configure CORS origins from environment variable
cors_origins_str = os.environ.get('CORS_ORIGINS', 'http://localhost:3000')
cors_origins = [origin.strip() for origin in cors_origins_str.split(',') if origin.strip()]

# Add fallback origins for development
if 'http://localhost:3000' not in cors_origins:
    cors_origins.append('http://localhost:3000')

logger.info(f"üåê CORS configured for origins: {cors_origins}")

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=cors_origins,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()
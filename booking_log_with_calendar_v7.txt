âœ… Loaded agent: JK First Caller-optimizer3-antigrav
   Model: grok-4-fast-non-reasoning
âœ… Loaded agent: JK First Caller-optimizer3-antigrav
   Model: grok-4-fast-non-reasoning
   Flow nodes: 66
âš ï¸ Could not import RAG service: Read-only file system (os error 30)
ğŸ“‹ Built cached system prompt: 5684 chars (global) + 1402 chars (technical)
ğŸ’‰ Injecting custom variables: {'customer_name': 'Kendrick', 'email': 'kendrickbowman9@gmail.com'}
âœ… Session initialized

============================================================
ğŸ“œ RUNNING SCRIPTED CONVERSATION
============================================================


============================================================
ğŸ¤ TURN 5: User says: "User: Hello?"
============================================================
â±ï¸ [20:06:45.512] ğŸ“¥ process_user_input() ENTRY - text: 'User: Hello?...'
â±ï¸ [20:06:45.512] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:45.512] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:45.512] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 1, Is first: True
â±ï¸ [20:06:45.512] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 9 chars) - will return text instantly
Using flow node: Greeting (type: conversation, mode: script)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [20:06:45.512] ğŸ“„ About to process content (mode=script, length=9)
ğŸ“¤ Streaming script as 1 sentence(s)
    ğŸ”Š TTS: Kendrick?
ğŸ“¤ Streamed script sentence 1/1: Kendrick?...
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 2 in conversation history
LLM response (0.00s): Kendrick?
Total latency: 0.00s

   ğŸ“ NODE: Greeting
   ğŸ¤– RESPONSE: Kendrick?

============================================================
ğŸ¤ TURN 6: User says: "User: Yes, this is Kendrick."
============================================================
â±ï¸ [20:06:46.013] ğŸ“¥ process_user_input() ENTRY - text: 'User: Yes, this is Kendrick....'
â±ï¸ [20:06:46.013] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:46.014] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:46.014] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 3, Is first: False
ğŸ” Using explicitly set current_node_id: 2
â±ï¸ [20:06:46.014] ğŸ”€ About to call _follow_transition() for: User: Yes, this is Kendrick....
Evaluating transitions from Greeting for message: User: Yes, this is Kendrick.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:06:46.064] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 3 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:46.488] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 423ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Confirms name (Yes|Speaking|This is he/she|etc)...', 'Wrong number (No John here|Wrong number|etc) - don...', 'Does not conform (Any other response / Resistance)...']
Selected transition index: 0
Transition: Greeting -> Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
â±ï¸ [TIMING] TRANSITION_EVAL: 474ms
â±ï¸ [20:06:46.488] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 89 chars) - will return text instantly
Using flow node: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation) (type: conversation, mode: script)
â±ï¸ [20:06:46.488] ğŸ“„ About to process content (mode=script, length=89)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: This is Jake...
ğŸ“¤ Streamed script sentence 1/2: This is Jake......
    ğŸ”Š TTS: I was just, um, wondering if you could possibly help me out for a moment?
ğŸ“¤ Streamed script sentence 2/2: I was just, um, wondering if you could possibly he...
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763159750250 in conversation history
LLM response (0.48s): This is Jake... I was just, um, wondering if you could possibly help me out for a moment?
Total latency: 0.48s

   ğŸ“ NODE: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
   ğŸ¤– RESPONSE: This is Jake... I was just, um, wondering if you could possibly help me out for a moment?

============================================================
ğŸ¤ TURN 7: User says: "User: Sure, what is this about?"
============================================================
â±ï¸ [20:06:46.990] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sure, what is this about?...'
â±ï¸ [20:06:46.990] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:46.990] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:46.990] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 5, Is first: False
ğŸ” Using explicitly set current_node_id: 1763159750250
â±ï¸ [20:06:46.990] ğŸ”€ About to call _follow_transition() for: User: Sure, what is this about...
Evaluating transitions from Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation) for message: User: Sure, what is this about?
ğŸ¤ AUTO-TRANSITION AFTER RESPONSE enabled - user spoke, transitioning to: 1763161849799
âœ… Auto-transitioned (after response) to: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
ğŸ“ User's response captured: 'User: Sure, what is this about?...'
â±ï¸ [TIMING] TRANSITION_EVAL: 0ms
â±ï¸ [20:06:46.991] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 260 chars) - will return text instantly
Using flow node: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic (type: conversation, mode: script)
â±ï¸ [20:06:46.991] ğŸ“„ About to process content (mode=script, length=260)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: Well, uh, I don't know if you could yet, but, I'm calling because you filled out...
ğŸ“¤ Streamed script sentence 1/2: Well, uh, I don't know if you could yet, but, I'm ...
    ğŸ”Š TTS: I know this call is out of the blue, but do you have just 25 seconds for me to e...
ğŸ“¤ Streamed script sentence 2/2: I know this call is out of the blue, but do you ha...
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763161849799 in conversation history
LLM response (0.00s): Well, uh, I don't know if you could yet, but, I'm calling because you filled out an ad about stacking income without stacking hours. I know this call is out of the blue, but do you have just 25 seconds for me to explain why I'm reaching out today specifically?
Total latency: 0.00s

   ğŸ“ NODE: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
   ğŸ¤– RESPONSE: Well, uh, I don't know if you could yet, but, I'm calling because you filled out an ad about stacking income without stacking hours. I know this call is out of the blue, but do you have just 25 second...

============================================================
ğŸ¤ TURN 8: User says: "User: That sounds interesting."
============================================================
â±ï¸ [20:06:47.492] ğŸ“¥ process_user_input() ENTRY - text: 'User: That sounds interesting....'
â±ï¸ [20:06:47.492] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:47.493] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:47.493] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 7, Is first: False
ğŸ” Using explicitly set current_node_id: 1763161849799
â±ï¸ [20:06:47.493] ğŸ”€ About to call _follow_transition() for: User: That sounds interesting....
Evaluating transitions from Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic for message: User: That sounds interesting.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:06:47.549] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 4 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:47.823] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 273ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Agrees|consents (yes|sure|okay|hear more|call cons...', 'Any objection or non compliance that isn\'t a "I do...', 'NO (flat out)|No recall (done quickly) AND no othe...', "I'm Busy, or requests to call back responses from ..."]
Selected transition index: 0
Transition: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic -> N_IntroduceModel_And_AskQuestions_V3_Adaptive
â±ï¸ [TIMING] TRANSITION_EVAL: 330ms
â±ï¸ [20:06:47.823] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 164 chars) - will return text instantly
Using flow node: N_IntroduceModel_And_AskQuestions_V3_Adaptive (type: conversation, mode: script)
â±ï¸ [20:06:47.823] ğŸ“„ About to process content (mode=script, length=164)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: Okay, in a nutshell, we set up passive income websites, and we let them produce ...
ğŸ“¤ Streamed script sentence 1/2: Okay, in a nutshell, we set up passive income webs...
    ğŸ”Š TTS: What questions come to mind as soon as you hear something like that?
ğŸ“¤ Streamed script sentence 2/2: What questions come to mind as soon as you hear so...
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763163400676 in conversation history
LLM response (0.33s): Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What questions come to mind as soon as you hear something like that?
Total latency: 0.33s

   ğŸ“ NODE: N_IntroduceModel_And_AskQuestions_V3_Adaptive
   ğŸ¤– RESPONSE: Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What questions come to mind as soon as you hear something like that?

============================================================
ğŸ¤ TURN 9: User says: "User: I work in software sales."
============================================================
â±ï¸ [20:06:48.325] ğŸ“¥ process_user_input() ENTRY - text: 'User: I work in software sales....'
â±ï¸ [20:06:48.325] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:48.325] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:48.326] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 9, Is first: False
ğŸ” Using explicitly set current_node_id: 1763163400676
â±ï¸ [20:06:48.326] ğŸ”€ About to call _follow_transition() for: User: I work in software sales...
Evaluating transitions from N_IntroduceModel_And_AskQuestions_V3_Adaptive for message: User: I work in software sales.
ğŸ¤ AUTO-TRANSITION AFTER RESPONSE enabled - user spoke, transitioning to: 1763206946898
âœ… Auto-transitioned (after response) to: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
ğŸ“ User's response captured: 'User: I work in software sales....'
â±ï¸ [TIMING] TRANSITION_EVAL: 0ms
â±ï¸ [20:06:48.327] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive (type: conversation, mode: conversation)
ğŸ“š Q&A/KB node detected by label - skipping pre-response mandatory check, will check on transition
â±ï¸ [20:06:48.327] ğŸ“„ About to process content (mode=conversation, length=483)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N_KB_Q&A_With_StrategicNarrative_V3_Adaptive': use_parallel_llm=False
â±ï¸ [20:06:48.373] ğŸ’¬ LLM REQUEST START: 9 conversation turns, 8508 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (1422 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 5, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:06 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (9 messages)
ğŸ“   assistant: Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What...
ğŸ“   user: User: I work in software sales....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:48.933] ğŸ’¬ LLM FIRST TOKEN: 560ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Software sales is a solid field.
ğŸ“¤ Streamed sentence: [N] Software sales is a solid field....
    ğŸ”Š TTS: How does that tie into your interest in adding passive income streams on the sid...
ğŸ“¤ Streamed final fragment: How does that tie into your interest in adding pas...
â±ï¸ [TIMING] LLM_TOTAL: 751ms for 119 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763206946898 in conversation history
LLM response (0.80s): [N] Software sales is a solid field. How does that tie into your interest in adding passive income streams on the side?
Total latency: 0.80s

   ğŸ“ NODE: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
   ğŸ¤– RESPONSE: [N] Software sales is a solid field. How does that tie into your interest in adding passive income streams on the side?

============================================================
ğŸ¤ TURN 13: User says: "User: I make about $120,000 a year base."
============================================================
â±ï¸ [20:06:49.626] ğŸ“¥ process_user_input() ENTRY - text: 'User: I make about $120,000 a year base....'
â±ï¸ [20:06:49.626] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:49.627] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:49.627] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 11, Is first: False
ğŸ” Using explicitly set current_node_id: 1763206946898
â±ï¸ [20:06:49.627] ğŸ”€ About to call _follow_transition() for: User: I make about $120,000 a ...
Evaluating transitions from N_KB_Q&A_With_StrategicNarrative_V3_Adaptive for message: User: I make about $120,000 a year base.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:06:49.676] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:50.198] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 521ms
ğŸ¤– AI transition decision: '1'
ğŸ“Š Available transitions: ['...would you honestly be upset if you had an extra...', 'User has answered income questions, provided finan...']
Selected transition index: 1
Transition: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive -> Logic Split - Income
â±ï¸ [TIMING] TRANSITION_EVAL: 571ms
â±ï¸ [20:06:50.198] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
ğŸ” Auto-detected PROMPT mode (instruction markers found)
Using flow node: Logic Split - Income (type: logic_split, mode: prompt)
ğŸ”€ Logic Split node reached - evaluating conditions
ğŸ”€ Evaluating 1 conditions
  Condition 1: amount_reference greater_than 8000
    Variable value: 
    Could not extract numbers: var=None, compare=8000.0
    Result: False
â„¹ï¸ No conditions matched - using default path: 1763197118793
âœ… Condition matched - moving to node: N_AskCapital_5k_V1_Adaptive
ğŸ“‹ Processing node streaming - Type: conversation, Mode: prompt, Content length: 921 chars
ğŸ¤– Using PROMPT mode - will generate AI response
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:06:50.245] ğŸ’¬ LLM REQUEST START: 11 conversation turns, 8946 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (1860 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 6, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:06 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (11 messages)
ğŸ“   assistant: [N] Software sales is a solid field. How does that tie into your interest in adding passive income s...
ğŸ“   user: User: I make about $120,000 a year base....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:51.278] ğŸ’¬ LLM FIRST TOKEN: 1033ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] $120,000 base is impressiveâ€”plenty of room to build on that with passive str...
ğŸ“¤ Streamed sentence: [N] $120,000 base is impressiveâ€”plenty of room to ...
    ğŸ”Š TTS: For this model,
ğŸ“¤ Streamed sentence: For this model,...
    ğŸ”Š TTS: we typically look for about five thousand dollars in liquid capital to get start...
ğŸ“¤ Streamed sentence: we typically look for about five thousand dollars ...
    ğŸ”Š TTS: Do you have that amount accessible right now?
ğŸ“¤ Streamed final fragment: Do you have that amount accessible right now?...
â±ï¸ [TIMING] LLM_TOTAL: 1505ms for 231 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763197118793 in conversation history
LLM response (2.12s): [N] $120,000 base is impressiveâ€”plenty of room to build on that with passive streams. For this model, we typically look for about five thousand dollars in liquid capital to get started. Do you have that amount accessible right now?
Total latency: 2.12s

   ğŸ“ NODE: N_AskCapital_5k_V1_Adaptive
   ğŸ¤– RESPONSE: [N] $120,000 base is impressiveâ€”plenty of room to build on that with passive streams. For this model, we typically look for about five thousand dollars in liquid capital to get started. Do you have th...

============================================================
ğŸ¤ TURN 15: User says: "User: I have about $20,000 in savings right now."
============================================================
â±ï¸ [20:06:52.252] ğŸ“¥ process_user_input() ENTRY - text: 'User: I have about $20,000 in savings right now....'
â±ï¸ [20:06:52.259] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:52.260] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:52.260] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 13, Is first: False
ğŸ” Using explicitly set current_node_id: 1763197118793
â±ï¸ [20:06:52.260] ğŸ”€ About to call _follow_transition() for: User: I have about $20,000 in ...
Evaluating transitions from N_AskCapital_5k_V1_Adaptive for message: User: I have about $20,000 in savings right now.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:06:52.335] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:52.714] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 379ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ["If the user's response indicates they have the cap...", "They indicate they don't have at least $5k (ie, No..."]
Selected transition index: 0
Transition: N_AskCapital_5k_V1_Adaptive -> N401_AskWhyNow_Initial_V10_AssertiveFrame
â±ï¸ [TIMING] TRANSITION_EVAL: 454ms
â±ï¸ [20:06:52.714] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [20:06:52.715] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/13 messages)
â±ï¸ [20:06:52.762] ğŸ’¬ LLM REQUEST START: 13 conversation turns, 12692 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5606 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 7, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:06 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] $120,000 base is impressiveâ€”plenty of room to build on that with passive streams. For this model...
ğŸ“   user: User: I have about $20,000 in savings right now....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:53.836] ğŸ’¬ LLM FIRST TOKEN: 1073ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Twenty thousand in savings gives you strong flexibility to start strong.
ğŸ“¤ Streamed sentence: [N] Twenty thousand in savings gives you strong fl...
    ğŸ”Š TTS: Just to understand a bit better,
ğŸ“¤ Streamed sentence: Just to understand a bit better,...
    ğŸ”Š TTS: is there a specific reason you're looking to make a change or explore something ...
ğŸ“¤ Streamed sentence: is there a specific reason you're looking to make ...
    ğŸ”Š TTS: as opposed to say,
ğŸ“¤ Streamed sentence: as opposed to say,...
    ğŸ”Š TTS: six months from now?
ğŸ“¤ Streamed final fragment: six months from now?...
â±ï¸ [TIMING] LLM_TOTAL: 1497ms for 250 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (2.01s): [N] Twenty thousand in savings gives you strong flexibility to start strong. Just to understand a bit better, is there a specific reason you're looking to make a change or explore something like this right now, as opposed to say, six months from now?
Total latency: 2.01s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] Twenty thousand in savings gives you strong flexibility to start strong. Just to understand a bit better, is there a specific reason you're looking to make a change or explore something like this ...

============================================================
ğŸ¤ TURN 17: User says: "User: No, it's just me making the decisions."
============================================================
â±ï¸ [20:06:54.762] ğŸ“¥ process_user_input() ENTRY - text: 'User: No, it's just me making the decisions....'
â±ï¸ [20:06:54.762] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:54.762] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:54.762] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 15, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [20:06:54.762] ğŸ”€ About to call _follow_transition() for: User: No, it's just me making ...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: No, it's just me making the decisions.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:06:54.799] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:55.219] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 420ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: To ask the "Why now?" question and then use assertive, frame-controlling tactics to handle any defer...
â±ï¸ [TIMING] TRANSITION_EVAL: 457ms
â±ï¸ [20:06:55.219] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [20:06:55.220] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/15 messages)
â±ï¸ [20:06:55.264] ğŸ’¬ LLM REQUEST START: 15 conversation turns, 12692 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5606 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 8, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:06 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Twenty thousand in savings gives you strong flexibility to start strong. Just to understand a bi...
ğŸ“   user: User: No, it's just me making the decisions....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:55.859] ğŸ’¬ LLM FIRST TOKEN: 594ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Got it,
ğŸ“¤ Streamed sentence: [N] Got it,...
    ğŸ”Š TTS: so you're the one calling the shots here.
ğŸ“¤ Streamed sentence: so you're the one calling the shots here....
    ğŸ”Š TTS: Exploring passive income now makes sense with that baseâ€”when you think about you...
ğŸ“¤ Streamed sentence: Exploring passive income now makes sense with that...
    ğŸ”Š TTS: do you see yourself staying put or making a move to add those extra streams?
ğŸ“¤ Streamed final fragment: do you see yourself staying put or making a move t...
â±ï¸ [TIMING] LLM_TOTAL: 1137ms for 246 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (1.64s): [N] Got it, so you're the one calling the shots here. Exploring passive income now makes sense with that baseâ€”when you think about your financial picture six months out, do you see yourself staying put or making a move to add those extra streams?
Total latency: 1.64s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] Got it, so you're the one calling the shots here. Exploring passive income now makes sense with that baseâ€”when you think about your financial picture six months out, do you see yourself staying pu...

============================================================
ğŸ¤ TURN 19: User says: "User: I can probably deduce about 10 hours a week."
============================================================
â±ï¸ [20:06:56.903] ğŸ“¥ process_user_input() ENTRY - text: 'User: I can probably deduce about 10 hours a week....'
â±ï¸ [20:06:56.904] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:56.904] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:56.904] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 17, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [20:06:56.904] ğŸ”€ About to call _follow_transition() for: User: I can probably deduce ab...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: I can probably deduce about 10 hours a week.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:06:56.939] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:57.379] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 440ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: To ask the "Why now?" question and then use assertive, frame-controlling tactics to handle any defer...
â±ï¸ [TIMING] TRANSITION_EVAL: 476ms
â±ï¸ [20:06:57.380] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [20:06:57.380] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/17 messages)
â±ï¸ [20:06:57.424] ğŸ’¬ LLM REQUEST START: 17 conversation turns, 12692 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5606 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 9, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:06 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Got it, so you're the one calling the shots here. Exploring passive income now makes sense with ...
ğŸ“   user: User: I can probably deduce about 10 hours a week....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:57.973] ğŸ’¬ LLM FIRST TOKEN: 549ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Ten hours a week is a realistic commitment that fits well with our model.
ğŸ“¤ Streamed sentence: [N] Ten hours a week is a realistic commitment tha...
    ğŸ”Š TTS: With your solid base income,
ğŸ“¤ Streamed sentence: With your solid base income,...
    ğŸ”Š TTS: what's prompting you to explore building passive streams right now instead of wa...
ğŸ“¤ Streamed final fragment: what's prompting you to explore building passive s...
â±ï¸ [TIMING] LLM_TOTAL: 834ms for 206 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (1.36s): [N] Ten hours a week is a realistic commitment that fits well with our model. With your solid base income, what's prompting you to explore building passive streams right now instead of waiting a few months?
Total latency: 1.36s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] Ten hours a week is a realistic commitment that fits well with our model. With your solid base income, what's prompting you to explore building passive streams right now instead of waiting a few m...

============================================================
ğŸ¤ TURN 21: User says: "User: My credit is good, around 750."
============================================================
â±ï¸ [20:06:58.760] ğŸ“¥ process_user_input() ENTRY - text: 'User: My credit is good, around 750....'
â±ï¸ [20:06:58.761] â© About to call _process_call_flow_streaming()
â±ï¸ [20:06:58.761] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:06:58.761] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 19, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [20:06:58.761] ğŸ”€ About to call _follow_transition() for: User: My credit is good, aroun...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: My credit is good, around 750.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:06:58.811] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:06:59.427] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 616ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: To ask the "Why now?" question and then use assertive, frame-controlling tactics to handle any defer...
â±ï¸ [TIMING] TRANSITION_EVAL: 666ms
â±ï¸ [20:06:59.428] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:06 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [20:06:59.428] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/19 messages)
â±ï¸ [20:06:59.472] ğŸ’¬ LLM REQUEST START: 19 conversation turns, 12693 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5607 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 10, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:06 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Ten hours a week is a realistic commitment that fits well with our model. With your solid base i...
ğŸ“   user: User: My credit is good, around 750....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:00.120] ğŸ’¬ LLM FIRST TOKEN: 648ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] A 750 credit score is excellent and opens up options if needed.
ğŸ“¤ Streamed sentence: [N] A 750 credit score is excellent and opens up o...
    ğŸ”Š TTS: With that financial stability,
ğŸ“¤ Streamed sentence: With that financial stability,...
    ğŸ”Š TTS: what's the main driver behind looking into passive income opportunities like thi...
ğŸ“¤ Streamed sentence: what's the main driver behind looking into passive...
    ğŸ”Š TTS: rather than putting it off for later?
ğŸ“¤ Streamed final fragment: rather than putting it off for later?...
â±ï¸ [TIMING] LLM_TOTAL: 960ms for 225 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (1.67s): [N] A 750 credit score is excellent and opens up options if needed. With that financial stability, what's the main driver behind looking into passive income opportunities like this today, rather than putting it off for later?
Total latency: 1.67s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] A 750 credit score is excellent and opens up options if needed. With that financial stability, what's the main driver behind looking into passive income opportunities like this today, rather than ...

============================================================
ğŸ¤ TURN 25: User says: "User: That makes sense. I see why you called."
============================================================
â±ï¸ [20:07:00.934] ğŸ“¥ process_user_input() ENTRY - text: 'User: That makes sense. I see why you called....'
â±ï¸ [20:07:00.934] â© About to call _process_call_flow_streaming()
â±ï¸ [20:07:00.934] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:07:00.934] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 21, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [20:07:00.934] ğŸ”€ About to call _follow_transition() for: User: That makes sense. I see ...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: That makes sense. I see why you called.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:07:00.981] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:01.366] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 385ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: 0
Transition: N401_AskWhyNow_Initial_V10_AssertiveFrame -> N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
â±ï¸ [TIMING] TRANSITION_EVAL: 432ms
â±ï¸ [20:07:01.367] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:07 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned (type: conversation, mode: prompt)
â±ï¸ [20:07:01.367] ğŸ“„ About to process content (mode=prompt, length=1863)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/21 messages)
â±ï¸ [20:07:01.410] ğŸ’¬ LLM REQUEST START: 21 conversation turns, 9889 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (2803 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 11, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:07 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] A 750 credit score is excellent and opens up options if needed. With that financial stability, w...
ğŸ“   user: User: That makes sense. I see why you called....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:02.003] ğŸ’¬ LLM FIRST TOKEN: 593ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] I appreciate you sharing that.
ğŸ“¤ Streamed sentence: [N] I appreciate you sharing that....
    ğŸ”Š TTS: I have to say,
ğŸ“¤ Streamed sentence: I have to say,...
    ğŸ”Š TTS: that's actually refreshing to hear.
ğŸ“¤ Streamed sentence: that's actually refreshing to hear....
    ğŸ”Š TTS: You know why?
ğŸ“¤ Streamed final fragment: You know why?...
â±ï¸ [TIMING] LLM_TOTAL: 778ms for 99 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198047712 in conversation history
LLM response (1.26s): [N] I appreciate you sharing that. I have to say, that's actually refreshing to hear. You know why?
Total latency: 1.26s

   ğŸ“ NODE: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
   ğŸ¤– RESPONSE: [N] I appreciate you sharing that. I have to say, that's actually refreshing to hear. You know why?

============================================================
ğŸ¤ TURN 28: User says: "User: I am in Eastern time."
============================================================
â±ï¸ [20:07:02.691] ğŸ“¥ process_user_input() ENTRY - text: 'User: I am in Eastern time....'
â±ï¸ [20:07:02.691] â© About to call _process_call_flow_streaming()
â±ï¸ [20:07:02.691] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:07:02.691] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 23, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198047712
â±ï¸ [20:07:02.691] ğŸ”€ About to call _follow_transition() for: User: I am in Eastern time....
Evaluating transitions from N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned for message: User: I am in Eastern time.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:07:02.740] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:03.169] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 428ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['The User responds with anything - take their respo...', 'The user says they have to go. - Call them back - ...']
Selected transition index: 0
Transition: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned -> N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
â±ï¸ [TIMING] TRANSITION_EVAL: 477ms
â±ï¸ [20:07:03.169] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:07 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned (type: conversation, mode: prompt)
â±ï¸ [20:07:03.169] ğŸ“„ About to process content (mode=prompt, length=4458)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/23 messages)
â±ï¸ [20:07:03.217] ğŸ’¬ LLM REQUEST START: 23 conversation turns, 12484 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5398 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 12, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:07 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] I appreciate you sharing that. I have to say, that's actually refreshing to hear. You know why?...
ğŸ“   user: User: I am in Eastern time....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:03.695] ğŸ’¬ LLM FIRST TOKEN: 477ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Eastern time works perfectly since that's where I'm based too.
ğŸ“¤ Streamed sentence: [N] Eastern time works perfectly since that's wher...
    ğŸ”Š TTS: You know why?
ğŸ“¤ Streamed final fragment: You know why?...
â±ï¸ [TIMING] LLM_TOTAL: 600ms for 80 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198201369 in conversation history
LLM response (1.13s): [N] Eastern time works perfectly since that's where I'm based too. You know why?
Total latency: 1.13s

   ğŸ“ NODE: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
   ğŸ¤– RESPONSE: [N] Eastern time works perfectly since that's where I'm based too. You know why?

============================================================
ğŸ¤ TURN 32: User says: "User: Sure, Tuesday at 2pm works for me."
============================================================
â±ï¸ [20:07:04.319] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sure, Tuesday at 2pm works for me....'
â±ï¸ [20:07:04.320] â© About to call _process_call_flow_streaming()
â±ï¸ [20:07:04.320] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:07:04.320] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 25, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198201369
â±ï¸ [20:07:04.320] ğŸ”€ About to call _follow_transition() for: User: Sure, Tuesday at 2pm wor...
Evaluating transitions from N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned for message: User: Sure, Tuesday at 2pm works for me.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:07:04.366] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:04.909] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 542ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['The User responds saying yes to some relevant valu...', 'The user says they have to go....']
Selected transition index: 0
Transition: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned -> N500A_ProposeDeeperDive_V5_Adaptive
â±ï¸ [TIMING] TRANSITION_EVAL: 589ms
â±ï¸ [20:07:04.909] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:07 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500A_ProposeDeeperDive_V5_Adaptive (type: conversation, mode: prompt)
â±ï¸ [20:07:04.909] ğŸ“„ About to process content (mode=prompt, length=4127)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500A_ProposeDeeperDive_V5_Adaptive': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/25 messages)
â±ï¸ [20:07:04.953] ğŸ’¬ LLM REQUEST START: 25 conversation turns, 12153 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5067 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 13, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:07 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Eastern time works perfectly since that's where I'm based too. You know why?...
ğŸ“   user: User: Sure, Tuesday at 2pm works for me....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:05.353] ğŸ’¬ LLM FIRST TOKEN: 399ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Perfect,
ğŸ“¤ Streamed sentence: [N] Perfect,...
    ğŸ”Š TTS: Tuesday at 2pm Eastern works great.
ğŸ“¤ Streamed sentence: Tuesday at 2pm Eastern works great....
    ğŸ”Š TTS: I'll go ahead and lock that in for you with our senior consultant,
ğŸ“¤ Streamed sentence: I'll go ahead and lock that in for you with our se...
    ğŸ”Š TTS: Kendrick,
ğŸ“¤ Streamed sentence: Kendrick,...
    ğŸ”Š TTS: to dive deeper into your strategy for those lead gen sites.
ğŸ“¤ Streamed sentence: to dive deeper into your strategy for those lead g...
    ğŸ”Š TTS: Just to confirm,
ğŸ“¤ Streamed sentence: Just to confirm,...
    ğŸ”Š TTS: is that your best contact number and email for the details?
ğŸ“¤ Streamed final fragment: is that your best contact number and email for the...
â±ï¸ [TIMING] LLM_TOTAL: 820ms for 262 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198305881 in conversation history
LLM response (1.45s): [N] Perfect, Tuesday at 2pm Eastern works great. I'll go ahead and lock that in for you with our senior consultant, Kendrick, to dive deeper into your strategy for those lead gen sites. Just to confirm, is that your best contact number and email for the details?
Total latency: 1.45s

   ğŸ“ NODE: N500A_ProposeDeeperDive_V5_Adaptive
   ğŸ¤– RESPONSE: [N] Perfect, Tuesday at 2pm Eastern works great. I'll go ahead and lock that in for you with our senior consultant, Kendrick, to dive deeper into your strategy for those lead gen sites. Just to confir...

============================================================
ğŸ¤ TURN 35: User says: "User: Sounds great, lock it in!"
============================================================
â±ï¸ [20:07:06.276] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sounds great, lock it in!...'
â±ï¸ [20:07:06.276] â© About to call _process_call_flow_streaming()
â±ï¸ [20:07:06.276] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:07:06.276] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 27, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198305881
â±ï¸ [20:07:06.276] ğŸ”€ About to call _follow_transition() for: User: Sounds great, lock it in...
Evaluating transitions from N500A_ProposeDeeperDive_V5_Adaptive for message: User: Sounds great, lock it in!
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:07:06.347] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:06.741] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 393ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Prospect agrees that setting up another call "soun...']
Selected transition index: 0
Transition: N500A_ProposeDeeperDive_V5_Adaptive -> N500B_AskTimezone_V2_FullyTuned
â±ï¸ [TIMING] TRANSITION_EVAL: 465ms
â±ï¸ [20:07:06.741] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:07 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500B_AskTimezone_V2_FullyTuned (type: conversation, mode: prompt)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [20:07:06.741] ğŸ“„ About to process content (mode=prompt, length=1398)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500B_AskTimezone_V2_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/27 messages)
â±ï¸ [20:07:06.788] ğŸ’¬ LLM REQUEST START: 27 conversation turns, 9424 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (2338 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: I type - adjust your response accordingly
CONVERSATION STATUS: Turn 14, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:07 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Perfect, Tuesday at 2pm Eastern works great. I'll go ahead and lock that in for you with our sen...
ğŸ“   user: User: Sounds great, lock it in!...
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:07.320] ğŸ’¬ LLM FIRST TOKEN: 531ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Awesome,
ğŸ“¤ Streamed sentence: [N] Awesome,...
    ğŸ”Š TTS: Tuesday at 2pm Eastern it is.
ğŸ“¤ Streamed sentence: Tuesday at 2pm Eastern it is....
    ğŸ”Š TTS: Let me check the calendar for that time real quick.
ğŸ“¤ Streamed sentence: Let me check the calendar for that time real quick...
    ğŸ”Š TTS: One second.
ğŸ“¤ Streamed final fragment: One second....
â±ï¸ [TIMING] LLM_TOTAL: 739ms for 106 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198398056 in conversation history
LLM response (1.25s): [N] Awesome, Tuesday at 2pm Eastern it is. Let me check the calendar for that time real quick. One second.
Total latency: 1.25s

   ğŸ“ NODE: N500B_AskTimezone_V2_FullyTuned
   ğŸ¤– RESPONSE: [N] Awesome, Tuesday at 2pm Eastern it is. Let me check the calendar for that time real quick. One second.

============================================================
ğŸ¤ TURN 36: User says: "Great, bye."
============================================================
â±ï¸ [20:07:08.028] ğŸ“¥ process_user_input() ENTRY - text: 'Great, bye....'
â±ï¸ [20:07:08.029] â© About to call _process_call_flow_streaming()
â±ï¸ [20:07:08.029] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [20:07:08.029] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 29, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198398056
ğŸ” PRE-TRANSITION: Extracting mandatory vars on CURRENT node N500B_AskTimezone_V2_FullyTuned before transition
ğŸ” Real-time extraction: Processing 3 variables
ğŸ¤– Using configured LLM provider: grok (grok-4-fast-non-reasoning) for extraction
Failed to decrypt key, assuming unencrypted: 
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
  âœ“ timeZone: Eastern time (extracted in real-time)
  âœ“ scheduleTime: Tuesday at 2pm (extracted in real-time)
  âœ“ amPm: pm (extracted in real-time)
âœ… Real-time extraction complete: 3 variables
âœ… PRE-TRANSITION: All mandatory vars satisfied on N500B_AskTimezone_V2_FullyTuned - proceeding with transition
â±ï¸ [20:07:08.582] ğŸ”€ About to call _follow_transition() for: Great, bye....
Evaluating transitions from N500B_AskTimezone_V2_FullyTuned for message: Great, bye.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [20:07:08.630] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:09.058] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 427ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ['The user has provided their timezone OR the user c...']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: Remove ssml tags - and keep toolkits max 1-2 sentences before any questions decigned to acheive the ...
â±ï¸ [TIMING] TRANSITION_EVAL: 475ms
â±ï¸ [20:07:09.058] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 8:07 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
ğŸ”§ Replaced {{timeZone}} with Eastern time in content
ğŸ”§ Replaced {{scheduleTime}} with Tuesday at 2pm in content
ğŸ”§ Replaced {{amPm}} with pm in content
Using flow node: N500B_AskTimezone_V2_FullyTuned (type: conversation, mode: prompt)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [20:07:09.059] ğŸ“„ About to process content (mode=prompt, length=1398)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500B_AskTimezone_V2_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/29 messages)
â±ï¸ [20:07:09.104] ğŸ’¬ LLM REQUEST START: 29 conversation turns, 9500 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (2414 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: I type - adjust your response accordingly
CONVERSATION STATUS: Turn 15, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 8:07 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Awesome, Tuesday at 2pm Eastern it is. Let me check the calendar for that time real quick. One s...
ğŸ“   user: Great, bye....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [20:07:09.726] ğŸ’¬ LLM FIRST TOKEN: 622ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Sounds good,
ğŸ“¤ Streamed sentence: [N] Sounds good,...
    ğŸ”Š TTS: Kendrick.
ğŸ“¤ Streamed sentence: Kendrick....
    ğŸ”Š TTS: Looking forward to Tuesday at 2pm Eastern.
ğŸ“¤ Streamed sentence: Looking forward to Tuesday at 2pm Eastern....
    ğŸ”Š TTS: Have a great evening!
ğŸ“¤ Streamed final fragment: Have a great evening!...
â±ï¸ [TIMING] LLM_TOTAL: 863ms for 91 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_200645 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198398056 in conversation history
LLM response (1.94s): [N] Sounds good, Kendrick. Looking forward to Tuesday at 2pm Eastern. Have a great evening!
Total latency: 1.94s

   ğŸ“ NODE: N500B_AskTimezone_V2_FullyTuned
   ğŸ¤– RESPONSE: [N] Sounds good, Kendrick. Looking forward to Tuesday at 2pm Eastern. Have a great evening!

============================================================
ğŸ“Š SCRIPT COMPLETE - NODE HISTORY:
============================================================
  Turn 5: Greeting
  Turn 6: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
  Turn 7: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
  Turn 8: N_IntroduceModel_And_AskQuestions_V3_Adaptive
  Turn 9: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
  Turn 13: N_AskCapital_5k_V1_Adaptive
  Turn 15: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 17: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 19: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 21: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 25: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
  Turn 28: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
  Turn 32: N500A_ProposeDeeperDive_V5_Adaptive
  Turn 35: N500B_AskTimezone_V2_FullyTuned
  Turn 36: N500B_AskTimezone_V2_FullyTuned

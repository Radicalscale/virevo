âœ… Loaded agent: JK First Caller-optimizer3-antigrav
   Model: grok-4-fast-non-reasoning
âœ… Loaded agent: JK First Caller-optimizer3-antigrav
   Model: grok-4-fast-non-reasoning
   Flow nodes: 66
âš ï¸ Could not import RAG service: Read-only file system (os error 30)
ğŸ“‹ Built cached system prompt: 5684 chars (global) + 1402 chars (technical)
ğŸ’‰ Injecting custom variables: {'customer_name': 'Kendrick', 'email': 'kendrickbowman9@gmail.com'}
âœ… Session initialized

============================================================
ğŸ“œ RUNNING SCRIPTED CONVERSATION
============================================================


============================================================
ğŸ¤ TURN 5: User says: "User: Hello?"
============================================================
â±ï¸ [18:44:44.726] ğŸ“¥ process_user_input() ENTRY - text: 'User: Hello?...'
â±ï¸ [18:44:44.726] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:44.726] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:44.727] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 1, Is first: True
â±ï¸ [18:44:44.727] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 9 chars) - will return text instantly
Using flow node: Greeting (type: conversation, mode: script)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [18:44:44.727] ğŸ“„ About to process content (mode=script, length=9)
ğŸ“¤ Streaming script as 1 sentence(s)
    ğŸ”Š TTS: Kendrick?
ğŸ“¤ Streamed script sentence 1/1: Kendrick?...
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 2 in conversation history
LLM response (0.00s): Kendrick?
Total latency: 0.00s

   ğŸ“ NODE: Greeting
   ğŸ¤– RESPONSE: Kendrick?

============================================================
ğŸ¤ TURN 6: User says: "User: Yes, this is Kendrick."
============================================================
â±ï¸ [18:44:45.228] ğŸ“¥ process_user_input() ENTRY - text: 'User: Yes, this is Kendrick....'
â±ï¸ [18:44:45.229] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:45.229] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:45.229] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 3, Is first: False
ğŸ” Using explicitly set current_node_id: 2
â±ï¸ [18:44:45.229] ğŸ”€ About to call _follow_transition() for: User: Yes, this is Kendrick....
Evaluating transitions from Greeting for message: User: Yes, this is Kendrick.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:44:45.295] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 3 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:45.826] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 530ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Confirms name (Yes|Speaking|This is he/she|etc)...', 'Wrong number (No John here|Wrong number|etc) - don...', 'Does not conform (Any other response / Resistance)...']
Selected transition index: 0
Transition: Greeting -> Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
â±ï¸ [TIMING] TRANSITION_EVAL: 596ms
â±ï¸ [18:44:45.826] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 89 chars) - will return text instantly
Using flow node: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation) (type: conversation, mode: script)
â±ï¸ [18:44:45.827] ğŸ“„ About to process content (mode=script, length=89)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: This is Jake...
ğŸ“¤ Streamed script sentence 1/2: This is Jake......
    ğŸ”Š TTS: I was just, um, wondering if you could possibly help me out for a moment?
ğŸ“¤ Streamed script sentence 2/2: I was just, um, wondering if you could possibly he...
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763159750250 in conversation history
LLM response (0.60s): This is Jake... I was just, um, wondering if you could possibly help me out for a moment?
Total latency: 0.60s

   ğŸ“ NODE: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
   ğŸ¤– RESPONSE: This is Jake... I was just, um, wondering if you could possibly help me out for a moment?

============================================================
ğŸ¤ TURN 7: User says: "User: Sure, what is this about?"
============================================================
â±ï¸ [18:44:46.328] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sure, what is this about?...'
â±ï¸ [18:44:46.328] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:46.328] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:46.328] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 5, Is first: False
ğŸ” Using explicitly set current_node_id: 1763159750250
â±ï¸ [18:44:46.328] ğŸ”€ About to call _follow_transition() for: User: Sure, what is this about...
Evaluating transitions from Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation) for message: User: Sure, what is this about?
ğŸ¤ AUTO-TRANSITION AFTER RESPONSE enabled - user spoke, transitioning to: 1763161849799
âœ… Auto-transitioned (after response) to: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
ğŸ“ User's response captured: 'User: Sure, what is this about?...'
â±ï¸ [TIMING] TRANSITION_EVAL: 0ms
â±ï¸ [18:44:46.329] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 260 chars) - will return text instantly
Using flow node: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic (type: conversation, mode: script)
â±ï¸ [18:44:46.329] ğŸ“„ About to process content (mode=script, length=260)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: Well, uh, I don't know if you could yet, but, I'm calling because you filled out...
ğŸ“¤ Streamed script sentence 1/2: Well, uh, I don't know if you could yet, but, I'm ...
    ğŸ”Š TTS: I know this call is out of the blue, but do you have just 25 seconds for me to e...
ğŸ“¤ Streamed script sentence 2/2: I know this call is out of the blue, but do you ha...
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763161849799 in conversation history
LLM response (0.00s): Well, uh, I don't know if you could yet, but, I'm calling because you filled out an ad about stacking income without stacking hours. I know this call is out of the blue, but do you have just 25 seconds for me to explain why I'm reaching out today specifically?
Total latency: 0.00s

   ğŸ“ NODE: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
   ğŸ¤– RESPONSE: Well, uh, I don't know if you could yet, but, I'm calling because you filled out an ad about stacking income without stacking hours. I know this call is out of the blue, but do you have just 25 second...

============================================================
ğŸ¤ TURN 8: User says: "User: That sounds interesting."
============================================================
â±ï¸ [18:44:46.831] ğŸ“¥ process_user_input() ENTRY - text: 'User: That sounds interesting....'
â±ï¸ [18:44:46.831] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:46.831] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:46.831] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 7, Is first: False
ğŸ” Using explicitly set current_node_id: 1763161849799
â±ï¸ [18:44:46.831] ğŸ”€ About to call _follow_transition() for: User: That sounds interesting....
Evaluating transitions from Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic for message: User: That sounds interesting.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:44:46.886] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 4 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:47.157] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 270ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Agrees|consents (yes|sure|okay|hear more|call cons...', 'Any objection or non compliance that isn\'t a "I do...', 'NO (flat out)|No recall (done quickly) AND no othe...', "I'm Busy, or requests to call back responses from ..."]
Selected transition index: 0
Transition: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic -> N_IntroduceModel_And_AskQuestions_V3_Adaptive
â±ï¸ [TIMING] TRANSITION_EVAL: 326ms
â±ï¸ [18:44:47.157] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
âœ… Using explicit SCRIPT mode (length: 164 chars) - will return text instantly
Using flow node: N_IntroduceModel_And_AskQuestions_V3_Adaptive (type: conversation, mode: script)
â±ï¸ [18:44:47.158] ğŸ“„ About to process content (mode=script, length=164)
ğŸ“¤ Streaming script as 2 sentence(s)
    ğŸ”Š TTS: Okay, in a nutshell, we set up passive income websites, and we let them produce ...
ğŸ“¤ Streamed script sentence 1/2: Okay, in a nutshell, we set up passive income webs...
    ğŸ”Š TTS: What questions come to mind as soon as you hear something like that?
ğŸ“¤ Streamed script sentence 2/2: What questions come to mind as soon as you hear so...
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763163400676 in conversation history
LLM response (0.33s): Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What questions come to mind as soon as you hear something like that?
Total latency: 0.33s

   ğŸ“ NODE: N_IntroduceModel_And_AskQuestions_V3_Adaptive
   ğŸ¤– RESPONSE: Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What questions come to mind as soon as you hear something like that?

============================================================
ğŸ¤ TURN 9: User says: "User: I work in software sales."
============================================================
â±ï¸ [18:44:47.659] ğŸ“¥ process_user_input() ENTRY - text: 'User: I work in software sales....'
â±ï¸ [18:44:47.659] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:47.659] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:47.659] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 9, Is first: False
ğŸ” Using explicitly set current_node_id: 1763163400676
â±ï¸ [18:44:47.659] ğŸ”€ About to call _follow_transition() for: User: I work in software sales...
Evaluating transitions from N_IntroduceModel_And_AskQuestions_V3_Adaptive for message: User: I work in software sales.
ğŸ¤ AUTO-TRANSITION AFTER RESPONSE enabled - user spoke, transitioning to: 1763206946898
âœ… Auto-transitioned (after response) to: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
ğŸ“ User's response captured: 'User: I work in software sales....'
â±ï¸ [TIMING] TRANSITION_EVAL: 0ms
â±ï¸ [18:44:47.660] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive (type: conversation, mode: conversation)
ğŸ“š Q&A/KB node detected by label - skipping pre-response mandatory check, will check on transition
â±ï¸ [18:44:47.660] ğŸ“„ About to process content (mode=conversation, length=483)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N_KB_Q&A_With_StrategicNarrative_V3_Adaptive': use_parallel_llm=False
â±ï¸ [18:44:47.720] ğŸ’¬ LLM REQUEST START: 9 conversation turns, 8508 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (1422 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 5, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 6:44 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (9 messages)
ğŸ“   assistant: Okay, in a nutshell, we set up passive income websites, and we let them produce income for you. What...
ğŸ“   user: User: I work in software sales....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:48.215] ğŸ’¬ LLM FIRST TOKEN: 494ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Software sales is a solid fieldâ€”lots of our folks come from there and use th...
ğŸ“¤ Streamed sentence: [N] Software sales is a solid fieldâ€”lots of our fo...
    ğŸ”Š TTS: What drew you to check out that ad about stacking income without more hours?
ğŸ“¤ Streamed final fragment: What drew you to check out that ad about stacking ...
â±ï¸ [TIMING] LLM_TOTAL: 843ms for 191 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763206946898 in conversation history
LLM response (0.91s): [N] Software sales is a solid fieldâ€”lots of our folks come from there and use this to build something on the side. What drew you to check out that ad about stacking income without more hours?
Total latency: 0.91s

   ğŸ“ NODE: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
   ğŸ¤– RESPONSE: [N] Software sales is a solid fieldâ€”lots of our folks come from there and use this to build something on the side. What drew you to check out that ad about stacking income without more hours?

============================================================
ğŸ¤ TURN 13: User says: "User: I make about $120,000 a year base."
============================================================
â±ï¸ [18:44:49.075] ğŸ“¥ process_user_input() ENTRY - text: 'User: I make about $120,000 a year base....'
â±ï¸ [18:44:49.075] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:49.075] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:49.075] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 11, Is first: False
ğŸ” Using explicitly set current_node_id: 1763206946898
â±ï¸ [18:44:49.075] ğŸ”€ About to call _follow_transition() for: User: I make about $120,000 a ...
Evaluating transitions from N_KB_Q&A_With_StrategicNarrative_V3_Adaptive for message: User: I make about $120,000 a year base.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:44:49.121] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:49.539] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 418ms
ğŸ¤– AI transition decision: '1'
ğŸ“Š Available transitions: ['...would you honestly be upset if you had an extra...', 'User has answered income questions, provided finan...']
Selected transition index: 1
Transition: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive -> Logic Split - Income
â±ï¸ [TIMING] TRANSITION_EVAL: 464ms
â±ï¸ [18:44:49.539] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
ğŸ” Auto-detected PROMPT mode (instruction markers found)
Using flow node: Logic Split - Income (type: logic_split, mode: prompt)
ğŸ”€ Logic Split node reached - evaluating conditions
ğŸ”€ Evaluating 1 conditions
  Condition 1: amount_reference greater_than 8000
    Variable value: 
    Could not extract numbers: var=None, compare=8000.0
    Result: False
â„¹ï¸ No conditions matched - using default path: 1763197118793
âœ… Condition matched - moving to node: N_AskCapital_5k_V1_Adaptive
ğŸ“‹ Processing node streaming - Type: conversation, Mode: prompt, Content length: 921 chars
ğŸ¤– Using PROMPT mode - will generate AI response
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:44:49.579] ğŸ’¬ LLM REQUEST START: 11 conversation turns, 8946 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (1860 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 6, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 6:44 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (11 messages)
ğŸ“   assistant: [N] Software sales is a solid fieldâ€”lots of our folks come from there and use this to build somethin...
ğŸ“   user: User: I make about $120,000 a year base....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:50.708] ğŸ’¬ LLM FIRST TOKEN: 1128ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] $120,000 base is impressiveâ€”puts you in a strong spot to scale up without ri...
ğŸ“¤ Streamed sentence: [N] $120,000 base is impressiveâ€”puts you in a stro...
    ğŸ”Š TTS: For this model,
ğŸ“¤ Streamed sentence: For this model,...
    ğŸ”Š TTS: we typically look for about five thousand dollars in liquid capital to get start...
ğŸ“¤ Streamed sentence: we typically look for about five thousand dollars ...
    ğŸ”Š TTS: Do you have that amount accessible right now?
ğŸ“¤ Streamed final fragment: Do you have that amount accessible right now?...
â±ï¸ [TIMING] LLM_TOTAL: 1513ms for 246 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763197118793 in conversation history
LLM response (2.02s): [N] $120,000 base is impressiveâ€”puts you in a strong spot to scale up without risking your main gig. For this model, we typically look for about five thousand dollars in liquid capital to get started. Do you have that amount accessible right now?
Total latency: 2.02s

   ğŸ“ NODE: N_AskCapital_5k_V1_Adaptive
   ğŸ¤– RESPONSE: [N] $120,000 base is impressiveâ€”puts you in a strong spot to scale up without risking your main gig. For this model, we typically look for about five thousand dollars in liquid capital to get started....

============================================================
ğŸ¤ TURN 15: User says: "User: I have about $20,000 in savings right now."
============================================================
â±ï¸ [18:44:51.595] ğŸ“¥ process_user_input() ENTRY - text: 'User: I have about $20,000 in savings right now....'
â±ï¸ [18:44:51.596] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:51.596] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:51.596] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 13, Is first: False
ğŸ” Using explicitly set current_node_id: 1763197118793
â±ï¸ [18:44:51.596] ğŸ”€ About to call _follow_transition() for: User: I have about $20,000 in ...
Evaluating transitions from N_AskCapital_5k_V1_Adaptive for message: User: I have about $20,000 in savings right now.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:44:51.658] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:52.058] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 399ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ["If the user's response indicates they have the cap...", "They indicate they don't have at least $5k (ie, No..."]
Selected transition index: 0
Transition: N_AskCapital_5k_V1_Adaptive -> N401_AskWhyNow_Initial_V10_AssertiveFrame
â±ï¸ [TIMING] TRANSITION_EVAL: 462ms
â±ï¸ [18:44:52.059] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [18:44:52.059] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/13 messages)
â±ï¸ [18:44:52.114] ğŸ’¬ LLM REQUEST START: 13 conversation turns, 12692 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5606 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 7, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 6:44 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] $120,000 base is impressiveâ€”puts you in a strong spot to scale up without risking your main gig....
ğŸ“   user: User: I have about $20,000 in savings right now....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:52.974] ğŸ’¬ LLM FIRST TOKEN: 859ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Twenty thousand in savings gives you plenty of flexibility to start strong w...
ğŸ“¤ Streamed sentence: [N] Twenty thousand in savings gives you plenty of...
    ğŸ”Š TTS: Just to understand a bit better,
ğŸ“¤ Streamed sentence: Just to understand a bit better,...
    ğŸ”Š TTS: is there a specific reason you're looking to make a change or explore something ...
ğŸ“¤ Streamed sentence: is there a specific reason you're looking to make ...
    ğŸ”Š TTS: as opposed to say,
ğŸ“¤ Streamed sentence: as opposed to say,...
    ğŸ”Š TTS: six months from now?
ğŸ“¤ Streamed final fragment: six months from now?...
â±ï¸ [TIMING] LLM_TOTAL: 1065ms for 263 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (1.58s): [N] Twenty thousand in savings gives you plenty of flexibility to start strong with this. Just to understand a bit better, is there a specific reason you're looking to make a change or explore something like this right now, as opposed to say, six months from now?
Total latency: 1.59s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] Twenty thousand in savings gives you plenty of flexibility to start strong with this. Just to understand a bit better, is there a specific reason you're looking to make a change or explore somethi...

============================================================
ğŸ¤ TURN 17: User says: "User: No, it's just me making the decisions."
============================================================
â±ï¸ [18:44:53.682] ğŸ“¥ process_user_input() ENTRY - text: 'User: No, it's just me making the decisions....'
â±ï¸ [18:44:53.682] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:53.682] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:53.682] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 15, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [18:44:53.682] ğŸ”€ About to call _follow_transition() for: User: No, it's just me making ...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: No, it's just me making the decisions.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:44:53.723] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:54.018] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 294ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: To ask the "Why now?" question and then use assertive, frame-controlling tactics to handle any defer...
â±ï¸ [TIMING] TRANSITION_EVAL: 335ms
â±ï¸ [18:44:54.018] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N401_AskWhyNow_Initial_V10_AssertiveFrame (type: conversation, mode: prompt)
â±ï¸ [18:44:54.018] ğŸ“„ About to process content (mode=prompt, length=4667)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N401_AskWhyNow_Initial_V10_AssertiveFrame': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/15 messages)
â±ï¸ [18:44:54.060] ğŸ’¬ LLM REQUEST START: 15 conversation turns, 12692 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5606 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 8, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 6:44 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Twenty thousand in savings gives you plenty of flexibility to start strong with this. Just to un...
ğŸ“   user: User: No, it's just me making the decisions....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:54.628] ğŸ’¬ LLM FIRST TOKEN: 568ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Got it,
ğŸ“¤ Streamed sentence: [N] Got it,...
    ğŸ”Š TTS: so you're the one calling the shots here.
ğŸ“¤ Streamed sentence: so you're the one calling the shots here....
    ğŸ”Š TTS: Exploring options like this on your own timeline makes sense.
ğŸ“¤ Streamed sentence: Exploring options like this on your own timeline m...
    ğŸ”Š TTS: But let me ask you this,
ğŸ“¤ Streamed sentence: But let me ask you this,...
    ğŸ”Š TTS: when you picture things six months from now,
ğŸ“¤ Streamed sentence: when you picture things six months from now,...
    ğŸ”Š TTS: do you see yourself in the exact same spot financially,
ğŸ“¤ Streamed sentence: do you see yourself in the exact same spot financi...
    ğŸ”Š TTS: or have you taken action on something to change that?
ğŸ“¤ Streamed final fragment: or have you taken action on something to change th...
â±ï¸ [TIMING] LLM_TOTAL: 968ms for 295 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763196939647 in conversation history
LLM response (1.35s): [N] Got it, so you're the one calling the shots here. Exploring options like this on your own timeline makes sense. But let me ask you this, when you picture things six months from now, do you see yourself in the exact same spot financially, or have you taken action on something to change that?
Total latency: 1.35s

   ğŸ“ NODE: N401_AskWhyNow_Initial_V10_AssertiveFrame
   ğŸ¤– RESPONSE: [N] Got it, so you're the one calling the shots here. Exploring options like this on your own timeline makes sense. But let me ask you this, when you picture things six months from now, do you see you...

============================================================
ğŸ¤ TURN 19: User says: "User: I can probably deduce about 10 hours a week."
============================================================
â±ï¸ [18:44:55.531] ğŸ“¥ process_user_input() ENTRY - text: 'User: I can probably deduce about 10 hours a week....'
â±ï¸ [18:44:55.531] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:55.531] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:55.531] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 17, Is first: False
ğŸ” Using explicitly set current_node_id: 1763196939647
â±ï¸ [18:44:55.531] ğŸ”€ About to call _follow_transition() for: User: I can probably deduce ab...
Evaluating transitions from N401_AskWhyNow_Initial_V10_AssertiveFrame for message: User: I can probably deduce about 10 hours a week.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:44:55.588] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:55.989] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 400ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ["User's response indicates a motivation for change ...", 'The user says they have to go....']
Selected transition index: 0
Transition: N401_AskWhyNow_Initial_V10_AssertiveFrame -> N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
â±ï¸ [TIMING] TRANSITION_EVAL: 457ms
â±ï¸ [18:44:55.989] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned (type: conversation, mode: prompt)
â±ï¸ [18:44:55.990] ğŸ“„ About to process content (mode=prompt, length=1863)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/17 messages)
â±ï¸ [18:44:56.048] ğŸ’¬ LLM REQUEST START: 17 conversation turns, 9888 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (2802 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 9, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 6:44 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail....
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Got it, so you're the one calling the shots here. Exploring options like this on your own timeli...
ğŸ“   user: User: I can probably deduce about 10 hours a week....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:56.824] ğŸ’¬ LLM FIRST TOKEN: 775ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Ten hours a week is a realistic commitment that fits well with how we struct...
ğŸ“¤ Streamed sentence: [N] Ten hours a week is a realistic commitment tha...
    ğŸ”Š TTS: You know why that's actually a smart move right now?
ğŸ“¤ Streamed final fragment: You know why that's actually a smart move right no...
â±ï¸ [TIMING] LLM_TOTAL: 1529ms for 193 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198047712 in conversation history
LLM response (2.05s): [N] Ten hours a week is a realistic commitment that fits well with how we structure thisâ€”many in sales backgrounds start there and scale up. You know why that's actually a smart move right now?
Total latency: 2.05s

   ğŸ“ NODE: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
   ğŸ¤– RESPONSE: [N] Ten hours a week is a realistic commitment that fits well with how we structure thisâ€”many in sales backgrounds start there and scale up. You know why that's actually a smart move right now?

============================================================
ğŸ¤ TURN 21: User says: "User: My credit is good, around 750."
============================================================
â±ï¸ [18:44:58.080] ğŸ“¥ process_user_input() ENTRY - text: 'User: My credit is good, around 750....'
â±ï¸ [18:44:58.080] â© About to call _process_call_flow_streaming()
â±ï¸ [18:44:58.080] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:44:58.080] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 19, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198047712
â±ï¸ [18:44:58.080] ğŸ”€ About to call _follow_transition() for: User: My credit is good, aroun...
Evaluating transitions from N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned for message: User: My credit is good, around 750.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:44:58.129] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:58.624] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 494ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['The User responds with anything - take their respo...', 'The user says they have to go. - Call them back - ...']
Selected transition index: 0
Transition: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned -> N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
â±ï¸ [TIMING] TRANSITION_EVAL: 543ms
â±ï¸ [18:44:58.624] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:44 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned (type: conversation, mode: prompt)
â±ï¸ [18:44:58.624] ğŸ“„ About to process content (mode=prompt, length=4458)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/19 messages)
â±ï¸ [18:44:58.661] ğŸ’¬ LLM REQUEST START: 19 conversation turns, 12484 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5398 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 10, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 6:44 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Ten hours a week is a realistic commitment that fits well with how we structure thisâ€”many in sal...
ğŸ“   user: User: My credit is good, around 750....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:44:59.159] ğŸ’¬ LLM FIRST TOKEN: 498ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] A 750 credit score is excellent and opens up options if needed,
ğŸ“¤ Streamed sentence: [N] A 750 credit score is excellent and opens up o...
    ğŸ”Š TTS: but this model doesn't rely on financingâ€”it's all about your upfront investment ...
ğŸ“¤ Streamed sentence: but this model doesn't rely on financingâ€”it's all ...
    ğŸ”Š TTS: You know why that's actually a smart move right now?
ğŸ“¤ Streamed final fragment: You know why that's actually a smart move right no...
â±ï¸ [TIMING] LLM_TOTAL: 893ms for 225 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198201369 in conversation history
LLM response (1.47s): [N] A 750 credit score is excellent and opens up options if needed, but this model doesn't rely on financingâ€”it's all about your upfront investment in building those sites. You know why that's actually a smart move right now?
Total latency: 1.47s

   ğŸ“ NODE: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
   ğŸ¤– RESPONSE: [N] A 750 credit score is excellent and opens up options if needed, but this model doesn't rely on financingâ€”it's all about your upfront investment in building those sites. You know why that's actuall...

============================================================
ğŸ¤ TURN 25: User says: "User: That makes sense. I see why you called."
============================================================
â±ï¸ [18:45:00.055] ğŸ“¥ process_user_input() ENTRY - text: 'User: That makes sense. I see why you called....'
â±ï¸ [18:45:00.055] â© About to call _process_call_flow_streaming()
â±ï¸ [18:45:00.055] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:45:00.055] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 21, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198201369
â±ï¸ [18:45:00.055] ğŸ”€ About to call _follow_transition() for: User: That makes sense. I see ...
Evaluating transitions from N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned for message: User: That makes sense. I see why you called.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:45:00.108] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 2 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:45:00.491] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 382ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['The User responds saying yes to some relevant valu...', 'The user says they have to go....']
Selected transition index: 0
Transition: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned -> N500A_ProposeDeeperDive_V5_Adaptive
â±ï¸ [TIMING] TRANSITION_EVAL: 436ms
â±ï¸ [18:45:00.491] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:45 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500A_ProposeDeeperDive_V5_Adaptive (type: conversation, mode: prompt)
â±ï¸ [18:45:00.492] ğŸ“„ About to process content (mode=prompt, length=4610)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500A_ProposeDeeperDive_V5_Adaptive': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/21 messages)
â±ï¸ [18:45:00.547] ğŸ’¬ LLM REQUEST START: 21 conversation turns, 12636 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5550 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 11, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 6:45 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] A 750 credit score is excellent and opens up options if needed, but this model doesn't rely on f...
ğŸ“   user: User: That makes sense. I see why you called....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:45:01.115] ğŸ’¬ LLM FIRST TOKEN: 567ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Glad it's clicking for you.
ğŸ“¤ Streamed sentence: [N] Glad it's clicking for you....
    ğŸ”Š TTS: The next step is setting up a quick strategy call with our senior consultant,
ğŸ“¤ Streamed sentence: The next step is setting up a quick strategy call ...
    ğŸ”Š TTS: Kendrick,
ğŸ“¤ Streamed sentence: Kendrick,...
    ğŸ”Š TTS: to map out a custom plan for your lead gen sites.
ğŸ“¤ Streamed sentence: to map out a custom plan for your lead gen sites....
    ğŸ”Š TTS: Sound good?
ğŸ“¤ Streamed final fragment: Sound good?...
â±ï¸ [TIMING] LLM_TOTAL: 920ms for 181 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198305881 in conversation history
LLM response (1.41s): [N] Glad it's clicking for you. The next step is setting up a quick strategy call with our senior consultant, Kendrick, to map out a custom plan for your lead gen sites. Sound good?
Total latency: 1.41s

   ğŸ“ NODE: N500A_ProposeDeeperDive_V5_Adaptive
   ğŸ¤– RESPONSE: [N] Glad it's clicking for you. The next step is setting up a quick strategy call with our senior consultant, Kendrick, to map out a custom plan for your lead gen sites. Sound good?

============================================================
ğŸ¤ TURN 28: User says: "User: I am in Eastern time."
============================================================
â±ï¸ [18:45:01.970] ğŸ“¥ process_user_input() ENTRY - text: 'User: I am in Eastern time....'
â±ï¸ [18:45:01.970] â© About to call _process_call_flow_streaming()
â±ï¸ [18:45:01.970] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:45:01.970] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 23, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198305881
â±ï¸ [18:45:01.971] ğŸ”€ About to call _follow_transition() for: User: I am in Eastern time....
Evaluating transitions from N500A_ProposeDeeperDive_V5_Adaptive for message: User: I am in Eastern time.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:45:02.029] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:45:02.450] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 420ms
ğŸ¤– AI transition decision: '-1'
ğŸ“Š Available transitions: ['Prospect agrees that setting up another call "soun...']
Selected transition index: -1
No specific condition matched, looking for default transition...
âš ï¸ No transition matched, but node has GOAL. Staying on current node to continue with goal-based guidance.
ğŸ¯ Goal: Simply ask them if they want to set up and appointment - do not offer an appointment or try to sched...
â±ï¸ [TIMING] TRANSITION_EVAL: 479ms
â±ï¸ [18:45:02.451] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:45 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500A_ProposeDeeperDive_V5_Adaptive (type: conversation, mode: prompt)
â±ï¸ [18:45:02.451] ğŸ“„ About to process content (mode=prompt, length=4610)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500A_ProposeDeeperDive_V5_Adaptive': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/23 messages)
â±ï¸ [18:45:02.508] ğŸ’¬ LLM REQUEST START: 23 conversation turns, 12636 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (5550 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: C type - adjust your response accordingly
CONVERSATION STATUS: Turn 12, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 6:45 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Glad it's clicking for you. The next step is setting up a quick strategy call with our senior co...
ğŸ“   user: User: I am in Eastern time....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:45:03.091] ğŸ’¬ LLM FIRST TOKEN: 582ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] Eastern time works perfectly since that's where we're based too.
ğŸ“¤ Streamed sentence: [N] Eastern time works perfectly since that's wher...
    ğŸ”Š TTS: So,
ğŸ“¤ Streamed sentence: So,...
    ğŸ”Š TTS: does setting up that strategy call with Kendrick sound like the right next move ...
ğŸ“¤ Streamed final fragment: does setting up that strategy call with Kendrick s...
â±ï¸ [TIMING] LLM_TOTAL: 827ms for 161 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198305881 in conversation history
LLM response (1.37s): [N] Eastern time works perfectly since that's where we're based too. So, does setting up that strategy call with Kendrick sound like the right next move for you?
Total latency: 1.37s

   ğŸ“ NODE: N500A_ProposeDeeperDive_V5_Adaptive
   ğŸ¤– RESPONSE: [N] Eastern time works perfectly since that's where we're based too. So, does setting up that strategy call with Kendrick sound like the right next move for you?

============================================================
ğŸ¤ TURN 32: User says: "User: Sure, Tuesday at 2pm works for me."
============================================================
â±ï¸ [18:45:03.837] ğŸ“¥ process_user_input() ENTRY - text: 'User: Sure, Tuesday at 2pm works for me....'
â±ï¸ [18:45:03.837] â© About to call _process_call_flow_streaming()
â±ï¸ [18:45:03.837] ğŸ”€ Agent type: call_flow, calling flow processor...
â±ï¸ [18:45:03.837] ğŸ”€ _process_call_flow_streaming() ENTRY
Flow processing - History length: 25, Is first: False
ğŸ” Using explicitly set current_node_id: 1763198305881
â±ï¸ [18:45:03.837] ğŸ”€ About to call _follow_transition() for: User: Sure, Tuesday at 2pm wor...
Evaluating transitions from N500A_ProposeDeeperDive_V5_Adaptive for message: User: Sure, Tuesday at 2pm works for me.
Failed to decrypt key, assuming unencrypted: 
â±ï¸ [18:45:03.888] ğŸ”€ TRANSITION EVALUATION START - Calling LLM for 1 options
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:45:04.336] ğŸ”€ TRANSITION EVALUATION COMPLETE - took 447ms
ğŸ¤– AI transition decision: '0'
ğŸ“Š Available transitions: ['Prospect agrees that setting up another call "soun...']
Selected transition index: 0
Transition: N500A_ProposeDeeperDive_V5_Adaptive -> N500B_AskTimezone_V2_FullyTuned
â±ï¸ [TIMING] TRANSITION_EVAL: 500ms
â±ï¸ [18:45:04.338] âœ… Node selected, about to process content...
ğŸ”§ Replaced {{now}} with Friday, December 19, 2025 at 6:45 PM EST in content
ğŸ”§ Replaced {{customer_name}} with Kendrick in content
ğŸ”§ Replaced {{callerName}} with  in content
ğŸ”§ Replaced {{from_number}} with +18885550123 in content
ğŸ”§ Replaced {{to_number}} with +17708336397 in content
ğŸ”§ Replaced {{email}} with kendrickbowman9@gmail.com in content
Using flow node: N500B_AskTimezone_V2_FullyTuned (type: conversation, mode: prompt)
ğŸ“š skip_mandatory_precheck=true - skipping pre-response mandatory check, will check on transition
â±ï¸ [18:45:04.339] ğŸ“„ About to process content (mode=prompt, length=2752)
Failed to decrypt key, assuming unencrypted: 
ğŸ” Node 'N500B_AskTimezone_V2_FullyTuned': use_parallel_llm=True
âš¡ Parallel mode: Using condensed history (10/25 messages)
â±ï¸ [18:45:04.414] ğŸ’¬ LLM REQUEST START: 25 conversation turns, 10778 system chars (KB cached)
ğŸ“ â•â•â•â•â•â•â•â•â•â•â• LLM PROMPT BREAKDOWN â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ [SYSTEM MSG 1 - GLOBAL PROMPT] (7086 chars):
ğŸ“   Preview: # Global Prompt: Direct Drive Engine (V4.2 - Acknowledging & Fluid)

When user states income, convert/update as [yearly_income] variable for logic splits.

If user says a name, don't assume it's theirsâ€”wait for explicit correction.

If user asks to repeat info, rephrase naturallyâ€”never exact repeat.

If asked your state: "Atlanta, GA. Been in Midtown 10 years."

If asked about call number: "Company number."

User email: {customer_email} (for them: {{customer_email}}).

If explaining ends in peri...
ğŸ“ [SYSTEM MSG 2 - DYNAMIC CONTEXT] (3692 chars):
ğŸ“   Preview: 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PREPROCESSED CONTEXT (to help you prioritize and focus):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

USER COMMUNICATION STYLE: S type - adjust your response accordingly
CONVERSATION STATUS: Turn 13, objection handling phase

This context is provided to help you focus. You still need to:
1. Generate a natural, contextual response
2. Evaluate transitions per your node instructions

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# CURRENT CONTEXT
Customer: Kendrick
Variables: {"now": "Friday, December 19, 2025 at 6:45 PM EST", "customer_name": "Kendrick", "callerName": "", "from_number": "+18885550123", "to_number": "+17708336397", "email": "kendrickbowman9@gmail...
ğŸ“ [CONVERSATION HISTORY] (10 messages)
ğŸ“   assistant: [N] Eastern time works perfectly since that's where we're based too. So, does setting up that strate...
ğŸ“   user: User: Sure, Tuesday at 2pm works for me....
ğŸ“ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HTTP Request: POST https://api.x.ai/v1/chat/completions "HTTP/1.1 200 OK"
â±ï¸ [18:45:04.893] ğŸ’¬ LLM FIRST TOKEN: 479ms (grok grok-4-fast-non-reasoning)
    ğŸ”Š TTS: [N] I appreciate you wanting to jump ahead on that.
ğŸ“¤ Streamed sentence: [N] I appreciate you wanting to jump ahead on that...
    ğŸ”Š TTS: But booking a time right now wouldn't be the best move without us first nailing ...
ğŸ“¤ Streamed sentence: But booking a time right now wouldn't be the best ...
    ğŸ”Š TTS: So,
ğŸ“¤ Streamed sentence: So,...
    ğŸ”Š TTS: does setting up that strategy call with Kendrick sound like the right next move ...
ğŸ“¤ Streamed final fragment: does setting up that strategy call with Kendrick s...
â±ï¸ [TIMING] LLM_TOTAL: 761ms for 264 chars (grok grok-4-fast-non-reasoning)
ğŸ”Š Silence tracking reset for call debug_20251219_184444 (user responded)
âœ… User responded to regular message, resetting counter
ğŸ’¾ Storing node ID 1763198398056 in conversation history
LLM response (1.34s): [N] I appreciate you wanting to jump ahead on that. But booking a time right now wouldn't be the best move without us first nailing down if this fits your goals perfectly. So, does setting up that strategy call with Kendrick sound like the right next move for you?
Total latency: 1.34s

   ğŸ“ NODE: N500B_AskTimezone_V2_FullyTuned
   ğŸ¤– RESPONSE: [N] I appreciate you wanting to jump ahead on that. But booking a time right now wouldn't be the best move without us first nailing down if this fits your goals perfectly. So, does setting up that str...

============================================================
ğŸ“Š SCRIPT COMPLETE - NODE HISTORY:
============================================================
  Turn 5: Greeting
  Turn 6: Node Prompt: N001B_IntroAndHelpRequest_Only (V3 - Follows Name Confirmation)
  Turn 7: Node ID: N_Opener_StackingIncomeHook_V3_CreativeTactic
  Turn 8: N_IntroduceModel_And_AskQuestions_V3_Adaptive
  Turn 9: N_KB_Q&A_With_StrategicNarrative_V3_Adaptive
  Turn 13: N_AskCapital_5k_V1_Adaptive
  Turn 15: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 17: N401_AskWhyNow_Initial_V10_AssertiveFrame
  Turn 19: N402_Compliment_And_AskYouKnowWhy_V5_FullyTuned
  Turn 21: N403_IdentityAffirmation_And_ValueFitQuestion_V8_GoalAligned
  Turn 25: N500A_ProposeDeeperDive_V5_Adaptive
  Turn 28: N500A_ProposeDeeperDive_V5_Adaptive
  Turn 32: N500B_AskTimezone_V2_FullyTuned
